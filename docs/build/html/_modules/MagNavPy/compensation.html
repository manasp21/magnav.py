<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>magnavpy.compensation &#8212; MagNavPy 0.1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=27fed22d" />
    <script src="../../_static/documentation_options.js?v=01f34227"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for magnavpy.compensation</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Python translation of MagNav.jl/src/compensation.jl</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">cast</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.signal</span><span class="w"> </span><span class="kn">import</span> <span class="n">detrend</span> <span class="k">as</span> <span class="n">scipy_detrend</span><span class="p">,</span> <span class="n">butter</span><span class="p">,</span> <span class="n">lfilter</span> <span class="c1"># Added butter, lfilter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span> <span class="c1"># For get_split (alternative)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span> <span class="c1"># For norm_sets (example)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">ElasticNet</span><span class="p">,</span> <span class="n">ElasticNetCV</span><span class="p">,</span> <span class="n">Ridge</span> <span class="c1"># For elasticnet_fit, linear_fit with ridge</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cross_decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PLSRegression</span> <span class="c1"># For plsr_fit</span>

<span class="c1"># --- Placeholder/Stub Definitions ---</span>
<span class="c1"># These would typically be imported from other modules or defined in detail.</span>

<span class="n">SILENT_DEBUG</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># Global debug flag, similar to silent_debug in Julia</span>

<div class="viewcode-block" id="Chain">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.Chain">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Chain</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span> <span class="c1"># Alias for torch.nn.Sequential for closer naming</span>
    <span class="k">pass</span></div>


<div class="viewcode-block" id="CompParams">
<a class="viewcode-back" href="../../api_structs.html#magnavpy.compensation.CompParams">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">CompParams</span><span class="p">:</span> <span class="c1"># Base placeholder</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">version</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;version&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_setup</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;features_setup&quot;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features_no_norm</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;features_no_norm&quot;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model_type&quot;</span><span class="p">,</span> <span class="s2">&quot;m1&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;y_type&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_mag</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_mag&quot;</span><span class="p">,</span> <span class="s2">&quot;mag_1_c&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_vec</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_vec&quot;</span><span class="p">,</span> <span class="s2">&quot;flux_a&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_norms</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;data_norms&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">terms</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;terms&quot;</span><span class="p">,</span> <span class="p">[])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">terms_A</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;terms_A&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">,</span> <span class="s2">&quot;induced&quot;</span><span class="p">,</span> <span class="s2">&quot;eddy&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sub_diurnal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;sub_diurnal&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sub_igrf</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;sub_igrf&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bpf_mag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;bpf_mag&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reorient_vec</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;reorient_vec&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_type_A</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;norm_type_A&quot;</span><span class="p">,</span> <span class="s2">&quot;none&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_type_x</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;norm_type_x&quot;</span><span class="p">,</span> <span class="s2">&quot;standardize&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_type_y</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;norm_type_y&quot;</span><span class="p">,</span> <span class="s2">&quot;standardize&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">TL_coef</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;TL_coef&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span></div>


<div class="viewcode-block" id="NNCompParams">
<a class="viewcode-back" href="../../api_structs.html#magnavpy.compensation.NNCompParams">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">NNCompParams</span><span class="p">(</span><span class="n">CompParams</span><span class="p">):</span> <span class="c1"># Placeholder</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">η_adam</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;η_adam&quot;</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_adam</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epoch_adam&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_lbfgs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epoch_lbfgs&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;hidden&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">8</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;activation&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">)</span> <span class="c1"># swish</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batchsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;batchsize&quot;</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frac_train</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;frac_train&quot;</span><span class="p">,</span> <span class="mi">14</span><span class="o">/</span><span class="mi">17</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">α_sgl</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;α_sgl&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">λ_sgl</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;λ_sgl&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_pca</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;k_pca&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_fi</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;drop_fi&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_fi_bson</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;drop_fi_bson&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop_fi_csv</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;drop_fi_csv&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">perm_fi</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;perm_fi&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">perm_fi_csv</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;perm_fi_csv&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinCompParams">
<a class="viewcode-back" href="../../api_structs.html#magnavpy.compensation.LinCompParams">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LinCompParams</span><span class="p">(</span><span class="n">CompParams</span><span class="p">):</span> <span class="c1"># Placeholder</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_plsr</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;k_plsr&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># Assuming 0 means use all features if not specified</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">λ_TL</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;λ_TL&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span></div>



<div class="viewcode-block" id="XYZ">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.XYZ">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">XYZ</span><span class="p">:</span> <span class="c1"># Placeholder</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">traj</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mag_1_c</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">flux_a</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">traj</span> <span class="o">=</span> <span class="n">traj</span> <span class="k">if</span> <span class="n">traj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span> <span class="c1"># Example: N x 3 (lat,lon,alt)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mag_1_c</span> <span class="o">=</span> <span class="n">mag_1_c</span> <span class="c1"># Placeholder for scalar magnetometer data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flux_a</span> <span class="o">=</span> <span class="n">flux_a</span>   <span class="c1"># Placeholder for vector magnetometer data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">=</span> <span class="n">dt</span>
        <span class="c1"># Add other fields as encountered, e.g., xyz.diurnal, xyz.igrf</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span></div>


<div class="viewcode-block" id="MapS">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.MapS">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MapS</span><span class="p">:</span> <span class="c1"># Placeholder</span>
    <span class="k">pass</span></div>

<div class="viewcode-block" id="MapSd">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.MapSd">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MapSd</span><span class="p">(</span><span class="n">MapS</span><span class="p">):</span> <span class="k">pass</span></div>

<div class="viewcode-block" id="MapS3D">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.MapS3D">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MapS3D</span><span class="p">(</span><span class="n">MapS</span><span class="p">):</span> <span class="k">pass</span></div>

<span class="n">mapS_null</span> <span class="o">=</span> <span class="n">MapS</span><span class="p">()</span> <span class="c1"># Placeholder</span>

<div class="viewcode-block" id="TempParams">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.TempParams">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">TempParams</span><span class="p">:</span> <span class="c1"># Placeholder</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">σ_curriculum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;σ_curriculum&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l_window</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;l_window&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;window_type&quot;</span><span class="p">,</span> <span class="s2">&quot;sliding&quot;</span><span class="p">)</span> <span class="c1"># :none, :sliding, :contiguous</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tf_layer_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;tf_layer_type&quot;</span><span class="p">,</span> <span class="s2">&quot;postlayer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tf_norm_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;tf_norm_type&quot;</span><span class="p">,</span> <span class="s2">&quot;batch&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dropout_prob&quot;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N_tf_head</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;N_tf_head&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tf_gain</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;tf_gain&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span></div>


<span class="c1"># --- Stub functions (to be implemented or imported) ---</span>
<div class="viewcode-block" id="norm_sets">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.norm_sets">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">norm_sets</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">norm_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;standardize&quot;</span><span class="p">,</span> <span class="n">no_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for data normalization.&quot;&quot;&quot;</span>
    <span class="c1"># This is a simplified example. The actual function might be more complex.</span>
    <span class="n">original_ndim</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="c1"># Store original ndim</span>
    <span class="n">data_for_norm</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># Work on a copy</span>
    <span class="k">if</span> <span class="n">original_ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">data_for_norm</span> <span class="o">=</span> <span class="n">data_for_norm</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Use data_for_norm</span>
    
    <span class="c1"># Handle empty data input gracefully</span>
    <span class="k">if</span> <span class="n">data_for_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Determine shape of bias/scale based on original_ndim and data_for_norm.shape[1]</span>
        <span class="k">if</span> <span class="n">original_ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_cols_empty</span> <span class="o">=</span> <span class="n">data_for_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_cols_empty</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_cols_empty</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">data_for_norm</span>

    <span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">data_for_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">data_for_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">data_norm</span> <span class="o">=</span> <span class="n">data_for_norm</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data_for_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">if</span> <span class="n">no_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">no_norm</span><span class="p">)</span> <span class="ow">and</span> <span class="n">no_norm</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="c1"># Added boundary check for no_norm</span>
            <span class="k">continue</span>
        <span class="k">if</span> <span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;standardize&quot;</span><span class="p">:</span>
            <span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data_for_norm</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
            <span class="n">scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">data_for_norm</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="n">scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># Avoid division by zero</span>
            <span class="n">data_norm</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_for_norm</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;normalize&quot;</span><span class="p">:</span> <span class="c1"># Example: min-max</span>
            <span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">data_for_norm</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
            <span class="n">scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">data_for_norm</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">data_for_norm</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="n">scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="n">data_norm</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_for_norm</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;none&quot;</span><span class="p">:</span>
            <span class="k">pass</span> <span class="c1"># No normalization</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown norm_type: </span><span class="si">{</span><span class="n">norm_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
    <span class="k">if</span> <span class="n">data_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">original_ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">bias_out</span> <span class="o">=</span> <span class="n">bias</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">scale_out</span> <span class="o">=</span> <span class="n">scale</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">data_norm_out</span> <span class="o">=</span> <span class="n">data_norm</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">bias_out</span><span class="p">,</span> <span class="n">scale_out</span><span class="p">,</span> <span class="n">data_norm_out</span>

    <span class="k">return</span> <span class="n">bias</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">data_norm</span></div>


<div class="viewcode-block" id="denorm_sets">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.denorm_sets">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">denorm_sets</span><span class="p">(</span><span class="n">bias</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">],</span> <span class="n">scale</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">],</span> <span class="n">data_norm</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for data denormalization.&quot;&quot;&quot;</span>
    <span class="c1"># Ensure bias and scale are broadcastable with data_norm</span>
    <span class="n">_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span>
    <span class="n">_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>

    <span class="c1"># If data_norm is 1D, bias and scale should be scalar or 1-element for broadcasting</span>
    <span class="k">if</span> <span class="n">data_norm</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">_bias</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">_bias</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="p">:</span> <span class="n">_bias</span> <span class="o">=</span> <span class="n">_bias</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">_scale</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">_scale</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="p">:</span> <span class="n">_scale</span> <span class="o">=</span> <span class="n">_scale</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># If data_norm is 2D (N,F) and bias/scale are (F,), broadcasting works.</span>
    <span class="c1"># If bias/scale are scalar, broadcasting works.</span>
    <span class="k">return</span> <span class="n">data_norm</span> <span class="o">*</span> <span class="n">_scale</span> <span class="o">+</span> <span class="n">_bias</span></div>


<div class="viewcode-block" id="unpack_data_norms">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.unpack_data_norms">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">unpack_data_norms</span><span class="p">(</span><span class="n">data_norms_tuple</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for unpacking data normalization parameters.&quot;&quot;&quot;</span>
    <span class="c1"># Example: (A_bias,A_scale,v_scale,x_bias,x_scale,y_bias,y_scale)</span>
    <span class="c1"># or (_,_,v_scale,x_bias,x_scale,y_bias,y_scale)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_norms_tuple</span><span class="p">)</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span> <span class="c1"># Common case</span>
        <span class="k">return</span> <span class="n">data_norms_tuple</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_norms_tuple</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span> <span class="c1"># For linear_fit etc. (x_b, x_s, y_b, y_s)</span>
        <span class="k">return</span> <span class="n">data_norms_tuple</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_norms_tuple</span><span class="p">)</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># For nn_comp_1 (v_pca, x_b, x_s, y_b, y_s)</span>
        <span class="c1"># Pad with None for A_b, A_s to allow consistent unpacking if a 7-tuple is expected by some internal logic</span>
        <span class="k">return</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="o">+</span> <span class="n">data_norms_tuple</span>
    <span class="c1"># Add more cases if other tuple structures are used</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported data_norms_tuple structure: length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data_norms_tuple</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="get_nn_m">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.get_nn_m">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_nn_m</span><span class="p">(</span><span class="n">Nf</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Ny</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for creating a neural network model (Chain).&quot;&quot;&quot;</span>
    <span class="n">layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">input_size</span> <span class="o">=</span> <span class="n">Nf</span>
    <span class="n">model_type_nn</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model_type&quot;</span><span class="p">)</span> <span class="c1"># Store for clarity</span>
    
    <span class="k">if</span> <span class="n">model_type_nn</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span> <span class="c1"># Temporal models might have different input handling</span>
        <span class="n">l_window</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;l_window&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># sequence length</span>
        <span class="c1"># Nf is features_per_step. The nn.Linear layers will operate on features_per_step.</span>
        <span class="c1"># Transformer/LSTM layers will handle the sequence.</span>
        <span class="k">pass</span> <span class="c1"># input_size remains Nf for the first Linear layer</span>


    <span class="n">current_layer_input_size</span> <span class="o">=</span> <span class="n">input_size</span>
    <span class="k">for</span> <span class="n">h_units</span> <span class="ow">in</span> <span class="n">hidden</span><span class="p">:</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">current_layer_input_size</span><span class="p">,</span> <span class="n">h_units</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">())</span>
        <span class="c1"># Potentially add dropout or batchnorm here if part of get_nn_m logic</span>
        <span class="n">current_layer_input_size</span> <span class="o">=</span> <span class="n">h_units</span>
    
    <span class="k">if</span> <span class="n">model_type_nn</span> <span class="o">==</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">:</span>
        <span class="c1"># Example: Add a TransformerEncoderLayer</span>
        <span class="n">tf_d_model</span> <span class="o">=</span> <span class="n">current_layer_input_size</span> <span class="c1"># d_model is the number of expected features in the input for the transformer layer</span>
        <span class="n">tf_nhead</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;N_tf_head&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
        <span class="n">tf_dim_feedforward</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;tf_dim_feedforward&quot;</span><span class="p">,</span> <span class="n">tf_d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span> <span class="c1"># Allow override</span>
        <span class="n">tf_dropout</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dropout_prob&quot;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="n">tf_activation_str</span> <span class="o">=</span> <span class="n">activation_to_str</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="c1"># Get string for transformer</span>
        
        <span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span>
            <span class="n">d_model</span><span class="o">=</span><span class="n">tf_d_model</span><span class="p">,</span>
            <span class="n">nhead</span><span class="o">=</span><span class="n">tf_nhead</span><span class="p">,</span>
            <span class="n">dim_feedforward</span><span class="o">=</span><span class="n">tf_dim_feedforward</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">tf_dropout</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">tf_activation_str</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span> <span class="c1"># Assuming input to transformer is (batch, seq_len, features)</span>
        <span class="p">)</span>
        <span class="n">num_tf_layers</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_tf_layers&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Allow specifying number of transformer layers</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_tf_layers</span><span class="p">))</span>
        <span class="c1"># Output of TransformerEncoder is (batch, seq_len, d_model).</span>
        <span class="c1"># The final Linear layer (added below) will take d_model as input features.</span>
        <span class="c1"># This assumes the transformer output is processed (e.g., taking last time step&#39;s output)</span>
        <span class="c1"># before this final linear layer if Ny is a scalar output per sequence.</span>
        <span class="c1"># If the NN is expected to output a sequence, the final Linear layer might need to be TimeDistributed.</span>
        <span class="c1"># For now, current_layer_input_size remains tf_d_model for the final Linear layer.</span>

    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">current_layer_input_size</span><span class="p">,</span> <span class="n">Ny</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span></div>


<div class="viewcode-block" id="activation_to_str">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.activation_to_str">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">activation_to_str</span><span class="p">(</span><span class="n">act_fn_type</span><span class="p">:</span> <span class="nb">type</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">act_fn_type</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">:</span> <span class="k">return</span> <span class="s2">&quot;silu&quot;</span>
    <span class="k">if</span> <span class="n">act_fn_type</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">:</span> <span class="k">return</span> <span class="s2">&quot;relu&quot;</span>
    <span class="k">if</span> <span class="n">act_fn_type</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">:</span> <span class="k">return</span> <span class="s2">&quot;tanh&quot;</span>
    <span class="k">if</span> <span class="n">act_fn_type</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">:</span> <span class="k">return</span> <span class="s2">&quot;gelu&quot;</span>
    <span class="c1"># Add more mappings as needed</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;activation_to_str: Unknown activation type </span><span class="si">{</span><span class="n">act_fn_type</span><span class="si">}</span><span class="s2">, defaulting to &#39;relu&#39;.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="s2">&quot;relu&quot;</span> <span class="c1"># Default</span></div>

<div class="viewcode-block" id="get_split">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.get_split">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_split</span><span class="p">(</span>
    <span class="n">N</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">frac_train</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">window_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">l_window</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get training &amp; validation data indices.</span>
<span class="sd">    Python translation of MagNav.jl&#39;s get_split.</span>
<span class="sd">    Indices returned are 0-indexed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">frac_train</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;frac_train of </span><span class="si">{</span><span class="n">frac_train</span><span class="si">}</span><span class="s2"> is not between 0 &amp; 1&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">N</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">l_window</span> <span class="o">&gt;=</span> <span class="n">N</span> <span class="ow">and</span> <span class="n">window_type</span> <span class="o">!=</span> <span class="s2">&quot;none&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;window length of </span><span class="si">{</span><span class="n">l_window</span><span class="si">}</span><span class="s2"> is too large for </span><span class="si">{</span><span class="n">N</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">N</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># Handle empty input case</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="n">p_train_np</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">p_val_np</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>

    <span class="k">if</span> <span class="n">window_type</span> <span class="o">==</span> <span class="s2">&quot;none&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">frac_train</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
            <span class="n">n_train</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">frac_train</span><span class="p">))</span>
            <span class="n">p_train_np</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span>
            <span class="n">p_val_np</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p_train_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
            <span class="n">p_val_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">window_type</span> <span class="o">==</span> <span class="s2">&quot;sliding&quot;</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">frac_train</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">n_train</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">frac_train</span><span class="p">))</span>
            <span class="c1"># Julia assertion: all(l_window .&lt;= (N_train, N-N_train))</span>
            <span class="c1"># This ensures that N_train &gt;= l_window and (N - N_train) &gt;= l_window.</span>
            <span class="c1"># This check can be added if strict adherence to original asserts is needed.</span>
            <span class="c1"># For now, focusing on the splitting logic.</span>
            
            <span class="n">p_train_np</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span>
            
            <span class="c1"># Julia: p_val = p[N_train+l_window : N] (1-indexed for p and start)</span>
            <span class="c1"># Python: val_start_idx_py = (N_train_from_1_based + l_window) - 1</span>
            <span class="c1"># n_train is count, so N_train_from_1_based is n_train.</span>
            <span class="n">val_start_idx_py</span> <span class="o">=</span> <span class="n">n_train</span> <span class="o">+</span> <span class="n">l_window</span> <span class="o">-</span><span class="mi">1</span> 
            <span class="k">if</span> <span class="n">val_start_idx_py</span> <span class="o">&gt;=</span> <span class="n">N</span> <span class="p">:</span> 
                <span class="n">p_val_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">p_val_np</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">val_start_idx_py</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># frac_train == 1</span>
            <span class="n">p_train_np</span> <span class="o">=</span> <span class="n">p</span>
            <span class="n">p_val_np</span> <span class="o">=</span> <span class="n">p</span>
    <span class="k">elif</span> <span class="n">window_type</span> <span class="o">==</span> <span class="s2">&quot;contiguous&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">l_window</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span> 
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;l_window must be positive for contiguous window_type&quot;</span><span class="p">)</span>
        
        <span class="n">block_starts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">l_window</span><span class="p">)</span>
        <span class="n">n_blocks</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">block_starts</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_blocks</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># N &lt; l_window, treat as &#39;none&#39; type split for these few samples</span>
            <span class="c1"># This also handles N == 0 correctly due to permutation of empty or arange(0)</span>
            <span class="n">p_rand</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
            <span class="n">n_train_samples_contig</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">frac_train</span><span class="p">))</span>
            <span class="n">p_train_np</span> <span class="o">=</span> <span class="n">p_rand</span><span class="p">[:</span><span class="n">n_train_samples_contig</span><span class="p">]</span>
            <span class="n">p_val_np</span> <span class="o">=</span> <span class="n">p_rand</span><span class="p">[</span><span class="n">n_train_samples_contig</span><span class="p">:]</span>


        <span class="k">else</span><span class="p">:</span>
            <span class="n">permuted_block_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n_blocks</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">frac_train</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">n_train_blocks</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">frac_train</span> <span class="o">*</span> <span class="n">n_blocks</span><span class="p">))</span>
                
                <span class="n">train_block_selector</span> <span class="o">=</span> <span class="n">permuted_block_indices</span><span class="p">[:</span><span class="n">n_train_blocks</span><span class="p">]</span>
                <span class="n">val_block_selector</span>   <span class="o">=</span> <span class="n">permuted_block_indices</span><span class="p">[</span><span class="n">n_train_blocks</span><span class="p">:]</span>
                
                <span class="n">p_train_list_internal</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">block_idx_in_selector</span> <span class="ow">in</span> <span class="n">train_block_selector</span><span class="p">:</span>
                    <span class="n">start</span> <span class="o">=</span> <span class="n">block_starts</span><span class="p">[</span><span class="n">block_idx_in_selector</span><span class="p">]</span>
                    <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">l_window</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
                    <span class="n">p_train_list_internal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">))</span>
                <span class="n">p_train_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">p_train_list_internal</span><span class="p">)</span> <span class="k">if</span> <span class="n">p_train_list_internal</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

                <span class="n">p_val_list_internal</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">block_idx_in_selector</span> <span class="ow">in</span> <span class="n">val_block_selector</span><span class="p">:</span>
                    <span class="n">start</span> <span class="o">=</span> <span class="n">block_starts</span><span class="p">[</span><span class="n">block_idx_in_selector</span><span class="p">]</span>
                    <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">l_window</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
                    <span class="n">p_val_list_internal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">))</span>
                <span class="n">p_val_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">p_val_list_internal</span><span class="p">)</span> <span class="k">if</span> <span class="n">p_val_list_internal</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span> <span class="c1"># frac_train == 1</span>
                <span class="n">p_all_list_internal</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">block_start_val</span> <span class="ow">in</span> <span class="n">block_starts</span><span class="p">:</span> 
                    <span class="n">start</span> <span class="o">=</span> <span class="n">block_start_val</span>
                    <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">l_window</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
                    <span class="n">p_all_list_internal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">))</span>
                <span class="n">p_train_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">p_all_list_internal</span><span class="p">)</span> <span class="k">if</span> <span class="n">p_all_list_internal</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
                <span class="n">p_val_np</span> <span class="o">=</span> <span class="n">p_train_np</span> 
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;window_type &#39;</span><span class="si">{</span><span class="n">window_type</span><span class="si">}</span><span class="s2">&#39; is invalid, select &#39;none&#39;, &#39;sliding&#39;, or &#39;contiguous&#39;&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">p_train_np</span><span class="p">,</span> <span class="n">p_val_np</span></div>

<div class="viewcode-block" id="get_temporal_data">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.get_temporal_data">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_temporal_data</span><span class="p">(</span><span class="n">x_norm</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">l_segs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">l_window</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Internal helper function to create windowed sequence temporal data from</span>
<span class="sd">    original data. Adds padding to beginning of data. Uses line lengths to avoid</span>
<span class="sd">    windowing across lines, but (ad hoc) checks if any lines may be sequential.</span>

<span class="sd">    Args:</span>
<span class="sd">        x_norm:   Nf x N normalized data matrix (Nf is number of features)</span>
<span class="sd">        l_segs:   length-N_lines vector of lengths of lines, sum(l_segs) = N</span>
<span class="sd">        l_window: temporal window length</span>

<span class="sd">    Returns:</span>
<span class="sd">        x_w: Nf x l_window x N normalized data matrix, windowed</span>
<span class="sd">             (Note: PyTorch LSTMs/Transformers often expect seq_len first or batch first,</span>
<span class="sd">              so further permutation might be needed depending on the model layer)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nf</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">=</span> <span class="n">x_norm</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># number of features &amp; samples (instances)</span>

    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span> <span class="o">!=</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;sum of lines = </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">l_segs</span><span class="p">:</span> <span class="c1"># Handle case with no segments</span>
        <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">l_window</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># If there&#39;s data but no segments, treat as one segment</span>
            <span class="n">l_segs_processed</span> <span class="o">=</span> <span class="p">[</span><span class="n">n_samples</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># No data or no window, return empty or appropriately shaped array</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nf</span><span class="p">,</span> <span class="n">l_window</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x_norm</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">l_segs_processed</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span> <span class="c1"># Make a mutable copy</span>

    <span class="c1"># Ad-hoc check for sequential lines (simplified from Julia&#39;s std check)</span>
    <span class="c1"># This part is tricky to translate directly without knowing the exact data characteristics</span>
    <span class="c1"># and the intent of `std(x_norm[:,l]-x_norm[:,l+1]) &lt; lim`.</span>
    <span class="c1"># For now, we&#39;ll skip the merging of segments based on this ad-hoc check,</span>
    <span class="c1"># as it might require more domain-specific knowledge or a clearer metric.</span>
    <span class="c1"># If this merging is critical, a more robust Python equivalent would be needed.</span>
    <span class="c1"># Julia code for merging:</span>
    <span class="c1"># if len(l_segs) &gt; 1:</span>
    <span class="c1">#     l0 = np.cumsum(l_segs)[:-1]</span>
    <span class="c1">#     lim = 0.25 # ad hoc</span>
    <span class="c1">#     # ind = [np.std(x_norm[:,l] - x_norm[:,l+1]) &lt; lim for l in l0] # Direct translation problematic</span>
    <span class="c1">#     # Simplified: assume segments are distinct unless explicitly told otherwise</span>
    <span class="c1">#     l_segs_ = list(l_segs) # mutable copy</span>
    <span class="c1">#     # ... merging logic based on &#39;ind&#39; ...</span>
    <span class="c1">#     l_segs_processed = [s for s in l_segs_ if s != 0]</span>

    <span class="n">current_l_segs</span> <span class="o">=</span> <span class="n">l_segs_processed</span>
    
    <span class="c1"># Correctly calculate cumulative sums for 0-indexed Python</span>
    <span class="c1"># l0_ = [0] + np.cumsum(current_l_segs[:-1]).tolist() if len(current_l_segs) &gt; 1 else [0]</span>
    <span class="c1"># A simpler way for segment start indices:</span>
    <span class="n">segment_starts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_l_segs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_l_segs</span><span class="p">)):</span>
        <span class="n">segment_starts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">segment_starts</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">current_l_segs</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">x_w_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">seg_idx</span><span class="p">,</span> <span class="n">n_seg_samples</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">current_l_segs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">n_seg_samples</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">x_w_segment</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nf</span><span class="p">,</span> <span class="n">l_window</span><span class="p">,</span> <span class="n">n_seg_samples</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x_norm</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">seg_start_abs_idx</span> <span class="o">=</span> <span class="n">segment_starts</span><span class="p">[</span><span class="n">seg_idx</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">j_in_seg</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_seg_samples</span><span class="p">):</span> <span class="c1"># 0 to n_seg_samples-1</span>
            <span class="c1"># j_in_seg is the current point in the segment</span>
            <span class="c1"># We want to create a window of l_window points ending at j_in_seg</span>

            <span class="c1"># Determine the start of the window in the current segment</span>
            <span class="n">window_start_in_seg</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">j_in_seg</span> <span class="o">-</span> <span class="n">l_window</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># Determine how many actual data points we can take for this window</span>
            <span class="n">num_actual_points</span> <span class="o">=</span> <span class="n">j_in_seg</span> <span class="o">-</span> <span class="n">window_start_in_seg</span> <span class="o">+</span> <span class="mi">1</span>
            
            <span class="c1"># Determine padding needed at the beginning of the window</span>
            <span class="n">num_padding_points</span> <span class="o">=</span> <span class="n">l_window</span> <span class="o">-</span> <span class="n">num_actual_points</span>

            <span class="c1"># Fill padding (if any)</span>
            <span class="c1"># In Julia, padding was with x_norm[:, l0_[i] .+ (j1)], which is the first element of the window.</span>
            <span class="c1"># Replicating this:</span>
            <span class="n">first_val_for_padding</span> <span class="o">=</span> <span class="n">x_norm</span><span class="p">[:,</span> <span class="n">seg_start_abs_idx</span> <span class="o">+</span> <span class="n">window_start_in_seg</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">k_pad</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_padding_points</span><span class="p">):</span>
                <span class="n">x_w_segment</span><span class="p">[:,</span> <span class="n">k_pad</span><span class="p">,</span> <span class="n">j_in_seg</span><span class="p">]</span> <span class="o">=</span> <span class="n">first_val_for_padding</span>

            <span class="c1"># Fill actual data</span>
            <span class="k">for</span> <span class="n">k_data</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_actual_points</span><span class="p">):</span>
                <span class="n">src_idx_in_x_norm</span> <span class="o">=</span> <span class="n">seg_start_abs_idx</span> <span class="o">+</span> <span class="n">window_start_in_seg</span> <span class="o">+</span> <span class="n">k_data</span>
                <span class="n">dest_idx_in_window</span> <span class="o">=</span> <span class="n">num_padding_points</span> <span class="o">+</span> <span class="n">k_data</span>
                <span class="n">x_w_segment</span><span class="p">[:,</span> <span class="n">dest_idx_in_window</span><span class="p">,</span> <span class="n">j_in_seg</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_norm</span><span class="p">[:,</span> <span class="n">src_idx_in_x_norm</span><span class="p">]</span>
                
        <span class="n">x_w_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_w_segment</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">x_w_list</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nf</span><span class="p">,</span> <span class="n">l_window</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x_norm</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">x_w_list</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span></div>


<div class="viewcode-block" id="sparse_group_lasso">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.sparse_group_lasso">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">sparse_group_lasso</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the Sparse Group Lasso (SGL) penalty term for a PyTorch model.</span>
<span class="sd">    The penalty is calculated as: alpha * L1_norm + (1-alpha) * L2_norm_group_wise</span>
<span class="sd">    This function sums this term over all nn.Linear layers&#39; weights.</span>
<span class="sd">    The overall regularization strength (lambda_sgl) should be applied multiplicatively</span>
<span class="sd">    to the output of this function.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (nn.Module): The neural network model (typically an nn.Sequential containing nn.Linear layers).</span>
<span class="sd">        alpha (float): The mixing parameter between L1 and L2 norms.</span>
<span class="sd">                       alpha=1 gives Lasso, alpha=0 gives Group Lasso (L2 on layer weights).</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The SGL penalty value (scalar tensor).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sgl_penalty</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    
    <span class="n">has_linear_layers</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="c1"># Iterate through modules of the model to find Linear layers</span>
    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
            <span class="n">has_linear_layers</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="c1"># Ensure the layer has a weight parameter</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span>
                
                <span class="c1"># L1 norm of all weights in the layer</span>
                <span class="n">l1_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                
                <span class="c1"># L2 norm of all weights in the layer (this acts as the group L2 norm)</span>
                <span class="n">l2_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                
                <span class="c1"># Add to total SGL penalty</span>
                <span class="n">sgl_penalty</span> <span class="o">+=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">l1_term</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">l2_term</span>
            
            <span class="c1"># Biases are typically not included in SGL or regularized differently.</span>
            <span class="c1"># If biases were to be included, similar logic for module.bias would be added.</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">has_linear_layers</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">SILENT_DEBUG</span><span class="p">:</span>
        <span class="c1"># This warning can be enhanced with a proper logging system if available.</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: sparse_group_lasso was called on a model that does not appear to contain nn.Linear layers. The SGL penalty will be 0.&quot;</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">sgl_penalty</span></div>


<div class="viewcode-block" id="err_segs">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.err_segs">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">err_segs</span><span class="p">(</span><span class="n">y_hat</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">l_segs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for calculating error, possibly mean-corrected per segment.&quot;&quot;&quot;</span>
    <span class="c1"># Simplified: just difference. Actual might involve detrending per segment.</span>
    <span class="n">current_pos</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_hat_flat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">y_flat</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">seg_len</span> <span class="ow">in</span> <span class="n">l_segs</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">seg_len</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">continue</span>
        <span class="n">y_hat_segment</span> <span class="o">=</span> <span class="n">y_hat_flat</span><span class="p">[</span><span class="n">current_pos</span> <span class="p">:</span> <span class="n">current_pos</span> <span class="o">+</span> <span class="n">seg_len</span><span class="p">]</span>
        <span class="n">y_segment</span> <span class="o">=</span> <span class="n">y_flat</span><span class="p">[</span><span class="n">current_pos</span> <span class="p">:</span> <span class="n">current_pos</span> <span class="o">+</span> <span class="n">seg_len</span><span class="p">]</span>
        
        <span class="c1"># Example: mean correction per segment</span>
        <span class="n">err_segment</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_segment</span> <span class="o">-</span> <span class="n">y_hat_segment</span><span class="p">)</span>
        <span class="n">err_segment</span> <span class="o">=</span> <span class="n">err_segment</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">err_segment</span><span class="p">)</span>
        <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err_segment</span><span class="p">)</span>
        <span class="n">current_pos</span> <span class="o">+=</span> <span class="n">seg_len</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">errors</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">y_hat</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span></div>



<div class="viewcode-block" id="create_TL_A">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.create_TL_A">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">create_TL_A</span><span class="p">(</span><span class="n">vec_mag_data</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">ind</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">terms</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">return_B</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for creating Tolles-Lawson A matrix.&quot;&quot;&quot;</span>
    <span class="c1"># vec_mag_data: N x 3 (flux_a, flux_b, flux_c)</span>
    <span class="c1"># ind: indices to select from vec_mag_data</span>
    <span class="c1"># terms: list of TL terms like &#39;permanent&#39;, &#39;induced&#39;, &#39;eddy&#39;</span>
    <span class="c1"># kwargs: Bt (scalar total field), etc.</span>
    
    <span class="c1"># Robust handling of &#39;ind&#39; for selecting data</span>
    <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span> <span class="c1"># Convert to numpy array to safely check size and handle lists</span>
        <span class="k">if</span> <span class="n">_ind</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">selected_data</span> <span class="o">=</span> <span class="n">vec_mag_data</span><span class="p">[</span><span class="n">_ind</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># ind was provided but resulted in an empty selection (e.g., empty list or array)</span>
            <span class="n">selected_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">vec_mag_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">vec_mag_data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># ind is None, use all data</span>
        <span class="n">selected_data</span> <span class="o">=</span> <span class="n">vec_mag_data</span>
    
    <span class="k">if</span> <span class="n">selected_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Return empty arrays with expected number of columns based on terms</span>
        <span class="n">num_cols</span> <span class="o">=</span> <span class="mi">18</span> <span class="c1"># Default for full TL model</span>
        <span class="c1"># A more robust way to determine num_cols is needed if this path is critical</span>
        <span class="k">if</span> <span class="n">terms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">terms</span> <span class="o">==</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">,</span> <span class="s2">&quot;induced&quot;</span><span class="p">,</span> <span class="s2">&quot;eddy&quot;</span><span class="p">]:</span> <span class="n">num_cols</span> <span class="o">=</span> <span class="mi">18</span>
            <span class="k">elif</span> <span class="n">terms</span> <span class="o">==</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">,</span> <span class="s2">&quot;induced&quot;</span><span class="p">]:</span> <span class="n">num_cols</span> <span class="o">=</span> <span class="mi">9</span>
            <span class="k">elif</span> <span class="n">terms</span> <span class="o">==</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">]:</span> <span class="n">num_cols</span> <span class="o">=</span> <span class="mi">3</span>
            <span class="c1"># Add other specific combinations or a more generic calculation</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># Fallback, very rough estimate</span>
                <span class="n">base_cols</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">if</span> <span class="s2">&quot;permanent&quot;</span> <span class="ow">in</span> <span class="n">terms</span><span class="p">:</span> <span class="n">base_cols</span> <span class="o">+=</span> <span class="mi">3</span>
                <span class="k">if</span> <span class="s2">&quot;induced&quot;</span> <span class="ow">in</span> <span class="n">terms</span><span class="p">:</span> <span class="n">base_cols</span> <span class="o">+=</span> <span class="mi">5</span> <span class="c1"># Assuming 5 for symmetric tensor</span>
                <span class="k">if</span> <span class="s2">&quot;eddy&quot;</span> <span class="ow">in</span> <span class="n">terms</span><span class="p">:</span> <span class="n">base_cols</span> <span class="o">+=</span> <span class="mi">9</span> <span class="c1"># Assuming 9 for eddy current terms</span>
                <span class="k">if</span> <span class="n">base_cols</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">num_cols</span> <span class="o">=</span> <span class="n">base_cols</span>
                <span class="c1"># If terms are unknown or don&#39;t match, 18 is a guess or could be more dynamic.</span>
        
        <span class="n">A_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">selected_data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">Bt_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">selected_data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">B_dot_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">selected_data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># Assuming B_dot is N x 3</span>
        <span class="k">if</span> <span class="n">return_B</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">A_matrix</span><span class="p">,</span> <span class="n">Bt_out</span><span class="p">,</span> <span class="n">B_dot_out</span>
        <span class="k">return</span> <span class="n">A_matrix</span>

    <span class="c1"># Placeholder A_matrix construction. A real implementation would use &#39;terms&#39;.</span>
    <span class="c1"># For this placeholder, if &#39;permanent&#39; is in terms, use the first 3 cols of selected_data.</span>
    <span class="c1"># This is a very simplified placeholder.</span>
    <span class="k">if</span> <span class="n">terms</span> <span class="ow">and</span> <span class="s2">&quot;permanent&quot;</span> <span class="ow">in</span> <span class="n">terms</span> <span class="ow">and</span> <span class="n">selected_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span><span class="mi">3</span> <span class="p">:</span>
         <span class="n">A_matrix</span> <span class="o">=</span> <span class="n">selected_data</span><span class="p">[:,:</span><span class="mi">3</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">selected_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># Fallback to using selected_data if it has columns</span>
         <span class="n">A_matrix</span> <span class="o">=</span> <span class="n">selected_data</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># selected_data is empty or has no columns, A_matrix should match num_cols logic from above</span>
        <span class="n">num_cols_fallback</span> <span class="o">=</span> <span class="mi">18</span> <span class="c1"># Default if terms is None or doesn&#39;t define structure</span>
        <span class="k">if</span> <span class="n">terms</span><span class="p">:</span> <span class="c1"># Try to infer from terms again if needed</span>
            <span class="k">if</span> <span class="n">terms</span> <span class="o">==</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">,</span> <span class="s2">&quot;induced&quot;</span><span class="p">,</span> <span class="s2">&quot;eddy&quot;</span><span class="p">]:</span> <span class="n">num_cols_fallback</span> <span class="o">=</span> <span class="mi">18</span>
            <span class="k">elif</span> <span class="n">terms</span> <span class="o">==</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">,</span> <span class="s2">&quot;induced&quot;</span><span class="p">]:</span> <span class="n">num_cols_fallback</span> <span class="o">=</span> <span class="mi">9</span>
            <span class="k">elif</span> <span class="n">terms</span> <span class="o">==</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">]:</span> <span class="n">num_cols_fallback</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">A_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">selected_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_cols_fallback</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">selected_data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>


    <span class="n">Bt_out_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">selected_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">selected_data</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">selected_data</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">selected_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span><span class="mi">3</span> <span class="p">:</span> <span class="c1"># Check if selected_data has at least 3 columns for norm</span>
        <span class="n">Bt_out_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">selected_data</span><span class="p">[:,:</span><span class="mi">3</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">B_dot_out_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">selected_data</span><span class="p">)</span> <span class="c1"># Placeholder, should be (N,3)</span>
    <span class="k">if</span> <span class="n">selected_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">selected_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span><span class="mi">3</span><span class="p">:</span> <span class="c1"># Can only compute gradient if more than 1 sample</span>
        <span class="n">dt_val</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dt_val</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span> <span class="n">dt_val</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="n">B_dot_out_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">selected_data</span><span class="p">[:,:</span><span class="mi">3</span><span class="p">],</span> <span class="n">dt_val</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_B</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">A_matrix</span><span class="p">,</span> <span class="n">Bt_out_val</span><span class="p">,</span> <span class="n">B_dot_out_val</span>
    <span class="k">return</span> <span class="n">A_matrix</span></div>



<div class="viewcode-block" id="get_TL_term_ind">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.get_TL_term_ind">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_TL_term_ind</span><span class="p">(</span><span class="n">term</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">terms_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder: Get indices for a specific TL term in the A matrix.&quot;&quot;&quot;</span>
    <span class="c1"># This depends on the fixed order of terms in create_TL_A</span>
    <span class="c1"># Example: if terms_list = [&#39;permanent&#39;, &#39;induced&#39;, &#39;eddy&#39;]</span>
    <span class="c1"># and &#39;permanent&#39; corresponds to first 3 columns, &#39;induced&#39; next 6, &#39;eddy&#39; next 9</span>
    <span class="k">if</span> <span class="n">term</span> <span class="o">==</span> <span class="s2">&quot;permanent&quot;</span><span class="p">:</span> <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span><span class="o">*</span><span class="mi">15</span><span class="p">)</span> <span class="c1"># if 18 terms total</span>
    <span class="c1"># This is highly dependent on the actual structure of A matrix from create_TL_A</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="mi">18</span><span class="p">)</span> <span class="c1"># Default to no match</span></div>

<div class="viewcode-block" id="TL_vec_split">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.TL_vec_split">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">TL_vec_split</span><span class="p">(</span><span class="n">TL_coef</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">terms</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Internal helper function to separate Tolles-Lawson coefficients from a single</span>
<span class="sd">    vector to individual permanent, induced, &amp; eddy current coefficient vectors.</span>

<span class="sd">    Args:</span>
<span class="sd">        TL_coef: Tolles-Lawson coefficients (must include &#39;permanent&#39; &amp; &#39;induced&#39;)</span>
<span class="sd">        terms:   Tolles-Lawson terms used {&#39;permanent&#39;,&#39;induced&#39;,&#39;eddy&#39;, </span>
<span class="sd">                     &#39;p&#39;,&#39;i&#39;,&#39;e&#39;, &#39;permanent3&#39;, &#39;p3&#39;,</span>
<span class="sd">                     &#39;induced6&#39;, &#39;i6&#39;, &#39;induced5&#39;, &#39;i5&#39;, &#39;induced3&#39;, &#39;i3&#39;,</span>
<span class="sd">                     &#39;eddy9&#39;, &#39;e9&#39;, &#39;eddy8&#39;, &#39;e8&#39;, &#39;eddy3&#39;, &#39;e3&#39;}</span>
<span class="sd">    Returns:</span>
<span class="sd">        TL_p: length-3 vector of permanent field coefficients</span>
<span class="sd">        TL_i: length-3, 5, or 6 vector of induced field coefficients</span>
<span class="sd">        TL_e: length-0, 3, 8, or 9 vector of eddy current coefficients</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Simplified term checking for Python</span>
    <span class="n">has_permanent</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">,</span> <span class="s2">&quot;p&quot;</span><span class="p">,</span> <span class="s2">&quot;permanent3&quot;</span><span class="p">,</span> <span class="s2">&quot;p3&quot;</span><span class="p">])</span>
    <span class="n">has_induced</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;induced&quot;</span><span class="p">,</span> <span class="s2">&quot;i&quot;</span><span class="p">,</span> <span class="s2">&quot;induced6&quot;</span><span class="p">,</span> <span class="s2">&quot;i6&quot;</span><span class="p">,</span> <span class="s2">&quot;induced5&quot;</span><span class="p">,</span> <span class="s2">&quot;i5&quot;</span><span class="p">,</span> <span class="s2">&quot;induced3&quot;</span><span class="p">,</span> <span class="s2">&quot;i3&quot;</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">has_permanent</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Permanent terms are required in TL_vec_split&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">has_induced</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Induced terms are required in TL_vec_split&quot;</span><span class="p">)</span>
    
    <span class="c1"># Check for disallowed terms (simplified)</span>
    <span class="n">disallowed_terms</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fdm&quot;</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">,</span> <span class="s2">&quot;fdm3&quot;</span><span class="p">,</span> <span class="s2">&quot;f3&quot;</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">disallowed_terms</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Derivative &amp; bias terms may not be used in TL_vec_split&quot;</span><span class="p">)</span>

    <span class="c1"># This assertion is harder to replicate directly without calling create_TL_A</span>
    <span class="c1"># A_test = create_TL_A(np.array([[1.0,1.0,1.0]]), terms=terms) # Assuming create_TL_A is available and works</span>
    <span class="c1"># if TL_coef.size != A_test.shape[1]:</span>
    <span class="c1">#     raise ValueError(&quot;TL_coef does not agree with specified terms&quot;)</span>

    <span class="n">current_idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">TL_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">TL_coef</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">TL_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">TL_coef</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">TL_e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">TL_coef</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="c1"># Permanent terms (always 3)</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">,</span> <span class="s2">&quot;p&quot;</span><span class="p">,</span> <span class="s2">&quot;permanent3&quot;</span><span class="p">,</span> <span class="s2">&quot;p3&quot;</span><span class="p">]):</span>
        <span class="n">TL_p</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">3</span>
    
    <span class="c1"># Induced terms</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;induced&quot;</span><span class="p">,</span> <span class="s2">&quot;i&quot;</span><span class="p">,</span> <span class="s2">&quot;induced6&quot;</span><span class="p">,</span> <span class="s2">&quot;i6&quot;</span><span class="p">]):</span>
        <span class="n">TL_i</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">6</span><span class="p">]</span>
        <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">6</span>
    <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;induced5&quot;</span><span class="p">,</span> <span class="s2">&quot;i5&quot;</span><span class="p">]):</span>
        <span class="n">TL_i</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">5</span><span class="p">]</span>
        <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">5</span>
    <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;induced3&quot;</span><span class="p">,</span> <span class="s2">&quot;i3&quot;</span><span class="p">]):</span>
        <span class="n">TL_i</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">3</span>
        
    <span class="c1"># Eddy terms (these come last, so we can infer from remaining length)</span>
    <span class="c1"># This logic assumes permanent and induced terms are always first and in that order.</span>
    <span class="n">remaining_coeffs</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="n">current_idx</span>
    
    <span class="k">if</span> <span class="n">remaining_coeffs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;eddy&quot;</span><span class="p">,</span> <span class="s2">&quot;e&quot;</span><span class="p">,</span> <span class="s2">&quot;eddy9&quot;</span><span class="p">,</span> <span class="s2">&quot;e9&quot;</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">remaining_coeffs</span> <span class="o">==</span> <span class="mi">9</span><span class="p">:</span> <span class="c1"># Check if it matches expected size</span>
                <span class="n">TL_e</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">9</span><span class="p">]</span>
                <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">9</span>
            <span class="c1"># else: warning or error if size mismatch</span>
        <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;eddy8&quot;</span><span class="p">,</span> <span class="s2">&quot;e8&quot;</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">remaining_coeffs</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
                <span class="n">TL_e</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">8</span><span class="p">]</span>
                <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">8</span>
        <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;eddy3&quot;</span><span class="p">,</span> <span class="s2">&quot;e3&quot;</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">remaining_coeffs</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">TL_e</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">3</span><span class="p">]</span>
                <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">3</span>
        <span class="c1"># If no specific eddy term matches but there are remaining coeffs,</span>
        <span class="c1"># it implies a mismatch or an unhandled term combination.</span>
        <span class="c1"># For robustness, one might assign remaining to TL_e or raise error.</span>
        <span class="c1"># Based on Julia, if specific eddy terms are not present, TL_e is empty.</span>
        <span class="c1"># So, only assign if a recognized eddy term is present AND size matches.</span>

    <span class="k">if</span> <span class="n">current_idx</span> <span class="o">!=</span> <span class="n">TL_coef</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
        <span class="c1"># This implies a mismatch between the sum of expected term lengths and TL_coef.size</span>
        <span class="n">has_eddy_term_spec</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;eddy&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">t</span> <span class="o">==</span> <span class="s2">&quot;e&quot;</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">remaining_coeffs</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">has_eddy_term_spec</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">SILENT_DEBUG</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TL_vec_split: </span><span class="si">{</span><span class="n">remaining_coeffs</span><span class="si">}</span><span class="s2"> coefficients remain but no eddy term specified in &#39;terms&#39;.&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">remaining_coeffs</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">has_eddy_term_spec</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">TL_e</span><span class="o">.</span><span class="n">size</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">SILENT_DEBUG</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TL_vec_split: Eddy term specified in &#39;terms&#39; but no/mismatched coefficients found for it.&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">current_idx</span> <span class="o">&lt;</span> <span class="n">TL_coef</span><span class="o">.</span><span class="n">size</span> <span class="ow">and</span> <span class="n">has_eddy_term_spec</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">TL_e</span><span class="o">.</span><span class="n">size</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">SILENT_DEBUG</span><span class="p">:</span>
             <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TL_vec_split: Eddy term specified, but remaining_coeffs (</span><span class="si">{</span><span class="n">remaining_coeffs</span><span class="si">}</span><span class="s2">) did not match expected size for any known eddy term type.&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">SILENT_DEBUG</span> <span class="p">:</span> <span class="c1"># General mismatch</span>
             <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TL_vec_split: Coefficient parsing mismatch. Expected to parse </span><span class="si">{</span><span class="n">TL_coef</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2">, but parsed </span><span class="si">{</span><span class="n">current_idx</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">TL_p</span><span class="p">,</span> <span class="n">TL_i</span><span class="p">,</span> <span class="n">TL_e</span></div>

<div class="viewcode-block" id="TL_vec2mat">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.TL_vec2mat">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">TL_vec2mat</span><span class="p">(</span><span class="n">TL_coef</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">terms</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Bt_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">50000.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract the matrix form of Tolles-Lawson coefficients from the vector form.</span>

<span class="sd">    Args:</span>
<span class="sd">        TL_coef:  Tolles-Lawson coefficients (must include &#39;permanent&#39; &amp; &#39;induced&#39;)</span>
<span class="sd">        terms:    Tolles-Lawson terms used {&#39;permanent&#39;,&#39;induced&#39;,&#39;eddy&#39;, ...}</span>
<span class="sd">        Bt_scale: (optional) scaling factor for induced &amp; eddy current terms [nT]</span>

<span class="sd">    Returns:</span>
<span class="sd">        TL_coef_p: length-3 vector of permanent field coefficients</span>
<span class="sd">        TL_coef_i: 3x3 symmetric matrix of induced field coefficients, denormalized</span>
<span class="sd">        TL_coef_e: 3x3 matrix of eddy current coefficients, denormalized</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">has_permanent</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">,</span> <span class="s2">&quot;p&quot;</span><span class="p">,</span> <span class="s2">&quot;permanent3&quot;</span><span class="p">,</span> <span class="s2">&quot;p3&quot;</span><span class="p">])</span>
    <span class="n">has_induced</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;induced&quot;</span><span class="p">,</span> <span class="s2">&quot;i&quot;</span><span class="p">,</span> <span class="s2">&quot;induced6&quot;</span><span class="p">,</span> <span class="s2">&quot;i6&quot;</span><span class="p">,</span> <span class="s2">&quot;induced5&quot;</span><span class="p">,</span> <span class="s2">&quot;i5&quot;</span><span class="p">,</span> <span class="s2">&quot;induced3&quot;</span><span class="p">,</span> <span class="s2">&quot;i3&quot;</span><span class="p">])</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">has_permanent</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Permanent terms are required in TL_vec2mat&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">has_induced</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Induced terms are required in TL_vec2mat&quot;</span><span class="p">)</span>

    <span class="n">disallowed_terms</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fdm&quot;</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">,</span> <span class="s2">&quot;fdm3&quot;</span><span class="p">,</span> <span class="s2">&quot;f3&quot;</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">disallowed_terms</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Derivative &amp; bias terms may not be used in TL_vec2mat&quot;</span><span class="p">)</span>

    <span class="c1"># Placeholder for A_test assertion if create_TL_A is fully implemented and available</span>
    <span class="c1"># A_test = create_TL_A(np.array([[1.0,1.0,1.0]]), terms=terms)</span>
    <span class="c1"># if TL_coef.size != A_test.shape[1]:</span>
    <span class="c1">#     raise ValueError(&quot;TL_coef does not agree with specified terms in TL_vec2mat&quot;)</span>

    <span class="n">current_idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">TL_coef_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">TL_coef</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">TL_coef_i_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">TL_coef</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">TL_coef_e_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">TL_coef</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># Initialize as empty or zero</span>

    <span class="c1"># Permanent terms</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">,</span> <span class="s2">&quot;p&quot;</span><span class="p">,</span> <span class="s2">&quot;permanent3&quot;</span><span class="p">,</span> <span class="s2">&quot;p3&quot;</span><span class="p">]):</span>
        <span class="n">TL_coef_p</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">3</span>
    
    <span class="c1"># Induced terms</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;induced&quot;</span><span class="p">,</span> <span class="s2">&quot;i&quot;</span><span class="p">,</span> <span class="s2">&quot;induced6&quot;</span><span class="p">,</span> <span class="s2">&quot;i6&quot;</span><span class="p">]):</span>
        <span class="n">TL_i_vec</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">6</span><span class="p">]</span>
        <span class="n">TL_coef_i_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
            <span class="p">[</span><span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">],</span>
            <span class="p">[</span><span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>   <span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">],</span>
            <span class="p">[</span><span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">5</span><span class="p">]]</span>
        <span class="p">])</span> <span class="o">/</span> <span class="n">Bt_scale</span>
        <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">6</span>
    <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;induced5&quot;</span><span class="p">,</span> <span class="s2">&quot;i5&quot;</span><span class="p">]):</span>
        <span class="n">TL_i_vec</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">5</span><span class="p">]</span>
        <span class="n">TL_coef_i_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
            <span class="p">[</span><span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">],</span>
            <span class="p">[</span><span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>   <span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">],</span>
            <span class="p">[</span><span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">TL_i_vec</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span> <span class="c1"># Assuming M_33 = 0 for 5-term model</span>
        <span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">Bt_scale</span> <span class="k">if</span> <span class="n">Bt_scale</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="c1"># Ensure symmetry for the 5-term case if it&#39;s not inherently symmetric from vector</span>
        <span class="n">TL_coef_i_mat</span> <span class="o">=</span> <span class="p">(</span><span class="n">TL_coef_i_mat</span> <span class="o">+</span> <span class="n">TL_coef_i_mat</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">/</span><span class="mf">2.0</span>
        <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># Explicitly set (3,3) to 0 for 5-term model</span>
        <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">5</span>
    <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;induced3&quot;</span><span class="p">,</span> <span class="s2">&quot;i3&quot;</span><span class="p">]):</span>
        <span class="n">TL_i_vec</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">TL_coef_i_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">TL_i_vec</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">Bt_scale</span> <span class="k">if</span> <span class="n">Bt_scale</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">3</span>

    <span class="c1"># Eddy terms</span>
    <span class="n">remaining_coeffs</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="n">current_idx</span>
    <span class="k">if</span> <span class="n">remaining_coeffs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;eddy&quot;</span><span class="p">,</span> <span class="s2">&quot;e&quot;</span><span class="p">,</span> <span class="s2">&quot;eddy9&quot;</span><span class="p">,</span> <span class="s2">&quot;e9&quot;</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">remaining_coeffs</span> <span class="o">==</span> <span class="mi">9</span><span class="p">:</span>
                <span class="n">TL_e_vec</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">9</span><span class="p">]</span>
                <span class="c1"># Julia stores vec(M&#39;), so reshape TL_e_vec (9 elements) to 3x3 column-major, then transpose.</span>
                <span class="c1"># Or, reshape row-major (default in numpy) and then transpose.</span>
                <span class="n">TL_coef_e_mat</span> <span class="o">=</span> <span class="n">TL_e_vec</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="p">(</span><span class="n">Bt_scale</span> <span class="k">if</span> <span class="n">Bt_scale</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">9</span>
        <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;eddy8&quot;</span><span class="p">,</span> <span class="s2">&quot;e8&quot;</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">remaining_coeffs</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span> <span class="c1"># Corrected indentation</span>
                <span class="n">TL_e_vec</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">8</span><span class="p">]</span>
                <span class="c1"># Construct 3x3 matrix, assuming last element of vec(M&#39;) is zero</span>
                <span class="n">temp_mat_flat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">TL_e_vec</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="n">temp_mat_flat</span><span class="p">[:</span><span class="mi">8</span><span class="p">]</span> <span class="o">=</span> <span class="n">TL_e_vec</span>
                <span class="n">TL_coef_e_mat</span> <span class="o">=</span> <span class="n">temp_mat_flat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="p">(</span><span class="n">Bt_scale</span> <span class="k">if</span> <span class="n">Bt_scale</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">8</span>
        <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;eddy3&quot;</span><span class="p">,</span> <span class="s2">&quot;e3&quot;</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">remaining_coeffs</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">TL_e_vec</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="p">[</span><span class="n">current_idx</span> <span class="p">:</span> <span class="n">current_idx</span><span class="o">+</span><span class="mi">3</span><span class="p">]</span>
                <span class="n">TL_coef_e_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">TL_e_vec</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">Bt_scale</span> <span class="k">if</span> <span class="n">Bt_scale</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="n">current_idx</span> <span class="o">+=</span> <span class="mi">3</span>
        <span class="c1"># If no specific eddy term is listed but coeffs remain, TL_coef_e_mat remains zero/empty</span>
        <span class="c1"># as per Julia&#39;s behavior (TL_e = [] if no eddy terms).</span>

    <span class="c1"># Final check, similar to TL_vec_split</span>
    <span class="c1"># if current_idx != TL_coef.size:</span>
    <span class="c1">#     # Potentially raise an error or warning if not all coefficients were consumed</span>
    <span class="c1">#     # and it doesn&#39;t align with an expectation of no eddy terms.</span>
    <span class="c1">#     pass</span>

    <span class="k">return</span> <span class="n">TL_coef_p</span><span class="p">,</span> <span class="n">TL_coef_i_mat</span><span class="p">,</span> <span class="n">TL_coef_e_mat</span></div>

<div class="viewcode-block" id="TL_mat2vec">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.TL_mat2vec">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">TL_mat2vec</span><span class="p">(</span><span class="n">TL_coef_p</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">TL_coef_i_mat</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">TL_coef_e_mat</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
               <span class="n">terms</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Bt_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">50000.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract the vector form of Tolles-Lawson coefficients from the matrix form.</span>

<span class="sd">    Args:</span>
<span class="sd">        TL_coef_p:     length-3 vector of permanent field coefficients</span>
<span class="sd">        TL_coef_i_mat: 3x3 symmetric matrix of induced field coefficients, denormalized</span>
<span class="sd">        TL_coef_e_mat: 3x3 matrix of eddy current coefficients, denormalized</span>
<span class="sd">        terms:         Tolles-Lawson terms used {&#39;permanent&#39;,&#39;induced&#39;,&#39;eddy&#39;, ...}</span>
<span class="sd">        Bt_scale:      (optional) scaling factor for induced &amp; eddy current terms [nT]</span>

<span class="sd">    Returns:</span>
<span class="sd">        TL_coef: Tolles-Lawson coefficients as a single vector</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">TL_coef_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Permanent terms (always present and first)</span>
    <span class="n">TL_coef_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TL_coef_p</span><span class="p">)</span>

    <span class="c1"># Induced terms</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;induced&quot;</span><span class="p">,</span> <span class="s2">&quot;i&quot;</span><span class="p">,</span> <span class="s2">&quot;induced6&quot;</span><span class="p">,</span> <span class="s2">&quot;i6&quot;</span><span class="p">]):</span>
        <span class="c1"># From matrix: [a b c; b d e; c e f] -&gt; [a, 2b, 2c, d, 2e, f] (scaled)</span>
        <span class="c1"># Indices for upper triangle (including diagonal): (0,0), (0,1), (0,2), (1,1), (1,2), (2,2)</span>
        <span class="n">i_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> 
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> 
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> 
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
        <span class="p">])</span> <span class="o">*</span> <span class="n">Bt_scale</span>
        <span class="n">TL_coef_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i_vec</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;induced5&quot;</span><span class="p">,</span> <span class="s2">&quot;i5&quot;</span><span class="p">]):</span>
        <span class="c1"># Matrix form assumed [a b c; b d e; c e 0] -&gt; [a, 2b, 2c, d, 2e]</span>
        <span class="n">i_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> 
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> 
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> 
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span>
        <span class="p">])</span> <span class="o">*</span> <span class="n">Bt_scale</span>
        <span class="n">TL_coef_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i_vec</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;induced3&quot;</span><span class="p">,</span> <span class="s2">&quot;i3&quot;</span><span class="p">]):</span>
        <span class="c1"># Matrix form assumed [a 0 0; 0 d 0; 0 0 f] -&gt; [a, d, f]</span>
        <span class="n">i_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> 
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> 
            <span class="n">TL_coef_i_mat</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
        <span class="p">])</span> <span class="o">*</span> <span class="n">Bt_scale</span>
        <span class="n">TL_coef_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i_vec</span><span class="p">)</span>
    <span class="c1"># If no induced terms specified, nothing is added for TL_i</span>

    <span class="c1"># Eddy terms</span>
    <span class="n">_Bt_scale_eff</span> <span class="o">=</span> <span class="n">Bt_scale</span> <span class="k">if</span> <span class="n">Bt_scale</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span>
    <span class="k">if</span> <span class="n">TL_coef_e_mat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">TL_coef_e_mat</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># Check if e_mat is provided</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;eddy&quot;</span><span class="p">,</span> <span class="s2">&quot;e&quot;</span><span class="p">,</span> <span class="s2">&quot;eddy9&quot;</span><span class="p">,</span> <span class="s2">&quot;e9&quot;</span><span class="p">]):</span>
            <span class="n">TL_coef_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TL_coef_e_mat</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">*</span> <span class="n">_Bt_scale_eff</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;eddy8&quot;</span><span class="p">,</span> <span class="s2">&quot;e8&quot;</span><span class="p">]):</span>
            <span class="n">TL_coef_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TL_coef_e_mat</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[:</span><span class="mi">8</span><span class="p">]</span> <span class="o">*</span> <span class="n">_Bt_scale_eff</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">any</span><span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">terms</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;eddy3&quot;</span><span class="p">,</span> <span class="s2">&quot;e3&quot;</span><span class="p">]):</span>
            <span class="n">TL_coef_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">TL_coef_e_mat</span><span class="p">)</span> <span class="o">*</span> <span class="n">_Bt_scale_eff</span><span class="p">)</span>
    <span class="c1"># If no eddy terms specified, TL_e remains empty / nothing added</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">TL_coef_list</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">TL_coef_p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">TL_coef_list</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">TL_coef_p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span></div>

<div class="viewcode-block" id="get_TL_aircraft_vec">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.get_TL_aircraft_vec">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_TL_aircraft_vec</span><span class="p">(</span>
    <span class="n">B_vec</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">B_vec_dot</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">TL_coef_p</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">TL_coef_i_mat</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">TL_coef_e_mat</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="c1"># Can be None or empty if no eddy terms</span>
    <span class="n">return_parts</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the Tolles-Lawson aircraft vector field.</span>

<span class="sd">    Args:</span>
<span class="sd">        B_vec:         3xN matrix of vector magnetometer measurements</span>
<span class="sd">        B_vec_dot:     3xN matrix of vector magnetometer measurement derivatives</span>
<span class="sd">        TL_coef_p:     length-3 vector of permanent field coefficients</span>
<span class="sd">        TL_coef_i_mat: 3x3 symmetric matrix of induced field coefficients, denormalized</span>
<span class="sd">        TL_coef_e_mat: 3x3 matrix of eddy current coefficients, denormalized, or None/empty</span>
<span class="sd">        return_parts:  (optional) if true, also return TL_perm, TL_induced, &amp; TL_eddy</span>

<span class="sd">    Returns:</span>
<span class="sd">        TL_aircraft: 3xN matrix of TL aircraft vector field</span>
<span class="sd">        (if return_parts): TL_perm, TL_induced, TL_eddy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Ensure B_vec and B_vec_dot are (3, N)</span>
    <span class="n">_B_vec</span> <span class="o">=</span> <span class="n">B_vec</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">B_vec</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">B_vec</span><span class="o">.</span><span class="n">size</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">B_vec</span>
    <span class="n">_B_vec_dot</span> <span class="o">=</span> <span class="n">B_vec_dot</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">B_vec_dot</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">B_vec_dot</span><span class="o">.</span><span class="n">size</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">B_vec_dot</span>

    <span class="k">if</span> <span class="n">_B_vec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;B_vec must be 3xN, but got </span><span class="si">{</span><span class="n">_B_vec</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="n">num_samples</span> <span class="o">=</span> <span class="n">_B_vec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># If TL_coef_e_mat is present, B_vec_dot must be valid and match N.</span>
    <span class="c1"># Otherwise, create a zero B_vec_dot if it&#39;s invalid or not matching.</span>
    <span class="k">if</span> <span class="n">TL_coef_e_mat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">TL_coef_e_mat</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">_B_vec_dot</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">3</span> <span class="ow">or</span> <span class="n">_B_vec_dot</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">num_samples</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;B_vec_dot shape mismatch. Expected (3, </span><span class="si">{</span><span class="n">num_samples</span><span class="si">}</span><span class="s2">), got </span><span class="si">{</span><span class="n">_B_vec_dot</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> when eddy terms are present.&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">_B_vec_dot</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">3</span> <span class="ow">or</span> <span class="n">_B_vec_dot</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">num_samples</span> <span class="p">:</span> <span class="c1"># B_vec_dot is present but invalid, and no eddy terms</span>
        <span class="n">_B_vec_dot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_B_vec</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">_B_vec_dot</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">num_samples</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">:</span> <span class="c1"># B_vec_dot is empty, create zeros</span>
        <span class="n">_B_vec_dot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_B_vec</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>


    <span class="c1"># TL_perm = TL_coef_p[:, np.newaxis] * np.ones_like(B_vec[0,:]) # Julia: TL_coef_p .* one.(B_vec)</span>
    <span class="c1"># A more direct way to make TL_coef_p (3,) broadcast to (3,N) with B_vec (3,N)</span>
    <span class="n">TL_perm</span> <span class="o">=</span> <span class="n">TL_coef_p</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="n">TL_induced</span> <span class="o">=</span> <span class="n">TL_coef_i_mat</span> <span class="o">@</span> <span class="n">_B_vec</span>

    <span class="n">TL_eddy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">_B_vec</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_B_vec</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">TL_coef_e_mat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">TL_coef_e_mat</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># _B_vec_dot is guaranteed to be (3,N) here by checks above</span>
        <span class="n">TL_eddy</span> <span class="o">=</span> <span class="n">TL_coef_e_mat</span> <span class="o">@</span> <span class="n">_B_vec_dot</span>
    
    <span class="n">TL_aircraft</span> <span class="o">=</span> <span class="n">TL_perm</span> <span class="o">+</span> <span class="n">TL_induced</span> <span class="o">+</span> <span class="n">TL_eddy</span>

    <span class="k">if</span> <span class="n">return_parts</span><span class="p">:</span>
        <span class="c1"># Ensure all parts are broadcastable to (3,N) if TL_perm was (3,1)</span>
        <span class="n">TL_perm_broadcast</span> <span class="o">=</span> <span class="n">TL_perm</span> <span class="k">if</span> <span class="n">TL_perm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">num_samples</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">TL_perm</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_samples</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">TL_aircraft</span><span class="p">,</span> <span class="n">TL_perm_broadcast</span><span class="p">,</span> <span class="n">TL_induced</span><span class="p">,</span> <span class="n">TL_eddy</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">TL_aircraft</span></div>

<div class="viewcode-block" id="get_curriculum_ind">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.get_curriculum_ind">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_curriculum_ind</span><span class="p">(</span><span class="n">TL_diff</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">N_sigma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Internal helper function to get indices for curriculum learning.</span>
<span class="sd">    Curriculum learning (Tolles-Lawson) indices are those within N_sigma </span>
<span class="sd">    of the mean, and neural network indices are those outside of it (i.e., outliers).</span>

<span class="sd">    Args:</span>
<span class="sd">        TL_diff: Difference of TL model to ground truth.</span>
<span class="sd">        N_sigma: (optional) Standard deviation threshold.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ind_cur: Indices for curriculum learning (within N_sigma), boolean array.</span>
<span class="sd">        ind_nn:  Indices for training the neural network (outside N_sigma), boolean array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">TL_diff</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># Handle empty input</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>

    <span class="c1"># Detrend (mean only)</span>
    <span class="c1"># scipy.signal.detrend by default subtracts the least-squares line.</span>
    <span class="c1"># For mean only, we can just subtract the mean.</span>
    <span class="n">TL_diff_detrended</span> <span class="o">=</span> <span class="n">TL_diff</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">TL_diff</span><span class="p">)</span>
    
    <span class="n">std_dev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">TL_diff_detrended</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">std_dev</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># Avoid issues if all diffs are the same (e.g., N_sigma * 0 = 0)</span>
        <span class="n">cutoff</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># All points will be ind_cur if N_sigma &gt;= 0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cutoff</span> <span class="o">=</span> <span class="n">N_sigma</span> <span class="o">*</span> <span class="n">std_dev</span>
    
    <span class="n">ind_cur</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">TL_diff_detrended</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">cutoff</span>
    <span class="n">ind_nn</span> <span class="o">=</span> <span class="o">~</span><span class="n">ind_cur</span> <span class="c1"># Boolean negation for the opposite set</span>
    
    <span class="k">return</span> <span class="n">ind_cur</span><span class="p">,</span> <span class="n">ind_nn</span></div>


<div class="viewcode-block" id="get_x">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.get_x">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_x</span><span class="p">(</span><span class="n">xyz</span><span class="p">:</span> <span class="n">XYZ</span><span class="p">,</span> <span class="n">ind</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">features_setup</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for getting feature matrix X.&quot;&quot;&quot;</span>
    <span class="c1"># This function would extract specified features from xyz data</span>
    <span class="c1"># For now, returns dummy data</span>
    <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span> <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ind</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    
    <span class="c1"># This is a placeholder. Actual implementation would build x_data based on features_setup.</span>
    <span class="c1"># For now, assume features_setup directly maps to columns or generates some random data.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">features_setup</span><span class="p">:</span> <span class="c1"># Default to using flux_a if no features specified</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="s1">&#39;flux_a&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">xyz</span><span class="o">.</span><span class="n">flux_a</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">xyz</span><span class="o">.</span><span class="n">flux_a</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">xyz</span><span class="o">.</span><span class="n">flux_a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ind</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Ensure indices in &#39;ind&#39; are valid for &#39;xyz.flux_a&#39;</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">xyz</span><span class="o">.</span><span class="n">flux_a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                    <span class="n">x_data</span> <span class="o">=</span> <span class="n">xyz</span><span class="o">.</span><span class="n">flux_a</span><span class="p">[</span><span class="n">ind</span><span class="p">,</span> <span class="p">:]</span>
                <span class="k">else</span><span class="p">:</span> <span class="c1"># Index out of bounds</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Indices for get_x out of bounds for flux_a. Using random data.&quot;</span><span class="p">)</span>
                    <span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># No indices, or ind is empty</span>
                <span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;flux_a_x&#39;</span><span class="p">,</span> <span class="s1">&#39;flux_a_y&#39;</span><span class="p">,</span> <span class="s1">&#39;flux_a_z&#39;</span><span class="p">]</span>
            <span class="n">num_features</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Fallback if flux_a not available</span>
            <span class="n">num_features</span> <span class="o">=</span> <span class="mi">3</span>
            <span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;default_feat_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_features</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">num_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">features_setup</span><span class="p">)</span>
        <span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># Placeholder</span>
        <span class="n">feature_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">features_setup</span><span class="p">)</span>

    <span class="n">no_norm_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;features_no_norm&quot;</span><span class="p">,</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span><span class="o">*</span><span class="n">num_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">no_norm_mask</span><span class="p">)</span> <span class="o">!=</span> <span class="n">num_features</span><span class="p">:</span> <span class="c1"># Ensure mask matches feature count</span>
        <span class="n">no_norm_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span> <span class="c1"># Default to all False if mismatch</span>

    <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="n">num_samples</span><span class="p">]</span> <span class="k">if</span> <span class="n">num_samples</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">[]</span> <span class="c1"># Empty list if no samples</span>
    
    <span class="k">return</span> <span class="n">x_data</span><span class="p">,</span> <span class="n">no_norm_mask</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="n">l_segs</span></div>


<div class="viewcode-block" id="get_y">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.get_y">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_y</span><span class="p">(</span><span class="n">xyz</span><span class="p">:</span> <span class="n">XYZ</span><span class="p">,</span> <span class="n">ind</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">map_val</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for getting target vector Y.&quot;&quot;&quot;</span>
    <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span> <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ind</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># Initialize</span>
    
    <span class="n">y_type</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;y_type&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">)</span>
    <span class="n">use_mag_field</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_mag&quot;</span><span class="p">,</span> <span class="s2">&quot;mag_1_c&quot;</span><span class="p">)</span>
    
    <span class="n">mag_data_selected</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_mag_field</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_mag_field</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">full_mag_data</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_mag_field</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ind</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">ind</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_mag_data</span><span class="p">))</span> <span class="k">if</span> <span class="n">ind</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_mag_data</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span> <span class="k">else</span> <span class="kc">True</span><span class="p">):</span> <span class="c1"># Check bounds</span>
            <span class="n">mag_data_selected</span> <span class="o">=</span> <span class="n">full_mag_data</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ind</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">:</span> <span class="c1"># ind out of bounds or other issue</span>
             <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Indices for get_y out of bounds for field </span><span class="si">{</span><span class="n">use_mag_field</span><span class="si">}</span><span class="s2">. Using zeros.&quot;</span><span class="p">)</span>


    <span class="n">map_val_processed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">map_val</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">map_val</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="n">num_samples</span><span class="p">:</span>
        <span class="n">map_val_processed</span> <span class="o">=</span> <span class="n">map_val</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">map_val</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">))</span> <span class="ow">and</span> <span class="n">map_val</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">num_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># mapS_null case</span>
        <span class="k">pass</span> <span class="c1"># map_val_processed remains zeros</span>
    <span class="k">elif</span> <span class="n">map_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">map_val</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_samples</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">map_val</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">map_val</span><span class="o">.</span><span class="n">size</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected map_val type or size in get_y: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">map_val</span><span class="p">)</span><span class="si">}</span><span class="s2">, size: </span><span class="si">{</span><span class="nb">getattr</span><span class="p">(</span><span class="n">map_val</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;size&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;N/A&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">. Using zeros.&quot;</span><span class="p">)</span>


    <span class="k">if</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span>
        <span class="c1"># B_earth = B_total - B_aircraft. B_aircraft needs TL model. Placeholder:</span>
        <span class="n">y_data</span> <span class="o">=</span> <span class="n">mag_data_selected</span>
    <span class="k">elif</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span>
        <span class="n">y_data</span> <span class="o">=</span> <span class="n">map_val_processed</span>
    <span class="k">elif</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s1">&#39;c&#39;</span><span class="p">:</span>
        <span class="n">y_data</span> <span class="o">=</span> <span class="n">mag_data_selected</span> <span class="o">-</span> <span class="n">map_val_processed</span>
    <span class="k">elif</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s1">&#39;d&#39;</span><span class="p">:</span>
        <span class="n">y_data</span> <span class="o">=</span> <span class="n">mag_data_selected</span>
        <span class="c1"># Typically, &#39;d&#39; implies delta from a reference like IGRF or diurnal mean.</span>
        <span class="c1"># This subtraction should happen *after* bpf_mag if y_type=&#39;e&#39; was the original goal.</span>
        <span class="c1"># For &#39;d&#39; directly, it&#39;s often mag_total - (IGRF + Diurnal).</span>
    <span class="k">elif</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s1">&#39;e&#39;</span><span class="p">:</span>
        <span class="n">y_data_temp</span> <span class="o">=</span> <span class="n">mag_data_selected</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;bpf_mag&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">fs</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;fs&quot;</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">xyz</span><span class="o">.</span><span class="n">dt</span> <span class="k">if</span> <span class="n">xyz</span><span class="o">.</span><span class="n">dt</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">10.0</span><span class="p">)</span>
            <span class="n">bpf_coeffs</span> <span class="o">=</span> <span class="n">get_bpf</span><span class="p">(</span><span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
            <span class="n">y_data_temp</span> <span class="o">=</span> <span class="n">bpf_data</span><span class="p">(</span><span class="n">y_data_temp</span><span class="p">,</span> <span class="n">bpf</span><span class="o">=</span><span class="n">bpf_coeffs</span><span class="p">)</span> <span class="k">if</span> <span class="n">bpf_coeffs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">y_data_temp</span>
        <span class="n">y_data</span> <span class="o">=</span> <span class="n">y_data_temp</span>
    
    <span class="c1"># Apply diurnal and IGRF corrections to the base total field component</span>
    <span class="c1"># This logic assumes y_data at this point represents some form of total field or direct measurement</span>
    <span class="c1"># before becoming the final target y (e.g. aircraft field).</span>
    <span class="c1"># If y_type is &#39;a&#39; or &#39;c&#39;, these should ideally be subtracted from the &#39;total field&#39; part.</span>
    <span class="c1"># For &#39;d&#39; and &#39;e&#39;, it&#39;s more direct.</span>
    
    <span class="c1"># Refined subtraction logic:</span>
    <span class="c1"># These are typically removed from the measured total field.</span>
    <span class="c1"># If y_data is already a difference (like &#39;c&#39;), this might be double subtraction.</span>
    <span class="c1"># Let&#39;s assume for &#39;d&#39; and &#39;e&#39;, they are subtracted from the (potentially BPF&#39;d) total field.</span>
    <span class="c1"># For &#39;a&#39;, &#39;b&#39;, &#39;c&#39;, the interpretation is more complex for these subtractions.</span>
    <span class="c1"># For now, apply if sub_X is true, to y_data as it stands.</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;sub_diurnal&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="s2">&quot;diurnal&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">xyz</span><span class="o">.</span><span class="n">diurnal</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ind</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">ind</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">xyz</span><span class="o">.</span><span class="n">diurnal</span><span class="p">))</span> <span class="k">if</span> <span class="n">ind</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">xyz</span><span class="o">.</span><span class="n">diurnal</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span> <span class="k">else</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">y_data</span> <span class="o">-=</span> <span class="n">xyz</span><span class="o">.</span><span class="n">diurnal</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;sub_igrf&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="s2">&quot;igrf&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">xyz</span><span class="o">.</span><span class="n">igrf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ind</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">ind</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">xyz</span><span class="o">.</span><span class="n">igrf</span><span class="p">))</span> <span class="k">if</span> <span class="n">ind</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">xyz</span><span class="o">.</span><span class="n">igrf</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span> <span class="k">else</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">y_data</span> <span class="o">-=</span> <span class="n">xyz</span><span class="o">.</span><span class="n">igrf</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
        
    <span class="k">return</span> <span class="n">y_data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span></div>



<div class="viewcode-block" id="get_map_val">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.get_map_val">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_map_val</span><span class="p">(</span><span class="n">mapS</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">traj</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">ind</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">200</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for getting map values along a trajectory.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">ind</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">return</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ind</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="mi">50000</span> <span class="c1"># Dummy map values</span></div>


<div class="viewcode-block" id="get_bpf">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.get_bpf">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_bpf</span><span class="p">(</span><span class="n">fs</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">pass1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">pass2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Gets bandpass filter coefficients using scipy.signal.butter.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">fs</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sampling frequency fs must be positive. Got </span><span class="si">{</span><span class="n">fs</span><span class="si">}</span><span class="s2">. Cannot create BPF.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="n">nyquist</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">fs</span>
    <span class="n">low</span> <span class="o">=</span> <span class="n">pass1</span> <span class="o">/</span> <span class="n">nyquist</span>
    <span class="n">high</span> <span class="o">=</span> <span class="n">pass2</span> <span class="o">/</span> <span class="n">nyquist</span>

    <span class="k">if</span> <span class="n">high</span> <span class="o">&gt;=</span> <span class="mf">1.0</span><span class="p">:</span> <span class="n">high</span> <span class="o">=</span> <span class="mf">0.999</span>
    <span class="k">if</span> <span class="n">low</span> <span class="o">&lt;=</span> <span class="mf">0.0</span><span class="p">:</span> <span class="n">low</span> <span class="o">=</span> <span class="mf">0.001</span>
    
    <span class="k">if</span> <span class="n">low</span> <span class="o">&gt;=</span> <span class="n">high</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BPF low cutoff </span><span class="si">{</span><span class="n">pass1</span><span class="si">}</span><span class="s2">Hz (norm: </span><span class="si">{</span><span class="n">low</span><span class="si">}</span><span class="s2">) &gt;= high cutoff </span><span class="si">{</span><span class="n">pass2</span><span class="si">}</span><span class="s2">Hz (norm: </span><span class="si">{</span><span class="n">high</span><span class="si">}</span><span class="s2">). Filter disabled.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># butter is already imported at the top</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">a</span> <span class="o">=</span> <span class="n">butter</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">],</span> <span class="n">btype</span><span class="o">=</span><span class="s1">&#39;band&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">a</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error creating BPF with pass1=</span><span class="si">{</span><span class="n">pass1</span><span class="si">}</span><span class="s2">, pass2=</span><span class="si">{</span><span class="n">pass2</span><span class="si">}</span><span class="s2">, fs=</span><span class="si">{</span><span class="n">fs</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Filter disabled.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="bpf_data">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.bpf_data">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">bpf_data</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">bpf</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Applies bandpass filter to data.&quot;&quot;&quot;</span>
    <span class="c1"># lfilter is imported at the top</span>
    <span class="k">if</span> <span class="n">bpf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">bpf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">bpf</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">filter_order_check</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bpf</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">len</span><span class="p">(</span><span class="n">bpf</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        
        <span class="n">min_data_len</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">filter_order_check</span>
        <span class="k">if</span> <span class="n">min_data_len</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">:</span> <span class="n">min_data_len</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># handle case where filter_order_check might be 0 for some reason</span>

        <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">min_data_len</span><span class="p">:</span>
                 <span class="k">return</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">bpf</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bpf</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">data</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                 <span class="c1"># logging.warning(f&quot;Data length ({data.shape[0]}) too short for BPF order ({filter_order_check}). Skipping filter.&quot;)</span>
                 <span class="k">return</span> <span class="n">data</span>
        <span class="k">elif</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">filtered_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="k">if</span> <span class="n">data</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">min_data_len</span><span class="p">:</span>
                    <span class="n">filtered_data</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">lfilter</span><span class="p">(</span><span class="n">bpf</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bpf</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># logging.warning(f&quot;Data column {i} length ({data.shape[0]}) too short for BPF. Skipping filter.&quot;)</span>
                    <span class="n">filtered_data</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">filtered_data</span>
    <span class="k">return</span> <span class="n">data</span></div>


<div class="viewcode-block" id="get_Axy">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.get_Axy">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_Axy</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Combined placeholder for variants of get_Axy.&quot;&quot;&quot;</span>
    <span class="c1"># This is a complex data loading and preprocessing function.</span>
    <span class="c1"># For now, returning dummy values based on some expected shapes.</span>
    <span class="c1"># Based on comp_train(comp_params, lines, df_line, df_flight, df_map)</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># Assuming lines is the first argument</span>
    <span class="c1"># A rough estimation of number of samples from lines</span>
    <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">))</span> <span class="k">else</span> <span class="mi">100</span> <span class="c1"># Dummy</span>
    
    <span class="n">terms_A</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;terms_A&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">,</span> <span class="s2">&quot;induced&quot;</span><span class="p">,</span> <span class="s2">&quot;eddy&quot;</span><span class="p">])</span>
    <span class="n">num_A_cols</span> <span class="o">=</span> <span class="mi">18</span> <span class="c1"># Estimate based on typical TL terms</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">num_A_cols</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="n">features_setup</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">4</span> <span class="k">else</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;features_setup&quot;</span><span class="p">,</span> <span class="p">[])</span>
    <span class="n">num_x_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">features_setup</span><span class="p">)</span> <span class="k">if</span> <span class="n">features_setup</span> <span class="k">else</span> <span class="mi">5</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">num_x_features</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">no_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_x_features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">features_setup</span> <span class="k">if</span> <span class="n">features_setup</span> <span class="k">else</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;feat</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_x_features</span><span class="p">)]</span></div>


<div class="viewcode-block" id="linear_fit">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.linear_fit">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">linear_fit</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">no_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">trim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">lambda_ridge</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="c1"># Renamed from λ to avoid keyword clash</span>
    <span class="n">norm_type_x</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">norm_type_y</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">data_norms_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Renamed from data_norms</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fit a linear regression model to data.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: N x Nf data matrix (Nf is number of features)</span>
<span class="sd">        y: length-N target vector</span>
<span class="sd">        no_norm: (optional) length-Nf Boolean indices of features to not be normalized</span>
<span class="sd">        trim: (optional) number of elements to trim from each segment (e.g., due to bpf)</span>
<span class="sd">        lambda_ridge: (optional) ridge parameter</span>
<span class="sd">        norm_type_x: (optional) normalization for x data matrix</span>
<span class="sd">        norm_type_y: (optional) normalization for y target vector</span>
<span class="sd">        data_norms_in: (optional) length-4 tuple of data normalizations, (x_bias,x_scale,y_bias,y_scale)</span>
<span class="sd">        l_segs: (optional) length-N_lines vector of lengths of lines, sum(l_segs) = N</span>
<span class="sd">        silent: (optional) if true, no print outs</span>

<span class="sd">    Returns:</span>
<span class="sd">        model: length-2 tuple of linear regression model, (length-Nf coefficients, bias=0.0)</span>
<span class="sd">        data_norms_out: length-4 tuple of data normalizations, (x_bias,x_scale,y_bias,y_scale)</span>
<span class="sd">        y_hat: length-N prediction vector</span>
<span class="sd">        err: length-N mean-corrected (per line) error</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;linear_fit expects a 1D target vector y, but got shape </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">y_flat</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="c1"># Ensure y is 1D</span>

    <span class="k">if</span> <span class="n">no_norm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">no_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">)]</span>
    
    <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">])</span> <span class="c1"># Defaults</span>

    <span class="k">if</span> <span class="n">data_norms_in</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">data_norms_in</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">:</span> <span class="c1"># Normalize data</span>
        <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">x_norm</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_x</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm</span><span class="p">)</span>
        <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">y_norm_flat</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">y_flat</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_y</span><span class="p">)</span>
        <span class="n">data_norms_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># Unpack data normalizations</span>
        <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="n">unpack_data_norms</span><span class="p">(</span><span class="n">data_norms_in</span><span class="p">)</span> <span class="c1"># type: ignore</span>
        <span class="n">x_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_bias</span><span class="p">)</span> <span class="o">/</span> <span class="n">x_scale</span>
        <span class="n">y_norm_flat</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_flat</span> <span class="o">-</span> <span class="n">y_bias</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_scale</span>
        <span class="n">data_norms_out</span> <span class="o">=</span> <span class="n">data_norms_in</span>

    <span class="c1"># Trim each line/segment</span>
    <span class="c1"># The original Julia code creates `ind` by taking `trim` from start and end of each segment.</span>
    <span class="c1"># Python equivalent:</span>
    <span class="n">trimmed_indices_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">current_pos</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">seg_len</span> <span class="ow">in</span> <span class="n">l_segs</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">seg_len</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">trim</span><span class="p">:</span> <span class="c1"># Ensure segment is long enough for trimming</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="n">current_pos</span> <span class="o">+</span> <span class="n">trim</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="n">current_pos</span> <span class="o">+</span> <span class="n">seg_len</span> <span class="o">-</span> <span class="n">trim</span>
            <span class="n">trimmed_indices_list</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">)))</span>
        <span class="c1"># else: segment is too short, skip or handle as error/warning</span>
        <span class="n">current_pos</span> <span class="o">+=</span> <span class="n">seg_len</span>
    
    <span class="n">trimmed_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trimmed_indices_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">trimmed_indices</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARN: No data left after trimming in linear_fit. Returning zero coefficients.&quot;</span><span class="p">)</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">bias_val</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">model_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">bias_val</span><span class="p">)</span>
        <span class="c1"># Predict with zero model</span>
        <span class="n">y_hat_full</span><span class="p">,</span> <span class="n">err_full</span> <span class="o">=</span> <span class="n">linear_test</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">y_flat</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">model_out</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_out</span><span class="p">,</span> <span class="n">data_norms_out</span><span class="p">,</span> <span class="n">y_hat_full</span><span class="p">,</span> <span class="n">err_full</span>

    <span class="n">x_norm_trimmed</span> <span class="o">=</span> <span class="n">x_norm</span><span class="p">[</span><span class="n">trimmed_indices</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">y_norm_trimmed</span> <span class="o">=</span> <span class="n">y_norm_flat</span><span class="p">[</span><span class="n">trimmed_indices</span><span class="p">]</span>

    <span class="c1"># Linear regression to get coefficients</span>
    <span class="c1"># The original linreg function in Julia does not fit an intercept (bias term is zero).</span>
    <span class="c1"># We will replicate this behavior.</span>
    <span class="k">if</span> <span class="n">x_norm_trimmed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># No data after trim</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x_norm_trimmed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">elif</span> <span class="n">lambda_ridge</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Simple least squares: (X^T X)^-1 X^T y</span>
        <span class="c1"># Using np.linalg.lstsq for numerical stability</span>
        <span class="n">coeffs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">x_norm_trimmed</span><span class="p">,</span> <span class="n">y_norm_trimmed</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Ridge regression: (X^T X + lambda I)^-1 X^T y</span>
        <span class="n">XtX</span> <span class="o">=</span> <span class="n">x_norm_trimmed</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">x_norm_trimmed</span>
        <span class="n">lambda_I</span> <span class="o">=</span> <span class="n">lambda_ridge</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">XtX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">XtX</span> <span class="o">+</span> <span class="n">lambda_I</span><span class="p">,</span> <span class="n">x_norm_trimmed</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y_norm_trimmed</span><span class="p">)</span>
    
    <span class="n">bias_val</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># As per original MagNav.jl linear_fit behavior (bias is zero)</span>
    <span class="n">model_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">coeffs</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bias_val</span><span class="p">)</span>

    <span class="c1"># Get results on the full (untrimmed, but normalized if applicable) dataset</span>
    <span class="n">y_hat_full</span><span class="p">,</span> <span class="n">err_full</span> <span class="o">=</span> <span class="n">linear_test</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">y_flat</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">model_out</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_full</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_full</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: fit error: </span><span class="si">{</span><span class="n">err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trim</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
             <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INFO: fit error may be misleading if using bandpass filter (due to trim)&quot;</span><span class="p">)</span>
             
    <span class="k">return</span> <span class="n">model_out</span><span class="p">,</span> <span class="n">data_norms_out</span><span class="p">,</span> <span class="n">y_hat_full</span><span class="p">,</span> <span class="n">err_full</span></div>

<div class="viewcode-block" id="linear_fwd">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.linear_fwd">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">linear_fwd</span><span class="p">(</span>
    <span class="n">x_in</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">data_norms_or_y_bias</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> 
    <span class="n">model_or_y_scale</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">model_if_normalized</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass of a linear model.</span>
<span class="sd">    This function handles two call signatures from Julia via dispatch:</span>
<span class="sd">    1. linear_fwd(x_norm, y_bias, y_scale, model_tuple)</span>
<span class="sd">    2. linear_fwd(x_raw, data_norms_tuple, model_tuple)</span>

<span class="sd">    :param x_in: N x Nf data matrix (either normalized or raw)</span>
<span class="sd">    :type x_in: numpy.ndarray</span>
<span class="sd">    :param data_norms_or_y_bias: Either data_norms tuple (x_bias, x_scale, y_bias, y_scale) or y_bias directly.</span>
<span class="sd">    :type data_norms_or_y_bias: Union[Tuple, float, numpy.ndarray]</span>
<span class="sd">    :param model_or_y_scale: Either the model tuple (coeffs, bias_val) or y_scale directly.</span>
<span class="sd">    :type model_or_y_scale: Union[Tuple[numpy.ndarray, float], float, numpy.ndarray]</span>
<span class="sd">    :param model_if_normalized: The model tuple, used if the first signature is matched.</span>
<span class="sd">    :type model_if_normalized: Optional[Tuple[numpy.ndarray, float]]</span>
<span class="sd">    :returns: length-N prediction vector</span>
<span class="sd">    :rtype: numpy.ndarray</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x_processed</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y_bias_eff</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span>
    <span class="n">y_scale_eff</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span>
    <span class="n">model_eff</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_norms_or_y_bias</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_norms_or_y_bias</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_or_y_scale</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="c1"># Signature 2: linear_fwd(x_raw, data_norms_tuple, model_tuple)</span>
        <span class="n">x_raw</span> <span class="o">=</span> <span class="n">x_in</span>
        <span class="n">data_norms_tuple</span> <span class="o">=</span> <span class="n">data_norms_or_y_bias</span>
        <span class="n">model_eff</span> <span class="o">=</span> <span class="n">model_or_y_scale</span>

        <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias_eff</span><span class="p">,</span> <span class="n">y_scale_eff</span> <span class="o">=</span> <span class="n">unpack_data_norms</span><span class="p">(</span><span class="n">data_norms_tuple</span><span class="p">)</span> <span class="c1"># type: ignore</span>
        
        <span class="c1"># Handle cases where bias/scale might be single float vs array</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_bias</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_scale</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
             <span class="n">x_processed</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_raw</span> <span class="o">-</span> <span class="n">x_bias</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_scale</span> <span class="k">if</span> <span class="n">x_scale</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_bias</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_scale</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
             <span class="n">x_processed</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_raw</span> <span class="o">-</span> <span class="n">x_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;x_bias and x_scale must be both float or both np.ndarray&quot;</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">model_if_normalized</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Signature 1: linear_fwd(x_norm, y_bias, y_scale, model_tuple)</span>
        <span class="n">x_processed</span> <span class="o">=</span> <span class="n">x_in</span> <span class="c1"># Already normalized</span>
        <span class="n">y_bias_eff</span> <span class="o">=</span> <span class="n">data_norms_or_y_bias</span>
        <span class="n">y_scale_eff</span> <span class="o">=</span> <span class="n">model_or_y_scale</span> 
        <span class="n">model_eff</span> <span class="o">=</span> <span class="n">model_if_normalized</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Invalid arguments for linear_fwd. Check call signature.&quot;</span><span class="p">)</span>

    <span class="n">coeffs</span><span class="p">,</span> <span class="n">bias_val</span> <span class="o">=</span> <span class="n">model_eff</span>
    
    <span class="n">y_hat_norm</span> <span class="o">=</span> <span class="n">x_processed</span> <span class="o">@</span> <span class="n">coeffs</span> <span class="o">+</span> <span class="n">bias_val</span>
    
    <span class="c1"># Denormalize</span>
    <span class="c1"># Ensure y_bias_eff and y_scale_eff are ndarrays for denorm_sets if they came as floats</span>
    <span class="n">_y_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_bias_eff</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_bias_eff</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span><span class="nb">int</span><span class="p">))</span> <span class="k">else</span> <span class="n">y_bias_eff</span>
    <span class="n">_y_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_scale_eff</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scale_eff</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span><span class="nb">int</span><span class="p">))</span> <span class="k">else</span> <span class="n">y_scale_eff</span>
    
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">denorm_sets</span><span class="p">(</span><span class="n">_y_bias</span><span class="p">,</span> <span class="n">_y_scale</span><span class="p">,</span> <span class="n">y_hat_norm</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span></div>



<div class="viewcode-block" id="linear_test">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.linear_test">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">linear_test</span><span class="p">(</span>
    <span class="n">x_in</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">data_norms_or_y_bias</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> 
    <span class="n">model_or_y_scale</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">model_if_normalized</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate performance of a linear model.</span>
<span class="sd">    Handles two call signatures similar to linear_fwd.</span>

<span class="sd">    Args (depending on signature):</span>
<span class="sd">        x_in: N x Nf data matrix (either normalized or raw)</span>
<span class="sd">        y: length-N target vector</span>
<span class="sd">        data_norms_or_y_bias: Either data_norms tuple or y_bias.</span>
<span class="sd">        model_or_y_scale: Either the model tuple or y_scale.</span>
<span class="sd">        model_if_normalized: (optional) The model tuple for the normalized signature.</span>
<span class="sd">        l_segs: (optional) length-N_lines vector of lengths of lines, sum(l_segs) = N</span>
<span class="sd">        silent: (optional) if true, no print outs</span>

<span class="sd">    Returns:</span>
<span class="sd">        y_hat: length-N prediction vector</span>
<span class="sd">        err: length-N mean-corrected (per line) error</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_flat</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">)]</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">linear_fwd</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="n">data_norms_or_y_bias</span><span class="p">,</span> <span class="n">model_or_y_scale</span><span class="p">,</span> <span class="n">model_if_normalized</span><span class="p">)</span>
    
    <span class="c1"># Ensure l_segs is valid for the length of y_hat/y</span>
    <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="n">l_segs</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: sum(l_segs)=</span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span><span class="si">}</span><span class="s2"> != len(y)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">)</span><span class="si">}</span><span class="s2">. Using single segment for error calculation.&quot;</span><span class="p">)</span>
        <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">)]</span>
        
    <span class="n">err_val</span> <span class="o">=</span> <span class="n">err_segs</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y_flat</span><span class="p">,</span> <span class="n">valid_l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span><span class="p">)</span> <span class="c1"># Use global SILENT_DEBUG for internal err_segs</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_val</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_val</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: test error: </span><span class="si">{</span><span class="n">err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">err_val</span></div>


<div class="viewcode-block" id="save_comp_params">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.save_comp_params">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">save_comp_params</span><span class="p">(</span><span class="n">comp_params</span><span class="p">:</span> <span class="n">CompParams</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for saving compensation parameters.&quot;&quot;&quot;</span>
    <span class="c1"># In Python, might use pickle, joblib, or torch.save for model parts</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Placeholder: Saving comp_params to </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="get_comp_params">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.get_comp_params">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">get_comp_params</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CompParams</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for loading compensation parameters.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Placeholder: Loading comp_params from </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Return a default CompParams object for now</span>
    <span class="k">return</span> <span class="n">NNCompParams</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;nn&quot;</span> <span class="ow">in</span> <span class="n">filename</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">or</span> <span class="s2">&quot;m1&quot;</span> <span class="ow">in</span> <span class="n">filename</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">or</span> <span class="s2">&quot;m2&quot;</span> <span class="ow">in</span> <span class="n">filename</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">or</span> <span class="s2">&quot;m3&quot;</span> <span class="ow">in</span> <span class="n">filename</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">else</span> <span class="n">LinCompParams</span><span class="p">()</span></div>


<div class="viewcode-block" id="field_check">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.field_check">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">field_check</span><span class="p">(</span><span class="n">xyz</span><span class="p">:</span> <span class="n">XYZ</span><span class="p">,</span> <span class="n">field_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">expected_type</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for checking if a field exists in XYZ struct.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">field_name</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;XYZ object does not have field: </span><span class="si">{</span><span class="n">field_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Can add type checking if needed: if not isinstance(getattr(xyz, field_name), expected_type): ...</span>
    <span class="k">pass</span></div>


<div class="viewcode-block" id="linreg">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.linreg">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">linreg</span><span class="p">(</span><span class="n">y_norm</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">x_norm</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">λ</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Placeholder for linear regression, possibly with ridge.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">x_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># No data</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">λ</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># Simple least squares</span>
        <span class="n">coeffs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">y_norm</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">coeffs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># Ridge regression</span>
        <span class="c1"># (X^T X + lambda I)^-1 X^T y</span>
        <span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">x_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">x_norm</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">x_norm</span> <span class="o">+</span> <span class="n">λ</span> <span class="o">*</span> <span class="n">I</span><span class="p">,</span> <span class="n">x_norm</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y_norm</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">coeffs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span></div>


<span class="c1"># --- Struct to Class Translations ---</span>

<div class="viewcode-block" id="M1Struct">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.M1Struct">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">M1Struct</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">m</span> <span class="c1"># This is the Chain (nn.Sequential)</span>

<div class="viewcode-block" id="M1Struct.forward">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.M1Struct.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># This forward might not be directly used if s.m is accessed,</span>
        <span class="c1"># but good practice for an nn.Module.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>
</div>


<div class="viewcode-block" id="M2Struct">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.M2Struct">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">M2Struct</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span> <span class="n">tl_coef_norm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">m</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tl_coef_norm</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">tl_coef_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">tl_coef_norm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">TL_coef_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">tl_coef_norm</span><span class="p">)</span> <span class="c1"># Trainable</span>

<div class="viewcode-block" id="M2Struct.forward">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.M2Struct.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># Placeholder, actual forward pass depends on usage</span></div>
</div>


<div class="viewcode-block" id="M2StructMOnly">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.M2StructMOnly">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">M2StructMOnly</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span> <span class="c1"># TL_coef_norm is not trained by optimizer directly</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span> <span class="n">tl_coef_norm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">m</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tl_coef_norm</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;TL_coef_norm&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">tl_coef_norm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;TL_coef_norm&#39;</span><span class="p">,</span> <span class="n">tl_coef_norm</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>


<div class="viewcode-block" id="M2StructMOnly.forward">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.M2StructMOnly.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>
</div>


<div class="viewcode-block" id="M3Struct">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.M3Struct">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">M3Struct</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span> <span class="n">tl_p</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> 
                 <span class="n">tl_i</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">tl_e</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">TL_p</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">tl_p</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tl_p</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">tl_p</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">TL_i</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">tl_i</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tl_i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">tl_i</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">TL_e</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">tl_e</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tl_e</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">tl_e</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>

<div class="viewcode-block" id="M3Struct.forward">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.M3Struct.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>
</div>


<span class="c1"># --- Function Translations ---</span>

<div class="viewcode-block" id="nn_comp_1_train">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_1_train">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_1_train</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">no_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">norm_type_x</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;standardize&quot;</span><span class="p">,</span>
    <span class="n">norm_type_y</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;standardize&quot;</span><span class="p">,</span>
    <span class="n">eta_adam</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="n">epoch_adam</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="n">epoch_lbfgs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">hidden</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="c1"># type: ignore</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">,</span>
    <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span> <span class="c1"># Renamed from loss to loss_fn to avoid conflict</span>
    <span class="n">batchsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="n">frac_train</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">14</span><span class="o">/</span><span class="mi">17</span><span class="p">,</span>
    <span class="n">alpha_sgl</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">lambda_sgl</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">k_pca</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">data_norms_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Renamed from data_norms</span>
    <span class="n">model_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Renamed from model</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">x_test_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Renamed from x_test</span>
    <span class="n">y_test_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Renamed from y_test</span>
    <span class="n">l_segs_test</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>

    <span class="k">if</span> <span class="n">no_norm</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">no_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span>
    <span class="k">if</span> <span class="n">x_test_in</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">x_test_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">y_test_in</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">y_test_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">l_segs_test</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">l_segs_test</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test_in</span><span class="p">)]</span>
    <span class="k">if</span> <span class="n">data_norms_in</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># Default from Julia</span>
        <span class="n">data_norms_in</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> 
                           <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                           <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                           <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>


    <span class="c1"># Convert to Float32</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">alpha_sgl</span><span class="p">)</span>
    <span class="n">lambda_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">lambda_sgl</span><span class="p">)</span> <span class="c1"># Renamed from lambda</span>
    <span class="n">x_test_in</span> <span class="o">=</span> <span class="n">x_test_in</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">y_test_in</span> <span class="o">=</span> <span class="n">y_test_in</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">Nf</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># number of features</span>

    <span class="n">v_scale_pca</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="k">if</span> <span class="n">data_norms_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data_norms_in</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># normalize data</span>
        <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">x_norm_np</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_x</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm</span><span class="p">)</span>
        <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">y_norm_np</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_y</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">k_pca</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">k_pca</span> <span class="o">&gt;</span> <span class="n">Nf</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: reducing k_pca from </span><span class="si">{</span><span class="n">k_pca</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">Nf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">k_pca</span> <span class="o">=</span> <span class="n">Nf</span>
            
            <span class="c1"># Ensure x_norm_np is 2D for np.cov</span>
            <span class="k">if</span> <span class="n">x_norm_np</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="n">x_norm_np_2d</span> <span class="o">=</span> <span class="n">x_norm_np</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span> <span class="n">x_norm_np_2d</span> <span class="o">=</span> <span class="n">x_norm_np</span>

            <span class="k">if</span> <span class="n">x_norm_np_2d</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="p">:</span> <span class="c1"># cov needs more than 1 sample</span>
                <span class="n">cov_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x_norm_np_2d</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">S_svd</span><span class="p">,</span> <span class="n">V_svd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">cov_x</span><span class="p">)</span>
                <span class="n">v_scale_pca</span> <span class="o">=</span> <span class="n">V_svd</span><span class="p">[:,</span> <span class="p">:</span><span class="n">k_pca</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S_svd</span><span class="p">[:</span><span class="n">k_pca</span><span class="p">])))</span>
                <span class="n">var_ret</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S_svd</span><span class="p">[:</span><span class="n">k_pca</span><span class="p">]))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S_svd</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: k_pca = </span><span class="si">{</span><span class="n">k_pca</span><span class="si">}</span><span class="s2"> of </span><span class="si">{</span><span class="n">Nf</span><span class="si">}</span><span class="s2">, variance retained: </span><span class="si">{</span><span class="n">var_ret</span><span class="si">}</span><span class="s2"> %&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># Not enough samples for meaningful SVD/PCA</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WARN: Not enough samples (</span><span class="si">{</span><span class="n">x_norm_np_2d</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">) for PCA with k_pca=</span><span class="si">{</span><span class="n">k_pca</span><span class="si">}</span><span class="s2">. Using identity matrix for v_scale_pca.&quot;</span><span class="p">)</span>
                <span class="n">v_scale_pca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">Nf</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">v_scale_pca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">Nf</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="n">x_norm_transformed</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_norm_np</span> <span class="o">@</span> <span class="n">v_scale_pca</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">y_norm_transformed</span> <span class="o">=</span> <span class="n">y_norm_np</span><span class="o">.</span><span class="n">T</span> <span class="k">if</span> <span class="n">y_norm_np</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">y_norm_np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Ensure 2D for DataLoader</span>
        
        <span class="c1"># Store original (non-PCA&#39;d) bias/scale for x for test data transformation</span>
        <span class="n">data_norms_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="c1"># Placeholder for Julia&#39;s first two elements</span>
                          <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="c1"># Placeholder</span>
                          <span class="n">v_scale_pca</span><span class="p">,</span> <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span> <span class="c1"># unpack data normalizations</span>
        <span class="c1"># Assuming data_norms_in has the structure: (_,_,v_scale_pca,x_bias,x_scale,y_bias,y_scale)</span>
        <span class="c1"># The first two elements are placeholders from Julia code.</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">v_scale_pca</span><span class="p">,</span> <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="n">unpack_data_norms</span><span class="p">(</span><span class="n">cast</span><span class="p">(</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">data_norms_in</span><span class="p">))</span>
        <span class="n">x_norm_transformed</span> <span class="o">=</span> <span class="p">(((</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_bias</span><span class="p">)</span> <span class="o">/</span> <span class="n">x_scale</span><span class="p">)</span> <span class="o">@</span> <span class="n">v_scale_pca</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">y_norm_transformed</span> <span class="o">=</span> <span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_bias</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_scale</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_bias</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_scale</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">data_norms_out</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">data_norms_in</span><span class="p">)</span>


    <span class="n">x_test_norm_transformed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">x_test_in</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Use x_bias and x_scale from training data before PCA for consistency</span>
        <span class="n">x_test_norm_transformed</span> <span class="o">=</span> <span class="p">(((</span><span class="n">x_test_in</span> <span class="o">-</span> <span class="n">x_bias</span><span class="p">)</span> <span class="o">/</span> <span class="n">x_scale</span><span class="p">)</span> <span class="o">@</span> <span class="n">v_scale_pca</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>


    <span class="c1"># Convert to PyTorch Tensors</span>
    <span class="n">x_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_norm_transformed</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">y_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_norm_transformed</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="c1"># Ensure 1D for MSELoss typical use</span>

    <span class="c1"># Separate into training &amp; validation</span>
    <span class="k">if</span> <span class="n">frac_train</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># PyTorch DataLoader expects (features, samples) for x, and (samples,) or (samples, features_y) for y</span>
        <span class="c1"># Current x_norm_torch is (features, samples), y_norm_torch is (samples,)</span>
        <span class="c1"># We need to split along the sample dimension (dim=1 for x_norm_torch)</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="n">x_norm_torch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="n">split_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">num_samples</span> <span class="o">*</span> <span class="n">frac_train</span><span class="p">))</span>
        
        <span class="n">train_indices</span><span class="p">,</span> <span class="n">val_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">split_idx</span><span class="p">],</span> <span class="n">indices</span><span class="p">[</span><span class="n">split_idx</span><span class="p">:]</span>
        
        <span class="n">x_train_norm_torch</span> <span class="o">=</span> <span class="n">x_norm_torch</span><span class="p">[:,</span> <span class="n">train_indices</span><span class="p">]</span>
        <span class="n">y_train_norm_torch</span> <span class="o">=</span> <span class="n">y_norm_torch</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
        <span class="n">x_val_norm_torch</span> <span class="o">=</span> <span class="n">x_norm_torch</span><span class="p">[:,</span> <span class="n">val_indices</span><span class="p">]</span>
        <span class="n">y_val_norm_torch</span> <span class="o">=</span> <span class="n">y_norm_torch</span><span class="p">[</span><span class="n">val_indices</span><span class="p">]</span>

        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_train_norm_torch</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">y_train_norm_torch</span><span class="p">)</span> <span class="c1"># DataLoader expects (sample, feature)</span>
        <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_val_norm_torch</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">y_val_norm_torch</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_norm_torch</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">y_norm_torch</span><span class="p">)</span>
        <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span>

    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># Usually False for validation</span>

    <span class="c1"># Setup NN</span>
    <span class="n">current_model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span>
    <span class="k">if</span> <span class="n">model_in</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">list</span><span class="p">(</span><span class="n">model_in</span><span class="o">.</span><span class="n">children</span><span class="p">()):</span> <span class="c1"># Check if model_in is empty Chain()</span>
        <span class="n">Ny</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># length of output</span>
        <span class="c1"># Input features to NN is k_pca if used, else Nf</span>
        <span class="n">nn_input_features</span> <span class="o">=</span> <span class="n">v_scale_pca</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># Number of columns in v_scale_pca</span>
        <span class="n">current_model</span> <span class="o">=</span> <span class="n">get_nn_m</span><span class="p">(</span><span class="n">nn_input_features</span><span class="p">,</span> <span class="n">Ny</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="n">hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">current_model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model_in</span><span class="p">)</span>
    
    <span class="n">s_model</span> <span class="o">=</span> <span class="n">M1Struct</span><span class="p">(</span><span class="n">current_model</span><span class="p">)</span> <span class="c1"># Wrap in our nn.Module compatible struct</span>

    <span class="c1"># Setup loss function (already a callable, e.g., nn.MSELoss())</span>
    <span class="c1"># The Julia loss_m1 and loss_m1_λ handle denormalization and SGL.</span>
    <span class="c1"># For PyTorch, SGL needs to be added to the main loss calculation.</span>
    <span class="c1"># Denormalization is handled in nn_comp_1_fwd.</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss_val</span><span class="p">(</span><span class="n">model_wrapper</span><span class="p">:</span> <span class="n">M1Struct</span><span class="p">,</span> <span class="n">loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">y_b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_s</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">model_wrapper</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch_norm</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
                <span class="c1"># x_batch is (batch, features), y_batch_norm is (batch,)</span>
                <span class="n">y_hat_norm</span> <span class="o">=</span> <span class="n">model_wrapper</span><span class="o">.</span><span class="n">m</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="c1"># model_wrapper.m is the nn.Sequential</span>
                
                <span class="c1"># SGL term (if lambda_ &gt; 0)</span>
                <span class="n">sgl_penalty</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">lambda_</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">sgl_penalty</span> <span class="o">=</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">sparse_group_lasso</span><span class="p">(</span><span class="n">model_wrapper</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

                <span class="n">loss_val</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat_norm</span><span class="p">,</span> <span class="n">y_batch_norm</span><span class="p">)</span> <span class="o">+</span> <span class="n">sgl_penalty</span>
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss_val</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x_batch</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">count</span> <span class="o">+=</span> <span class="n">x_batch</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">count</span> <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span>


    <span class="c1"># Setup Adam optimizer</span>
    <span class="n">optimizer_adam</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">eta_adam</span><span class="p">)</span>

    <span class="c1"># Train NN with Adam optimizer</span>
    <span class="n">best_model_state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
    <span class="n">best_loss_val</span> <span class="o">=</span> <span class="n">compute_loss_val</span><span class="p">(</span><span class="n">s_model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">)</span>
    
    <span class="n">best_test_error_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">x_test_norm_transformed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_test_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_test_in</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Ensure l_segs_test is valid</span>
        <span class="n">valid_l_segs_test</span> <span class="o">=</span> <span class="n">l_segs_test</span> <span class="k">if</span> <span class="n">l_segs_test</span> <span class="ow">and</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs_test</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test_in</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test_in</span><span class="p">)]</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">err_test_init</span> <span class="o">=</span> <span class="n">nn_comp_1_test</span><span class="p">(</span><span class="n">x_test_norm_transformed</span><span class="p">,</span> <span class="n">y_test_in</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span>
                                          <span class="n">l_segs</span><span class="o">=</span><span class="n">valid_l_segs_test</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span><span class="p">)</span> <span class="c1"># type: ignore</span>
        <span class="n">best_test_error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_test_init</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_test_init</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>


    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: epoch 0: loss = </span><span class="si">{</span><span class="n">best_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epoch_adam</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">s_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch_norm</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">optimizer_adam</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">y_hat_norm</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            
            <span class="n">sgl_penalty</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">lambda_</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">sgl_penalty</span> <span class="o">=</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">sparse_group_lasso</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
            
            <span class="n">loss_train</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat_norm</span><span class="p">,</span> <span class="n">y_batch_norm</span><span class="p">)</span> <span class="o">+</span> <span class="n">sgl_penalty</span>
            <span class="n">loss_train</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer_adam</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">current_loss_val</span> <span class="o">=</span> <span class="n">compute_loss_val</span><span class="p">(</span><span class="n">s_model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">x_test_norm_transformed</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">y_test_in</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">y_test_in</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">:</span> <span class="c1"># No test set</span>
            <span class="k">if</span> <span class="n">current_loss_val</span> <span class="o">&lt;</span> <span class="n">best_loss_val</span><span class="p">:</span>
                <span class="n">best_loss_val</span> <span class="o">=</span> <span class="n">current_loss_val</span>
                <span class="n">best_model_state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">best_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># With test set</span>
            <span class="c1"># Ensure l_segs_test is valid</span>
            <span class="n">valid_l_segs_test</span> <span class="o">=</span> <span class="n">l_segs_test</span> <span class="k">if</span> <span class="n">l_segs_test</span> <span class="ow">and</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs_test</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test_in</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test_in</span><span class="p">)]</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">err_test_current</span> <span class="o">=</span> <span class="n">nn_comp_1_test</span><span class="p">(</span><span class="n">x_test_norm_transformed</span><span class="p">,</span> <span class="n">y_test_in</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span>
                                                 <span class="n">l_segs</span><span class="o">=</span><span class="n">valid_l_segs_test</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span><span class="p">)</span> <span class="c1"># type: ignore</span>
            <span class="n">current_test_error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_test_current</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_test_current</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">best_test_error_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">current_test_error_std</span> <span class="o">&lt;</span> <span class="n">best_test_error_std</span><span class="p">:</span>
                <span class="n">best_test_error_std</span> <span class="o">=</span> <span class="n">current_test_error_std</span>
                <span class="n">best_model_state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
            
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">current_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, test error = </span><span class="si">{</span><span class="n">best_test_error_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span> <span class="k">if</span> <span class="n">best_test_error_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;INFO: epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">current_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
            <span class="c1"># Evaluate on full training data (normalized)</span>
            <span class="c1"># Ensure l_segs is valid</span>
            <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="n">l_segs</span> <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">and</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">train_err_np</span> <span class="o">=</span> <span class="n">nn_comp_1_test</span><span class="p">(</span><span class="n">x_norm_torch</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span>
                                             <span class="n">l_segs</span><span class="o">=</span><span class="n">valid_l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># type: ignore</span>
            <span class="n">train_err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_err_np</span><span class="p">)</span> <span class="k">if</span> <span class="n">train_err_np</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> train error: </span><span class="si">{</span><span class="n">train_err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">x_test_norm_transformed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_test_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_test_in</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">best_test_error_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                 <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> test  error: </span><span class="si">{</span><span class="n">current_test_error_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>


    <span class="n">s_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_state</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">epoch_lbfgs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INFO: LBFGS training started.&quot;</span><span class="p">)</span>
        <span class="n">optimizer_lbfgs</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># lr is often 1 for LBFGS, but can be tuned. Max_iter in options.</span>
        
        <span class="c1"># LBFGS requires a closure function</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">closure</span><span class="p">():</span>
            <span class="n">optimizer_lbfgs</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="c1"># For LBFGS, usually train on the whole dataset or large batches</span>
            <span class="c1"># Using the full normalized training set (or a large single batch)</span>
            <span class="n">y_hat_norm_lbfgs</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">(</span><span class="n">x_norm_torch</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="c1"># x_norm_torch.T is (samples, features)</span>
            
            <span class="n">sgl_penalty_lbfgs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">lambda_</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">sgl_penalty_lbfgs</span> <span class="o">=</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">sparse_group_lasso</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
            
            <span class="n">loss_lbfgs</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat_norm_lbfgs</span><span class="p">,</span> <span class="n">y_norm_torch</span><span class="p">)</span> <span class="o">+</span> <span class="n">sgl_penalty_lbfgs</span>
            <span class="n">loss_lbfgs</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">loss_lbfgs</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_lbfgs</span><span class="p">):</span>
            <span class="n">optimizer_lbfgs</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>
            <span class="c1"># Optionally, log loss or evaluate validation set</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                 <span class="n">current_loss_lbfgs</span> <span class="o">=</span> <span class="n">closure</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="c1"># Re-evaluate for logging</span>
                 <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: LBFGS epoch </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">current_loss_lbfgs</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INFO: LBFGS training finished.&quot;</span><span class="p">)</span>


    <span class="c1"># Get final results on training data</span>
    <span class="c1"># Ensure l_segs is valid</span>
    <span class="n">valid_l_segs_final</span> <span class="o">=</span> <span class="n">l_segs</span> <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">and</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span>
    <span class="n">y_hat_final</span><span class="p">,</span> <span class="n">err_final</span> <span class="o">=</span> <span class="n">nn_comp_1_test</span><span class="p">(</span><span class="n">x_norm_torch</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span>
                                            <span class="n">l_segs</span><span class="o">=</span><span class="n">valid_l_segs_final</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># type: ignore</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: train error: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_final</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span> <span class="k">if</span> <span class="n">err_final</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;INFO: train error: N/A&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">x_test_norm_transformed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_test_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_test_in</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Ensure l_segs_test is valid</span>
        <span class="n">valid_l_segs_test_final</span> <span class="o">=</span> <span class="n">l_segs_test</span> <span class="k">if</span> <span class="n">l_segs_test</span> <span class="ow">and</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs_test</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test_in</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test_in</span><span class="p">)]</span>
        <span class="n">nn_comp_1_test</span><span class="p">(</span><span class="n">x_test_norm_transformed</span><span class="p">,</span> <span class="n">y_test_in</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span>
                       <span class="n">l_segs</span><span class="o">=</span><span class="n">valid_l_segs_test_final</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span> <span class="c1"># type: ignore</span>

    <span class="n">final_model_chain</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span>
    
    <span class="k">return</span> <span class="n">final_model_chain</span><span class="p">,</span> <span class="n">data_norms_out</span><span class="p">,</span> <span class="n">y_hat_final</span><span class="p">,</span> <span class="n">err_final</span></div>



<div class="viewcode-block" id="nn_comp_1_fwd">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_1_fwd">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_1_fwd</span><span class="p">(</span>
    <span class="n">x_norm_in</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> 
    <span class="n">y_bias</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> 
    <span class="n">y_scale</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> 
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span>
    <span class="n">denorm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">testmode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># In PyTorch, model.eval() is used instead of a flag during forward</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>

    <span class="k">if</span> <span class="n">testmode</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="c1"># Set back to train mode if it was changed</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_norm_in</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="c1"># Assuming x_norm_in is (features, samples) from Julia&#39;s perspective</span>
        <span class="c1"># PyTorch nn.Linear expects (batch/samples, features)</span>
        <span class="n">x_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_norm_in</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> 
    <span class="k">else</span><span class="p">:</span> <span class="c1"># Already a torch tensor</span>
        <span class="n">x_torch</span> <span class="o">=</span> <span class="n">x_norm_in</span><span class="o">.</span><span class="n">T</span> <span class="c1"># Assuming (features, samples) -&gt; (samples, features)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># Important for inference</span>
        <span class="n">y_hat_norm_torch</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_torch</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    
    <span class="n">y_hat_norm_np</span> <span class="o">=</span> <span class="n">y_hat_norm_torch</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="n">y_hat_np</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="k">if</span> <span class="n">denorm</span><span class="p">:</span>
        <span class="n">y_hat_np</span> <span class="o">=</span> <span class="n">denorm_sets</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_bias</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_scale</span><span class="p">),</span> <span class="n">y_hat_norm_np</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y_hat_np</span> <span class="o">=</span> <span class="n">y_hat_norm_np</span>
        
    <span class="k">return</span> <span class="n">y_hat_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span></div>



<span class="c1"># Overloaded version of nn_comp_1_fwd</span>
<div class="viewcode-block" id="nn_comp_1_fwd_from_raw">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_1_fwd_from_raw">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_1_fwd_from_raw</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">data_norms</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span> <span class="c1"># Should contain (_,_,v_scale,x_bias,x_scale,y_bias,y_scale)</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="n">x_f32</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Unpack data normalizations</span>
    <span class="c1"># Assuming data_norms has structure: (_, placeholder_v_scale_bias, v_scale_pca, x_bias_orig, x_scale_orig, y_bias, y_scale)</span>
    <span class="c1"># The first two elements are placeholders from Julia code.</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">v_scale_pca</span><span class="p">,</span> <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="n">unpack_data_norms</span><span class="p">(</span><span class="n">data_norms</span><span class="p">)</span>
    
    <span class="c1"># Normalize x: ( (x - x_bias) / x_scale ) @ v_scale_pca</span>
    <span class="c1"># Then transpose for model input (features, samples) -&gt; (samples, features) for PyTorch</span>
    <span class="n">x_norm_np_for_fwd</span> <span class="o">=</span> <span class="p">(((</span><span class="n">x_f32</span> <span class="o">-</span> <span class="n">x_bias</span><span class="p">)</span> <span class="o">/</span> <span class="n">x_scale</span><span class="p">)</span> <span class="o">@</span> <span class="n">v_scale_pca</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="c1"># This is (features, samples)</span>
    
    <span class="c1"># nn_comp_1_fwd expects (features, samples) if it&#39;s numpy, or (samples, features) if torch</span>
    <span class="c1"># The internal nn_comp_1_fwd will handle transpose if it&#39;s numpy</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">nn_comp_1_fwd</span><span class="p">(</span><span class="n">x_norm_np_for_fwd</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">denorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">testmode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_hat</span></div>



<div class="viewcode-block" id="nn_comp_1_test">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_1_test">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_1_test</span><span class="p">(</span>
    <span class="n">x_norm_in</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="c1"># (features, samples) if numpy, (samples, features) if torch</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">y_bias</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> 
    <span class="n">y_scale</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> 
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>

    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span>
    
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">nn_comp_1_fwd</span><span class="p">(</span><span class="n">x_norm_in</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">denorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">testmode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Ensure l_segs is valid for the length of y_hat/y</span>
    <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="n">l_segs</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: sum(l_segs)=</span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span><span class="si">}</span><span class="s2"> != len(y)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s2">. Using single segment.&quot;</span><span class="p">)</span>
        <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span>
        
    <span class="n">err</span> <span class="o">=</span> <span class="n">err_segs</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">valid_l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err</span><span class="p">)</span> <span class="k">if</span> <span class="n">err</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: test error: </span><span class="si">{</span><span class="n">err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">err</span></div>


<span class="c1"># Overloaded version of nn_comp_1_test</span>
<div class="viewcode-block" id="nn_comp_1_test_from_raw">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_1_test_from_raw">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_1_test_from_raw</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">data_norms</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span> 
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    
    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span>
    <span class="n">y_f32</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># y_hat is already denormalized by nn_comp_1_fwd_from_raw</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">nn_comp_1_fwd_from_raw</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    
    <span class="c1"># Ensure l_segs is valid</span>
    <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="n">l_segs</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_f32</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: sum(l_segs)=</span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span><span class="si">}</span><span class="s2"> != len(y)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y_f32</span><span class="p">)</span><span class="si">}</span><span class="s2">. Using single segment.&quot;</span><span class="p">)</span>
        <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_f32</span><span class="p">)]</span>

    <span class="n">err</span> <span class="o">=</span> <span class="n">err_segs</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y_f32</span><span class="p">,</span> <span class="n">valid_l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err</span><span class="p">)</span> <span class="k">if</span> <span class="n">err</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: test error: </span><span class="si">{</span><span class="n">err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">err</span></div>


<div class="viewcode-block" id="nn_comp_2_fwd">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_2_fwd">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_2_fwd</span><span class="p">(</span>
    <span class="n">A_norm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>      <span class="c1"># (TL_terms, samples)</span>
    <span class="n">x_norm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>      <span class="c1"># (features, samples)</span>
    <span class="n">y_bias</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">y_scale</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">model_nn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span> <span class="c1"># The core nn.Sequential model (s.m in Julia)</span>
    <span class="n">TL_coef_norm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="c1"># Normalized TL coefficients</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="c1"># &quot;m2a&quot;, &quot;m2b&quot;, &quot;m2c&quot;, &quot;m2d&quot;</span>
    <span class="n">denorm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">testmode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass of neural network-based aeromagnetic compensation, model 2.</span>
<span class="sd">    Assumes A_norm and x_norm are (features, samples) if numpy,</span>
<span class="sd">    and expects model_nn to take (samples, features_x).</span>
<span class="sd">    TL_coef_norm is expected to be a 1D array/tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">testmode</span><span class="p">:</span>
        <span class="n">model_nn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># If called during training, ensure model is in train mode if it has dropout/batchnorm</span>
        <span class="c1"># This is typically handled by the main training loop calling model.train()</span>
        <span class="k">pass</span> 

    <span class="n">is_torch_input</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">A_norm</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">A_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">A_norm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">A_norm_torch</span> <span class="o">=</span> <span class="n">A_norm</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="c1"># PyTorch nn.Linear expects (batch/samples, features)</span>
        <span class="n">x_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_norm</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x_norm_torch</span> <span class="o">=</span> <span class="n">x_norm</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># Assuming (features, samples) -&gt; (samples, features)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">TL_coef_norm</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">TL_coef_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">TL_coef_norm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">TL_coef_norm_torch</span> <span class="o">=</span> <span class="n">TL_coef_norm</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

    <span class="n">y_hat_norm_torch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span> <span class="k">if</span> <span class="n">testmode</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span> <span class="c1"># Ensure no_grad for pure inference</span>
        <span class="n">nn_output</span> <span class="o">=</span> <span class="n">model_nn</span><span class="p">(</span><span class="n">x_norm_torch</span><span class="p">)</span> <span class="c1"># (samples, nn_output_features)</span>

        <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m2a&quot;</span><span class="p">,</span> <span class="s2">&quot;m2d&quot;</span><span class="p">]:</span>
            <span class="c1"># NN output shape should be (samples, num_TL_terms) for these models</span>
            <span class="c1"># A_norm_torch is (TL_terms, samples)</span>
            <span class="c1"># nn_output is (samples, TL_terms)</span>
            <span class="c1"># We need element-wise product then sum over TL_terms</span>
            <span class="c1"># (A_norm_torch.T * nn_output) -&gt; (samples, TL_terms) element-wise</span>
            <span class="c1"># sum over dim=1 -&gt; (samples,)</span>
            <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;m2a&quot;</span><span class="p">:</span>
                <span class="c1"># y_hat = vec(sum(A_norm.*m(x_norm), dims=1))</span>
                <span class="c1"># m(x_norm) shape is (num_TL_terms, samples) in Julia after transpose</span>
                <span class="c1"># A_norm shape is (num_TL_terms, samples)</span>
                <span class="c1"># Python: nn_output is (samples, num_TL_terms), A_norm_torch.T is (samples, num_TL_terms)</span>
                <span class="n">y_hat_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A_norm_torch</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">nn_output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;m2d&quot;</span><span class="p">:</span>
                <span class="c1"># y_hat = vec(sum(A_norm.*(m(x_norm) .+ TL_coef_norm), dims=1))</span>
                <span class="c1"># m(x_norm) .+ TL_coef_norm -&gt; TL_coef_norm needs to broadcast or match shape</span>
                <span class="c1"># TL_coef_norm_torch is (num_TL_terms), nn_output is (samples, num_TL_terms)</span>
                <span class="c1"># A_norm_torch.T is (samples, num_TL_terms)</span>
                <span class="n">combined_coeffs</span> <span class="o">=</span> <span class="n">nn_output</span> <span class="o">+</span> <span class="n">TL_coef_norm_torch</span> <span class="c1"># Broadcasting TL_coef_norm</span>
                <span class="n">y_hat_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A_norm_torch</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">combined_coeffs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">elif</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m2b&quot;</span><span class="p">,</span> <span class="s2">&quot;m2c&quot;</span><span class="p">]:</span>
            <span class="c1"># NN output shape is (samples, 1)</span>
            <span class="c1"># y_hat = vec(m(x_norm)) + A_norm&#39;*TL_coef_norm</span>
            <span class="c1"># A_norm_torch is (TL_terms, samples), TL_coef_norm_torch is (TL_terms)</span>
            <span class="c1"># A_norm_torch.T @ TL_coef_norm_torch -&gt; (samples, TL_terms) @ (TL_terms) -&gt; (samples,)</span>
            <span class="n">tl_effect</span> <span class="o">=</span> <span class="n">A_norm_torch</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">TL_coef_norm_torch</span>
            <span class="n">y_hat_norm_torch</span> <span class="o">=</span> <span class="n">nn_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">+</span> <span class="n">tl_effect</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown model_type for nn_comp_2_fwd: </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">y_hat_norm_np</span> <span class="o">=</span> <span class="n">y_hat_norm_torch</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">is_torch_input</span> <span class="ow">or</span> <span class="n">testmode</span> <span class="k">else</span> <span class="n">y_hat_norm_torch</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>


    <span class="n">y_hat_np</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="k">if</span> <span class="n">denorm</span><span class="p">:</span>
        <span class="n">_y_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_bias</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_bias</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span><span class="nb">int</span><span class="p">))</span> <span class="k">else</span> <span class="n">y_bias</span>
        <span class="n">_y_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_scale</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scale</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span><span class="nb">int</span><span class="p">))</span> <span class="k">else</span> <span class="n">y_scale</span>
        <span class="n">y_hat_np</span> <span class="o">=</span> <span class="n">denorm_sets</span><span class="p">(</span><span class="n">_y_bias</span><span class="p">,</span> <span class="n">_y_scale</span><span class="p">,</span> <span class="n">y_hat_norm_np</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y_hat_np</span> <span class="o">=</span> <span class="n">y_hat_norm_np</span>
        
    <span class="k">return</span> <span class="n">y_hat_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span></div>


<div class="viewcode-block" id="nn_comp_2_fwd_from_raw">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_2_fwd_from_raw">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_2_fwd_from_raw</span><span class="p">(</span>
    <span class="n">A_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples, TL_terms)</span>
    <span class="n">x_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples, features)</span>
    <span class="n">data_norms</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span>      <span class="c1"># (A_bias, A_scale, v_scale_pca, x_bias, x_scale, y_bias, y_scale)</span>
    <span class="n">model_nn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">TL_coef</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>     <span class="c1"># Raw (not normalized) TL coefficients</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass of neural network-based aeromagnetic compensation, model 2, from raw inputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">A_raw_f32</span> <span class="o">=</span> <span class="n">A_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x_raw_f32</span> <span class="o">=</span> <span class="n">x_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">TL_coef_f32</span> <span class="o">=</span> <span class="n">TL_coef</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">A_bias</span><span class="p">,</span> <span class="n">A_scale</span><span class="p">,</span> <span class="n">v_scale_pca</span><span class="p">,</span> <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="n">unpack_data_norms</span><span class="p">(</span><span class="n">data_norms</span><span class="p">)</span>

    <span class="c1"># Normalize A: ((A_raw - A_bias) / A_scale).T -&gt; (TL_terms, samples)</span>
    <span class="n">A_norm_np</span> <span class="o">=</span> <span class="p">((</span><span class="n">A_raw_f32</span> <span class="o">-</span> <span class="n">A_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">A_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">A_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">T</span>
    
    <span class="c1"># Normalize x: (((x_raw - x_bias) / x_scale) @ v_scale_pca).T -&gt; (PCA_features, samples)</span>
    <span class="n">x_norm_step1</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_raw_f32</span> <span class="o">-</span> <span class="n">x_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">x_norm_np</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_norm_step1</span> <span class="o">@</span> <span class="n">v_scale_pca</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># Normalize TL_coef: TL_coef / y_scale</span>
    <span class="c1"># Ensure y_scale is not zero</span>
    <span class="n">y_scale_eff</span> <span class="o">=</span> <span class="n">y_scale</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scale</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">y_scale</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">y_scale</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">(</span><span class="n">y_scale</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scale</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span> <span class="ow">and</span> <span class="n">y_scale</span> <span class="o">!=</span><span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scale_eff</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">y_scale_eff</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span> <span class="c1"># Should be scalar for this context</span>
        <span class="n">y_scale_val</span> <span class="o">=</span> <span class="n">y_scale_eff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">y_scale_eff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scale_eff</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
         <span class="n">y_scale_val</span> <span class="o">=</span> <span class="n">y_scale_eff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">y_scale_eff</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">y_scale_eff</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># float</span>
        <span class="n">y_scale_val</span> <span class="o">=</span> <span class="n">y_scale_eff</span> <span class="k">if</span> <span class="n">y_scale_eff</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span>

    <span class="n">TL_coef_norm_np</span> <span class="o">=</span> <span class="n">TL_coef_f32</span> <span class="o">/</span> <span class="n">y_scale_val</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">nn_comp_2_fwd</span><span class="p">(</span>
        <span class="n">A_norm_np</span><span class="p">,</span> <span class="n">x_norm_np</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">model_nn</span><span class="p">,</span>
        <span class="n">TL_coef_norm_np</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">denorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">testmode</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">y_hat</span></div>

<div class="viewcode-block" id="nn_comp_2_test">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_2_test">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_2_test</span><span class="p">(</span>
    <span class="n">A_norm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>      <span class="c1"># (TL_terms, samples)</span>
    <span class="n">x_norm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>      <span class="c1"># (features, samples)</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>                                <span class="c1"># Raw target vector (samples,)</span>
    <span class="n">y_bias</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">y_scale</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">model_nn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span>
    <span class="n">TL_coef_norm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate performance of neural network-based aeromagnetic compensation, model 2.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_flat</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">)]</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">nn_comp_2_fwd</span><span class="p">(</span>
        <span class="n">A_norm</span><span class="p">,</span> <span class="n">x_norm</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">model_nn</span><span class="p">,</span>
        <span class="n">TL_coef_norm</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">denorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">testmode</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    
    <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="n">l_segs</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: sum(l_segs)=</span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span><span class="si">}</span><span class="s2"> != len(y)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">)</span><span class="si">}</span><span class="s2">. Using single segment.&quot;</span><span class="p">)</span>
        <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">)]</span>

    <span class="n">err_val</span> <span class="o">=</span> <span class="n">err_segs</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y_flat</span><span class="p">,</span> <span class="n">valid_l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_val</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_val</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: test error: </span><span class="si">{</span><span class="n">err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">err_val</span></div>


<div class="viewcode-block" id="nn_comp_2_test_from_raw">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_2_test_from_raw">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_2_test_from_raw</span><span class="p">(</span>
    <span class="n">A_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples, TL_terms)</span>
    <span class="n">x_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples, features)</span>
    <span class="n">y_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples,)</span>
    <span class="n">data_norms</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span>      <span class="c1"># (A_bias, A_scale, v_scale_pca, x_bias, x_scale, y_bias, y_scale)</span>
    <span class="n">model_nn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">TL_coef</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>    <span class="c1"># Raw (not normalized) TL coefficients</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate performance of neural network-based aeromagnetic compensation, model 2, from raw inputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_raw_flat</span> <span class="o">=</span> <span class="n">y_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_raw_flat</span><span class="p">)]</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">nn_comp_2_fwd_from_raw</span><span class="p">(</span>
        <span class="n">A_raw</span><span class="p">,</span> <span class="n">x_raw</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">model_nn</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">TL_coef</span>
    <span class="p">)</span>
    
    <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="n">l_segs</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_raw_flat</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: sum(l_segs)=</span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span><span class="si">}</span><span class="s2"> != len(y)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y_raw_flat</span><span class="p">)</span><span class="si">}</span><span class="s2">. Using single segment.&quot;</span><span class="p">)</span>
        <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_raw_flat</span><span class="p">)]</span>
        
    <span class="n">err_val</span> <span class="o">=</span> <span class="n">err_segs</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y_raw_flat</span><span class="p">,</span> <span class="n">valid_l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_val</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_val</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: test error: </span><span class="si">{</span><span class="n">err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">err_val</span></div>

<div class="viewcode-block" id="nn_comp_2_train">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_2_train">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_2_train</span><span class="p">(</span>
    <span class="n">A</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples, TL_terms)</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples, features)</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples,)</span>
    <span class="n">no_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;m2a&quot;</span><span class="p">,</span> <span class="c1"># :m2a, :m2b, :m2c, :m2d</span>
    <span class="n">norm_type_A</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">norm_type_x</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;standardize&quot;</span><span class="p">,</span>
    <span class="n">norm_type_y</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="c1"># Note: Julia default is :none for y in m2</span>
    <span class="n">TL_coef_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Renamed from TL_coef</span>
    <span class="n">eta_adam</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="n">epoch_adam</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="n">epoch_lbfgs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">hidden</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">,</span> <span class="c1"># swish</span>
    <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span> <span class="c1"># Renamed from loss</span>
    <span class="n">batchsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="n">frac_train</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">14</span><span class="o">/</span><span class="mi">17</span><span class="p">,</span>
    <span class="n">alpha_sgl</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">lambda_sgl</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">k_pca</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">data_norms_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># (A_bias,A_scale,v_scale_pca,x_bias,x_scale,y_bias,y_scale)</span>
    <span class="n">model_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">A_test_raw</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Renamed from A_test</span>
    <span class="n">x_test_raw</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Renamed from x_test</span>
    <span class="n">y_test_raw</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Renamed from y_test</span>
    <span class="n">l_segs_test</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train neural network-based aeromagnetic compensation, model 2.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">TL_coef_in</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Determine number of TL terms from A matrix if possible, else default (e.g. 18)</span>
        <span class="n">num_tl_terms</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">A</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">18</span>
        <span class="n">TL_coef_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_tl_terms</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Convert to Float32</span>
    <span class="n">A_f32</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x_f32</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">y_f32</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">alpha_sgl</span><span class="p">)</span>
    <span class="n">lambda_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">lambda_sgl</span><span class="p">)</span>
    <span class="n">TL_coef_f32</span> <span class="o">=</span> <span class="n">TL_coef_in</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">A_test_f32</span> <span class="o">=</span> <span class="n">A_test_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">A_test_raw</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="n">A_f32</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x_test_f32</span> <span class="o">=</span> <span class="n">x_test_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">x_test_raw</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="n">x_f32</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">y_test_f32</span> <span class="o">=</span> <span class="n">y_test_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">if</span> <span class="n">y_test_raw</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">no_norm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">no_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x_f32</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_f32</span><span class="p">)]</span>
    <span class="k">if</span> <span class="n">l_segs_test</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">l_segs_test</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test_f32</span><span class="p">)]</span>


    <span class="n">Nf</span> <span class="o">=</span> <span class="n">x_f32</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># number of features for x</span>

    <span class="c1"># Normalization</span>
    <span class="n">A_bias</span><span class="p">,</span> <span class="n">A_scale</span><span class="p">,</span> <span class="n">v_scale_pca</span><span class="p">,</span> <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span><span class="o">*</span><span class="mi">7</span>
    
    <span class="k">if</span> <span class="n">data_norms_in</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">data_norms_in</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">:</span> <span class="c1"># data_norms_in[6] is y_scale</span>
        <span class="n">A_bias</span><span class="p">,</span> <span class="n">A_scale</span><span class="p">,</span> <span class="n">A_norm_np</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">A_f32</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_A</span><span class="p">)</span> <span class="c1"># A_norm_np is (samples, TL_terms)</span>
        <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">x_norm_np_orig</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">x_f32</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_x</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm</span><span class="p">)</span> <span class="c1"># x_norm_np_orig is (samples, features)</span>
        <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">y_norm_np</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">y_f32</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_y</span><span class="p">)</span> <span class="c1"># y_norm_np is (samples,)</span>

        <span class="k">if</span> <span class="n">k_pca</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">k_pca</span> <span class="o">&gt;</span> <span class="n">Nf</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: reducing k_pca from </span><span class="si">{</span><span class="n">k_pca</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">Nf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">k_pca</span> <span class="o">=</span> <span class="n">Nf</span>
            <span class="k">if</span> <span class="n">x_norm_np_orig</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">cov_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x_norm_np_orig</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">S_svd</span><span class="p">,</span> <span class="n">V_svd_T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">cov_x</span><span class="p">)</span> <span class="c1"># V_svd_T is V.T</span>
                <span class="n">V_svd</span> <span class="o">=</span> <span class="n">V_svd_T</span><span class="o">.</span><span class="n">T</span>
                <span class="c1"># Ensure S_svd has k_pca elements, pad with small value if fewer</span>
                <span class="n">S_svd_padded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">S_svd</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k_pca</span> <span class="o">-</span> <span class="n">S_svd</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span> <span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>

                <span class="n">v_scale_pca</span> <span class="o">=</span> <span class="n">V_svd</span><span class="p">[:,</span> <span class="p">:</span><span class="n">k_pca</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S_svd_padded</span><span class="p">[:</span><span class="n">k_pca</span><span class="p">]))</span>
                <span class="n">var_ret</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S_svd_padded</span><span class="p">[:</span><span class="n">k_pca</span><span class="p">]))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S_svd_padded</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: k_pca = </span><span class="si">{</span><span class="n">k_pca</span><span class="si">}</span><span class="s2"> of </span><span class="si">{</span><span class="n">Nf</span><span class="si">}</span><span class="s2">, variance retained: </span><span class="si">{</span><span class="n">var_ret</span><span class="si">}</span><span class="s2"> %&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WARN: Not enough samples (</span><span class="si">{</span><span class="n">x_norm_np_orig</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">) for PCA. Using identity for v_scale_pca.&quot;</span><span class="p">)</span>
                <span class="n">v_scale_pca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">Nf</span><span class="p">,</span> <span class="n">k_pca</span> <span class="k">if</span> <span class="n">k_pca</span> <span class="o">&lt;=</span> <span class="n">Nf</span> <span class="k">else</span> <span class="n">Nf</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># Ensure correct shape if k_pca &gt; Nf</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">v_scale_pca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">Nf</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="c1"># Transpose for PyTorch convention (features, samples)</span>
        <span class="n">A_norm_transposed</span> <span class="o">=</span> <span class="n">A_norm_np</span><span class="o">.</span><span class="n">T</span>   <span class="c1"># (TL_terms, samples)</span>
        <span class="n">x_norm_transformed_transposed</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_norm_np_orig</span> <span class="o">@</span> <span class="n">v_scale_pca</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="c1"># (PCA_features, samples)</span>
        <span class="n">y_norm_transposed</span> <span class="o">=</span> <span class="n">y_norm_np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># (1, samples)</span>

        <span class="n">data_norms_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_bias</span><span class="p">,</span> <span class="n">A_scale</span><span class="p">,</span> <span class="n">v_scale_pca</span><span class="p">,</span> <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">A_bias</span><span class="p">,</span> <span class="n">A_scale</span><span class="p">,</span> <span class="n">v_scale_pca</span><span class="p">,</span> <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="n">unpack_data_norms</span><span class="p">(</span><span class="n">data_norms_in</span><span class="p">)</span> <span class="c1"># type: ignore</span>
        <span class="n">A_norm_transposed</span> <span class="o">=</span> <span class="p">((</span><span class="n">A_f32</span> <span class="o">-</span> <span class="n">A_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">A_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">A_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">T</span>
        <span class="n">x_norm_orig</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_f32</span> <span class="o">-</span> <span class="n">x_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">x_norm_transformed_transposed</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_norm_orig</span> <span class="o">@</span> <span class="n">v_scale_pca</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">y_norm_transposed</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_f32</span> <span class="o">-</span> <span class="n">y_bias</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_scale</span> <span class="k">if</span> <span class="n">y_scale</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">data_norms_out</span> <span class="o">=</span> <span class="n">data_norms_in</span>

    <span class="c1"># Normalize TL_coef (y_scale can be float or array)</span>
    <span class="n">y_scale_val</span> <span class="o">=</span> <span class="n">y_scale</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scale</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">y_scale</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">(</span><span class="n">y_scale</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scale</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span><span class="nb">int</span><span class="p">))</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">y_scale_val</span> <span class="o">=</span> <span class="n">y_scale_val</span> <span class="k">if</span> <span class="n">y_scale_val</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span> <span class="c1"># Avoid division by zero</span>
    <span class="n">TL_coef_norm_np</span> <span class="o">=</span> <span class="n">TL_coef_f32</span> <span class="o">/</span> <span class="n">y_scale_val</span>

    <span class="c1"># Normalize test data if provided</span>
    <span class="n">A_test_norm_transposed</span><span class="p">,</span> <span class="n">x_test_norm_transformed_transposed</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">A_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">A_test_norm_transposed</span> <span class="o">=</span> <span class="p">((</span><span class="n">A_test_f32</span> <span class="o">-</span> <span class="n">A_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">A_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">A_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">T</span>
    <span class="k">if</span> <span class="n">x_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">x_test_norm_orig</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_test_f32</span> <span class="o">-</span> <span class="n">x_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">x_test_norm_transformed_transposed</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_test_norm_orig</span> <span class="o">@</span> <span class="n">v_scale_pca</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># PyTorch Tensors: DataLoader expects (samples, features)</span>
    <span class="n">A_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">A_norm_transposed</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> <span class="c1"># (samples, TL_terms)</span>
    <span class="n">x_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_norm_transformed_transposed</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> <span class="c1"># (samples, PCA_features)</span>
    <span class="n">y_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_norm_transposed</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> <span class="c1"># (samples,)</span>
    <span class="n">TL_coef_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">TL_coef_norm_np</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

    <span class="c1"># Training/Validation Split</span>
    <span class="k">if</span> <span class="n">frac_train</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="n">x_norm_torch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Use get_split for consistent splitting logic if temporal aspects are important later</span>
        <span class="c1"># For now, simple random permutation for non-temporal split:</span>
        <span class="c1"># indices = np.random.permutation(num_samples)</span>
        <span class="c1"># split_idx = int(np.floor(num_samples * frac_train))</span>
        <span class="c1"># train_indices, val_indices = indices[:split_idx], indices[split_idx:]</span>
        <span class="n">train_indices</span><span class="p">,</span> <span class="n">val_indices</span> <span class="o">=</span> <span class="n">get_split</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">frac_train</span><span class="p">,</span> <span class="n">window_type</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span> <span class="c1"># Assuming non-temporal for M2 split</span>

        <span class="n">A_train_norm_torch</span><span class="p">,</span> <span class="n">x_train_norm_torch</span><span class="p">,</span> <span class="n">y_train_norm_torch</span> <span class="o">=</span> <span class="n">A_norm_torch</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">x_norm_torch</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">y_norm_torch</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
        <span class="n">A_val_norm_torch</span><span class="p">,</span> <span class="n">x_val_norm_torch</span><span class="p">,</span> <span class="n">y_val_norm_torch</span> <span class="o">=</span> <span class="n">A_norm_torch</span><span class="p">[</span><span class="n">val_indices</span><span class="p">],</span> <span class="n">x_norm_torch</span><span class="p">[</span><span class="n">val_indices</span><span class="p">],</span> <span class="n">y_norm_torch</span><span class="p">[</span><span class="n">val_indices</span><span class="p">]</span>
        
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">A_train_norm_torch</span><span class="p">,</span> <span class="n">x_train_norm_torch</span><span class="p">,</span> <span class="n">y_train_norm_torch</span><span class="p">)</span>
        <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">A_val_norm_torch</span><span class="p">,</span> <span class="n">x_val_norm_torch</span><span class="p">,</span> <span class="n">y_val_norm_torch</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">A_norm_torch</span><span class="p">,</span> <span class="n">x_norm_torch</span><span class="p">,</span> <span class="n">y_norm_torch</span><span class="p">)</span>
        <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span> <span class="c1"># Use full dataset for validation if frac_train is 1</span>

    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Setup NN model</span>
    <span class="n">current_nn_model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span>
    <span class="n">nn_input_features</span> <span class="o">=</span> <span class="n">x_norm_transformed_transposed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># Number of PCA features</span>
    
    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m2a&quot;</span><span class="p">,</span> <span class="s2">&quot;m2d&quot;</span><span class="p">]:</span>
        <span class="n">Ny_nn</span> <span class="o">=</span> <span class="n">A_norm_transposed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># NN outputs a coefficient for each TL term</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># m2b, m2c</span>
        <span class="n">Ny_nn</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># NN outputs a scalar correction</span>
        
    <span class="k">if</span> <span class="n">model_in</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">list</span><span class="p">(</span><span class="n">model_in</span><span class="o">.</span><span class="n">children</span><span class="p">()):</span>
        <span class="n">current_nn_model</span> <span class="o">=</span> <span class="n">get_nn_m</span><span class="p">(</span><span class="n">nn_input_features</span><span class="p">,</span> <span class="n">Ny_nn</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="n">hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">current_nn_model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model_in</span><span class="p">)</span>

    <span class="c1"># Setup combined model structure (M2Struct or M2StructMOnly)</span>
    <span class="c1"># TL_coef_norm_torch is already prepared</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;m2c&quot;</span><span class="p">:</span> <span class="c1"># TL_coef_norm is trainable</span>
        <span class="n">s_model</span> <span class="o">=</span> <span class="n">M2Struct</span><span class="p">(</span><span class="n">current_nn_model</span><span class="p">,</span> <span class="n">TL_coef_norm_torch</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># m2a, m2b, m2d: TL_coef_norm is fixed or handled outside direct NN optimization</span>
        <span class="n">s_model</span> <span class="o">=</span> <span class="n">M2StructMOnly</span><span class="p">(</span><span class="n">current_nn_model</span><span class="p">,</span> <span class="n">TL_coef_norm_torch</span><span class="p">)</span>

    <span class="c1"># Loss function (will be called within the training loop)</span>
    <span class="c1"># The loss needs to compute y_hat_norm using nn_comp_2_fwd (with denorm=False)</span>
    <span class="c1"># and then apply the base loss_fn (e.g., MSELoss)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss_val_m2</span><span class="p">(</span><span class="n">model_wrapper</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">M2Struct</span><span class="p">,</span> <span class="n">M2StructMOnly</span><span class="p">],</span> <span class="n">loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">model_wrapper</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">A_b_norm</span><span class="p">,</span> <span class="n">x_b_norm</span><span class="p">,</span> <span class="n">y_b_norm</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
                <span class="c1"># nn_comp_2_fwd expects (features, samples) for numpy,</span>
                <span class="c1"># but here we pass tensors directly.</span>
                <span class="c1"># A_b_norm: (batch, TL_terms), x_b_norm: (batch, PCA_features)</span>
                <span class="c1"># y_b_norm: (batch,)</span>
                <span class="c1"># TL_coef_norm is taken from model_wrapper</span>
                
                <span class="n">y_hat_b_norm</span> <span class="o">=</span> <span class="n">nn_comp_2_fwd</span><span class="p">(</span>
                    <span class="n">A_b_norm</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">x_b_norm</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="c1"># Pass as (features, batch)</span>
                    <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="c1"># Dummy bias/scale as we want normalized output</span>
                    <span class="n">model_wrapper</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> 
                    <span class="n">model_wrapper</span><span class="o">.</span><span class="n">TL_coef_norm</span><span class="p">,</span> <span class="c1"># Use the one from the struct</span>
                    <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span>
                    <span class="n">denorm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                    <span class="n">testmode</span><span class="o">=</span><span class="kc">True</span> <span class="c1"># Already in no_grad context</span>
                <span class="p">)</span>
                <span class="n">y_hat_b_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_hat_b_norm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
                
                <span class="n">current_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat_b_norm_torch</span><span class="p">,</span> <span class="n">y_b_norm</span><span class="p">)</span>
                <span class="c1"># SGL penalty (if applicable)</span>
                <span class="k">if</span> <span class="n">lambda_</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">sgl_penalty</span> <span class="o">=</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">sparse_group_lasso</span><span class="p">(</span><span class="n">model_wrapper</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
                    <span class="n">current_loss</span> <span class="o">+=</span> <span class="n">sgl_penalty</span>
                
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">current_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x_b_norm</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">count</span> <span class="o">+=</span> <span class="n">x_b_norm</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">count</span> <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span>

    <span class="c1"># Optimizer</span>
    <span class="n">optimizer_adam</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">eta_adam</span><span class="p">)</span> <span class="c1"># s_model.parameters() includes TL_coef_norm if M2Struct</span>

    <span class="c1"># Training loop (Adam)</span>
    <span class="n">best_model_state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
    <span class="n">best_loss_val</span> <span class="o">=</span> <span class="n">compute_loss_val_m2</span><span class="p">(</span><span class="n">s_model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
    
    <span class="n">best_test_error_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">x_test_norm_transformed_transposed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">A_test_norm_transposed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">err_test_init</span> <span class="o">=</span> <span class="n">nn_comp_2_test</span><span class="p">(</span>
            <span class="n">A_test_norm_transposed</span><span class="p">,</span> <span class="n">x_test_norm_transformed_transposed</span><span class="p">,</span> 
            <span class="n">y_test_f32</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> 
            <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_coef_norm</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">model_type</span><span class="p">,</span>
            <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_test</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span>
        <span class="p">)</span>
        <span class="n">best_test_error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_test_init</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_test_init</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M2 epoch 0: loss = </span><span class="si">{</span><span class="n">best_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epoch_adam</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">s_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">A_batch_norm</span><span class="p">,</span> <span class="n">x_batch_norm</span><span class="p">,</span> <span class="n">y_batch_norm_target</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="c1"># A_batch_norm: (batch, TL_terms), x_batch_norm: (batch, PCA_features)</span>
            <span class="c1"># y_batch_norm_target: (batch,)</span>
            <span class="n">optimizer_adam</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            
            <span class="c1"># Forward pass for loss calculation (normalized)</span>
            <span class="n">y_hat_batch_norm</span> <span class="o">=</span> <span class="n">nn_comp_2_fwd</span><span class="p">(</span>
                <span class="n">A_batch_norm</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">x_batch_norm</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="c1"># Pass as (features, batch)</span>
                <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="c1"># Dummy bias/scale for normalized output</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> 
                <span class="n">s_model</span><span class="o">.</span><span class="n">TL_coef_norm</span><span class="p">,</span> <span class="c1"># Use current TL_coef_norm from model</span>
                <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span>
                <span class="n">denorm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">testmode</span><span class="o">=</span><span class="kc">False</span> <span class="c1"># Important: ensure gradients flow</span>
            <span class="p">)</span>
            <span class="n">y_hat_batch_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_hat_batch_norm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            
            <span class="n">loss_train_val</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat_batch_norm_torch</span><span class="p">,</span> <span class="n">y_batch_norm_target</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">lambda_</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">sgl_penalty</span> <span class="o">=</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">sparse_group_lasso</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
                <span class="n">loss_train_val</span> <span class="o">+=</span> <span class="n">sgl_penalty</span>
            
            <span class="n">loss_train_val</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer_adam</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">current_loss_val</span> <span class="o">=</span> <span class="n">compute_loss_val_m2</span><span class="p">(</span><span class="n">s_model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">x_test_norm_transformed_transposed</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">y_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">A_test_norm_transposed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">current_loss_val</span> <span class="o">&lt;</span> <span class="n">best_loss_val</span><span class="p">:</span>
                <span class="n">best_loss_val</span> <span class="o">=</span> <span class="n">current_loss_val</span>
                <span class="n">best_model_state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M2 epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">best_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">err_test_current</span> <span class="o">=</span> <span class="n">nn_comp_2_test</span><span class="p">(</span>
                <span class="n">A_test_norm_transposed</span><span class="p">,</span> <span class="n">x_test_norm_transformed_transposed</span><span class="p">,</span>
                <span class="n">y_test_f32</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_coef_norm</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">model_type</span><span class="p">,</span>
                <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_test</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span>
            <span class="p">)</span>
            <span class="n">current_test_error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_test_current</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_test_current</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">best_test_error_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">current_test_error_std</span> <span class="o">&lt;</span> <span class="n">best_test_error_std</span><span class="p">:</span>
                <span class="n">best_test_error_std</span> <span class="o">=</span> <span class="n">current_test_error_std</span>
                <span class="n">best_model_state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
            
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M2 epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">current_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, test error = </span><span class="si">{</span><span class="n">best_test_error_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span> <span class="k">if</span> <span class="n">best_test_error_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;INFO: M2 epoch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">current_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># Optional: Log full training set error periodically</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">train_err_np</span> <span class="o">=</span> <span class="n">nn_comp_2_test</span><span class="p">(</span>
                <span class="n">A_norm_transposed</span><span class="p">,</span> <span class="n">x_norm_transformed_transposed</span><span class="p">,</span> <span class="c1"># Full normalized training data</span>
                <span class="n">y_f32</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> 
                <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_coef_norm</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">model_type</span><span class="p">,</span>
                <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">train_err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_err_np</span><span class="p">)</span> <span class="k">if</span> <span class="n">train_err_np</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M2 </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> train error: </span><span class="si">{</span><span class="n">train_err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>


    <span class="n">s_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_state</span><span class="p">)</span>
    <span class="n">final_TL_coef_norm</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_coef_norm</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># Get the best TL_coef_norm</span>

    <span class="c1"># LBFGS optimization (if epoch_lbfgs &gt; 0)</span>
    <span class="k">if</span> <span class="n">epoch_lbfgs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INFO: M2 LBFGS training started.&quot;</span><span class="p">)</span>
        <span class="n">optimizer_lbfgs</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># lr often 1, PyTorch default is 1</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">closure_lbfgs_m2</span><span class="p">():</span>
            <span class="n">optimizer_lbfgs</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="c1"># Use full training dataset for LBFGS</span>
            <span class="n">y_hat_norm_lbfgs</span> <span class="o">=</span> <span class="n">nn_comp_2_fwd</span><span class="p">(</span>
                <span class="n">A_norm_torch</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">x_norm_torch</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="c1"># (features, N)</span>
                <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="c1"># Dummy for normalized output</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_coef_norm</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span>
                <span class="n">denorm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">testmode</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">y_hat_norm_lbfgs_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_hat_norm_lbfgs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            
            <span class="n">loss_val</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat_norm_lbfgs_torch</span><span class="p">,</span> <span class="n">y_norm_torch</span><span class="p">)</span> <span class="c1"># y_norm_torch is (N,)</span>
            <span class="k">if</span> <span class="n">lambda_</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">loss_val</span> <span class="o">+=</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">sparse_group_lasso</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
            <span class="n">loss_val</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">loss_val</span>

        <span class="k">for</span> <span class="n">i_lbfgs</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_lbfgs</span><span class="p">):</span>
            <span class="n">optimizer_lbfgs</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure_lbfgs_m2</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i_lbfgs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">current_loss_lbfgs</span> <span class="o">=</span> <span class="n">closure_lbfgs_m2</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M2 LBFGS epoch </span><span class="si">{</span><span class="n">i_lbfgs</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">current_loss_lbfgs</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INFO: M2 LBFGS training finished.&quot;</span><span class="p">)</span>
        <span class="n">final_TL_coef_norm</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_coef_norm</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># Update after LBFGS</span>

    <span class="c1"># Denormalize final TL coefficients</span>
    <span class="n">final_TL_coef</span> <span class="o">=</span> <span class="n">final_TL_coef_norm</span> <span class="o">*</span> <span class="n">y_scale_val</span>

    <span class="c1"># Final evaluation on training data</span>
    <span class="n">y_hat_final</span><span class="p">,</span> <span class="n">err_final</span> <span class="o">=</span> <span class="n">nn_comp_2_test</span><span class="p">(</span>
        <span class="n">A_norm_transposed</span><span class="p">,</span> <span class="n">x_norm_transformed_transposed</span><span class="p">,</span> <span class="n">y_f32</span><span class="p">,</span> 
        <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">final_TL_coef_norm</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span>
        <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> 
        <span class="n">err_std_final</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_final</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_final</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M2 final train error: </span><span class="si">{</span><span class="n">err_std_final</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>

    <span class="c1"># Final evaluation on test data if provided</span>
    <span class="k">if</span> <span class="n">x_test_norm_transformed_transposed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">A_test_norm_transposed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">nn_comp_2_test</span><span class="p">(</span>
            <span class="n">A_test_norm_transposed</span><span class="p">,</span> <span class="n">x_test_norm_transformed_transposed</span><span class="p">,</span> <span class="n">y_test_f32</span><span class="p">,</span>
            <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">final_TL_coef_norm</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span>
            <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_test</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span> <span class="c1"># Show test error if not silent overall</span>
        <span class="p">)</span>
        
    <span class="k">return</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">final_TL_coef</span><span class="p">,</span> <span class="n">data_norms_out</span><span class="p">,</span> <span class="n">y_hat_final</span><span class="p">,</span> <span class="n">err_final</span></div>

<div class="viewcode-block" id="nn_comp_3_fwd">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_3_fwd">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_3_fwd</span><span class="p">(</span>
    <span class="n">B_unit</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>      <span class="c1"># (3, samples)</span>
    <span class="n">B_vec</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>       <span class="c1"># (3, samples)</span>
    <span class="n">B_vec_dot</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>   <span class="c1"># (3, samples)</span>
    <span class="n">x_norm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>      <span class="c1"># (features, samples) or (features, window, samples) for temporal</span>
    <span class="n">y_bias</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">y_scale</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">model_nn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span>
    <span class="n">TL_coef_p</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>   <span class="c1"># (3,)</span>
    <span class="n">TL_coef_i_mat</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="c1"># (3,3)</span>
    <span class="n">TL_coef_e_mat</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="c1"># (3,3) or None</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>    <span class="c1"># :m3s, :m3v, :m3sc, :m3vc, :m3w, :m3tf</span>
    <span class="n">y_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>        <span class="c1"># :a, :b, :c, :d</span>
    <span class="n">use_nn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">denorm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">testmode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass of neural network-based aeromagnetic compensation, model 3.</span>
<span class="sd">    B_unit, B_vec, B_vec_dot are (3, samples).</span>
<span class="sd">    x_norm is (features, samples) or (features, window, samples) for temporal.</span>
<span class="sd">    TL_coef_p is (3,), TL_coef_i_mat is (3,3), TL_coef_e_mat is (3,3) or None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">y_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported y_type = </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2"> for nn_comp_3&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">testmode</span><span class="p">:</span>
        <span class="n">model_nn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="c1"># else: training mode is set by the main loop</span>

    <span class="c1"># Ensure inputs are PyTorch tensors for nn_comp_3_fwd internal logic</span>
    <span class="n">B_unit_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">B_unit</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">B_vec_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">B_vec</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">B_vec_dot_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">B_vec_dot</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">B_vec_dot</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">B_vec_dot</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">B_vec_th</span><span class="p">)</span>
    
    <span class="c1"># x_norm needs to be (samples, features) or (samples, window, features) for PyTorch model</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span> <span class="c1"># (features, window, samples) -&gt; (samples, window, features)</span>
            <span class="n">x_norm_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># (features, samples) -&gt; (samples, features)</span>
            <span class="n">x_norm_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_norm</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># Already a tensor</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span> <span class="c1"># Assuming (features, window, samples)</span>
             <span class="n">x_norm_th</span> <span class="o">=</span> <span class="n">x_norm</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># (samples, window, features)</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Assuming (features, samples)</span>
            <span class="n">x_norm_th</span> <span class="o">=</span> <span class="n">x_norm</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># (samples, features)</span>


    <span class="n">TL_coef_p_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">TL_coef_p</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">TL_coef_i_mat_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">TL_coef_i_mat</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">TL_coef_e_mat_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">TL_coef_e_mat</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">TL_coef_e_mat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">TL_coef_e_mat</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>
    
    <span class="n">y_hat_torch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span> <span class="k">if</span> <span class="n">testmode</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">():</span>
        <span class="c1"># Calculate TL aircraft field vector</span>
        <span class="c1"># get_TL_aircraft_vec expects (3,N) inputs</span>
        <span class="n">tl_aircraft_vec</span> <span class="o">=</span> <span class="n">get_TL_aircraft_vec</span><span class="p">(</span>
            <span class="n">B_vec_th</span><span class="p">,</span> <span class="n">B_vec_dot_th</span><span class="p">,</span> <span class="n">TL_coef_p_th</span><span class="p">,</span> <span class="n">TL_coef_i_mat_th</span><span class="p">,</span> <span class="n">TL_coef_e_mat_th</span><span class="p">,</span> <span class="n">return_parts</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span> <span class="c1"># Returns (3, N)</span>
        
        <span class="n">vec_aircraft_th</span> <span class="o">=</span> <span class="n">tl_aircraft_vec</span> <span class="c1"># (3, N)</span>

        <span class="k">if</span> <span class="n">use_nn</span><span class="p">:</span>
            <span class="n">nn_output</span> <span class="o">=</span> <span class="n">model_nn</span><span class="p">(</span><span class="n">x_norm_th</span><span class="p">)</span> <span class="c1"># (samples, nn_out_features)</span>
            <span class="c1"># nn_out_features is 3 for m3v/m3vc, 1 for m3s/m3sc/m3w/m3tf</span>

            <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3v&quot;</span><span class="p">,</span> <span class="s2">&quot;m3vc&quot;</span><span class="p">]:</span> <span class="c1"># vector NN correction</span>
                <span class="c1"># nn_output is (samples, 3), needs to be (3, samples)</span>
                <span class="n">vec_aircraft_th</span> <span class="o">=</span> <span class="n">vec_aircraft_th</span> <span class="o">+</span> <span class="n">nn_output</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">y_scale</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># Rescale NN part</span>
            <span class="c1"># For scalar models (m3s, m3sc, m3w, m3tf), NN correction is applied after projecting to scalar</span>
            
        <span class="c1"># Calculate y_hat based on y_type</span>
        <span class="k">if</span> <span class="n">y_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">]:</span> <span class="c1"># Aircraft field component along B_unit</span>
            <span class="c1"># vec_aircraft_th is (3,N), B_unit_th is (3,N)</span>
            <span class="c1"># Dot product for each sample: sum(vec_aircraft_th * B_unit_th, dim=0)</span>
            <span class="n">y_hat_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">vec_aircraft_th</span> <span class="o">*</span> <span class="n">B_unit_th</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># (N,)</span>
        <span class="k">elif</span> <span class="n">y_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">]:</span> <span class="c1"># Magnitude of Earth field</span>
            <span class="n">B_e_th</span> <span class="o">=</span> <span class="n">B_vec_th</span> <span class="o">-</span> <span class="n">vec_aircraft_th</span> <span class="c1"># (3,N)</span>
            <span class="n">y_hat_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">B_e_th</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># (N,)</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Should not happen due to earlier check</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;y_type </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2"> logic error in nn_comp_3_fwd&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">use_nn</span> <span class="ow">and</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3s&quot;</span><span class="p">,</span> <span class="s2">&quot;m3sc&quot;</span><span class="p">,</span> <span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span> <span class="c1"># scalar NN correction</span>
            <span class="n">nn_output_scalar</span> <span class="o">=</span> <span class="n">model_nn</span><span class="p">(</span><span class="n">x_norm_th</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="c1"># (samples,)</span>
            <span class="n">y_hat_torch</span> <span class="o">=</span> <span class="n">y_hat_torch</span> <span class="o">+</span> <span class="n">nn_output_scalar</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">y_scale</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># Rescale NN part</span>

    <span class="n">y_hat_norm_np</span> <span class="o">=</span> <span class="n">y_hat_torch</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_hat_torch</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">y_hat_torch</span> <span class="c1"># if already numpy</span>

    <span class="n">y_hat_final_np</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="k">if</span> <span class="n">denorm</span><span class="p">:</span>
        <span class="n">_y_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_bias</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_bias</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span><span class="nb">int</span><span class="p">))</span> <span class="k">else</span> <span class="n">y_bias</span>
        <span class="n">_y_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_scale</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scale</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span><span class="nb">int</span><span class="p">))</span> <span class="k">else</span> <span class="n">y_scale</span>
        <span class="n">y_hat_final_np</span> <span class="o">=</span> <span class="n">denorm_sets</span><span class="p">(</span><span class="n">_y_bias</span><span class="p">,</span> <span class="n">_y_scale</span><span class="p">,</span> <span class="n">y_hat_norm_np</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y_hat_final_np</span> <span class="o">=</span> <span class="n">y_hat_norm_np</span>
        
    <span class="k">return</span> <span class="n">y_hat_final_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span></div>


<div class="viewcode-block" id="nn_comp_3_fwd_from_raw">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_3_fwd_from_raw">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_3_fwd_from_raw</span><span class="p">(</span>
    <span class="n">A_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples, TL_terms_raw_A) e.g. flux components</span>
    <span class="n">Bt_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>     <span class="c1"># (samples,) total field</span>
    <span class="n">B_dot_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># (samples, 3) derivatives of flux components</span>
    <span class="n">x_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples, features)</span>
    <span class="n">data_norms</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span>      <span class="c1"># (A_bias, A_scale, v_scale_pca, x_bias, x_scale, y_bias, y_scale)</span>
                            <span class="c1"># Note: A_bias/A_scale here are for the components of A used in create_TL_A (e.g. flux, not the full TL matrix)</span>
    <span class="n">model_nn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">y_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">TL_coef_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="c1"># Raw (not normalized) full TL coefficient vector</span>
    <span class="n">terms_A</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>      <span class="c1"># Terms used to construct the full TL matrix from A_raw components</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># For get_temporal_data if model is temporal</span>
    <span class="n">l_window</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># For get_temporal_data</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass of neural network-based aeromagnetic compensation, model 3, from raw inputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">A_raw_f32</span> <span class="o">=</span> <span class="n">A_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">Bt_raw_f32</span> <span class="o">=</span> <span class="n">Bt_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">B_dot_raw_f32</span> <span class="o">=</span> <span class="n">B_dot_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># (samples, 3)</span>
    <span class="n">x_raw_f32</span> <span class="o">=</span> <span class="n">x_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">TL_coef_raw_f32</span> <span class="o">=</span> <span class="n">TL_coef_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Unpack data normalizations</span>
    <span class="c1"># The data_norms tuple for M3 is typically:</span>
    <span class="c1"># (placeholder_A_bias, placeholder_A_scale, v_scale_pca, x_bias, x_scale, y_bias, y_scale)</span>
    <span class="c1"># The A_bias/A_scale from norm_sets(A_f32) in nn_comp_3_train are not directly used here for A_raw.</span>
    <span class="c1"># Instead, B_unit, B_vec, B_vec_dot are constructed from raw A_raw (fluxes) and Bt_raw.</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">v_scale_pca</span><span class="p">,</span> <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="n">unpack_data_norms</span><span class="p">(</span><span class="n">data_norms</span><span class="p">)</span>

    <span class="c1"># Construct B_unit, B_vec, B_vec_dot from raw inputs</span>
    <span class="c1"># A_raw is typically the flux components (samples, 3)</span>
    <span class="c1"># B_unit = A_raw / ||A_raw|| (row-wise)</span>
    <span class="n">norm_A_raw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A_raw_f32</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">norm_A_raw</span><span class="p">[</span><span class="n">norm_A_raw</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-9</span> <span class="c1"># Avoid division by zero</span>
    <span class="n">B_unit_np</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_raw_f32</span> <span class="o">/</span> <span class="n">norm_A_raw</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="c1"># (3, samples)</span>
    
    <span class="n">B_vec_np</span> <span class="o">=</span> <span class="n">B_unit_np</span> <span class="o">*</span> <span class="n">Bt_raw_f32</span> <span class="c1"># (3, samples) * (samples,) -&gt; (3, samples)</span>
    <span class="n">B_vec_dot_np</span> <span class="o">=</span> <span class="n">B_dot_raw_f32</span><span class="o">.</span><span class="n">T</span>    <span class="c1"># (3, samples)</span>

    <span class="c1"># Normalize x</span>
    <span class="n">x_norm_step1</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_raw_f32</span> <span class="o">-</span> <span class="n">x_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">x_norm_pca</span> <span class="o">=</span> <span class="n">x_norm_step1</span> <span class="o">@</span> <span class="n">v_scale_pca</span> <span class="c1"># (samples, PCA_features)</span>
    
    <span class="c1"># Handle temporal data if needed</span>
    <span class="n">x_norm_for_fwd_transposed</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="c1"># Will be (PCA_features, samples) or (PCA_features, window, samples)</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_norm_pca</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">x_norm_temporal</span> <span class="o">=</span> <span class="n">get_temporal_data</span><span class="p">(</span><span class="n">x_norm_pca</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">l_segs</span><span class="p">,</span> <span class="n">l_window</span><span class="p">)</span> <span class="c1"># Expects (features, N)</span>
        <span class="n">x_norm_for_fwd_transposed</span> <span class="o">=</span> <span class="n">x_norm_temporal</span> <span class="c1"># Already (features, window, N)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x_norm_for_fwd_transposed</span> <span class="o">=</span> <span class="n">x_norm_pca</span><span class="o">.</span><span class="n">T</span> <span class="c1"># (PCA_features, samples)</span>

    <span class="c1"># Split TL_coef_raw into p, i_mat, e_mat components</span>
    <span class="c1"># Bt_scale is used inside TL_vec2mat for denormalizing i and e components from the vector form</span>
    <span class="c1"># Here, TL_coef_raw is already in the &quot;vector&quot; form but not scaled by Bt_scale for i and e parts yet.</span>
    <span class="c1"># The TL_vec2mat function expects the vector form where i and e are already scaled by Bt_scale.</span>
    <span class="c1"># This means we need to be careful. The TL_coef_raw from NNCompParams is the direct output of training.</span>
    <span class="c1"># Let&#39;s assume TL_coef_raw is the &quot;beta&quot; from `tolles_lawson_train` or similar,</span>
    <span class="c1"># which means it&#39;s directly applicable to the A matrix from `create_TL_A`.</span>
    <span class="c1"># The `nn_comp_3_fwd` expects p, i_mat, e_mat that are already appropriately scaled.</span>
    
    <span class="c1"># The TL_coef stored in CompParams is the direct coefficient vector.</span>
    <span class="c1"># We need to convert it to the matrix forms (p, i_mat, e_mat) expected by nn_comp_3_fwd.</span>
    <span class="c1"># The Bt_scale in TL_vec2mat is for converting the &quot;normalized&quot; vector components (like those in Flux)</span>
    <span class="c1"># back to physical units. Here, TL_coef_raw is already in physical units.</span>
    <span class="c1"># So, we use Bt_scale=1.0 when calling TL_vec2mat if TL_coef_raw&#39;s i and e parts are already physical.</span>
    <span class="c1"># However, the nn_comp_3_fwd expects TL_coef_i_mat and TL_coef_e_mat to be such that</span>
    <span class="c1"># TL_induced = TL_coef_i_mat @ B_vec.</span>
    <span class="c1"># If TL_coef_raw comes from `tolles_lawson_train`, its induced/eddy parts are typically normalized by Bt.</span>
    <span class="c1"># Let&#39;s assume TL_coef_raw is the direct output of `nn_comp_3_train` which stores the physical coefficients.</span>
    
    <span class="c1"># The `TL_vec2mat` function in Julia divides by Bt_scale for induced/eddy.</span>
    <span class="c1"># So, if TL_coef_raw has induced/eddy parts that are meant to be multiplied by B_vec/B_vec_dot directly,</span>
    <span class="c1"># then TL_vec2mat should be called with Bt_scale=1.0.</span>
    <span class="c1"># Or, if TL_coef_raw&#39;s induced/eddy parts are like the &#39;c&#39; in c*B (where B includes Bt), then Bt_scale=50000.</span>
    <span class="c1"># Given the context of nn_comp_3_fwd, TL_coef_i_mat and TL_coef_e_mat are multiplied by B_vec and B_vec_dot respectively.</span>
    <span class="c1"># These B_vec and B_vec_dot already contain the magnetic field strength.</span>
    <span class="c1"># So, the coefficients themselves should be dimensionless or scaled appropriately.</span>
    <span class="c1"># The Julia `TL_vec2mat` divides by Bt_scale. This implies the input TL_coef vector&#39;s induced/eddy parts</span>
    <span class="c1"># are effectively (dimensionless_coeff * Bt_scale).</span>
    <span class="c1"># If our TL_coef_raw is this (dimensionless_coeff * Bt_scale) form, then Julia&#39;s TL_vec2mat is correct.</span>
    <span class="c1"># The `nn_comp_3_train` stores `TL_coef = [s.TL_p;s.TL_i;s.TL_e]`.</span>
    <span class="c1"># `s.TL_p, s.TL_i, s.TL_e` are parameters of `m3_struct`, which are trained.</span>
    <span class="c1"># The loss function `loss_m3` calls `TL_vec2mat(TL_coef, terms_A; Bt_scale=Bt_scale)`.</span>
    <span class="c1"># This implies the stored `s.TL_p,i,e` are such that when recombined and then split by `TL_vec2mat`</span>
    <span class="c1"># with the standard Bt_scale, they yield the correct physical matrices.</span>
    <span class="c1"># This means the stored s.TL_i and s.TL_e components in m3_struct are likely the &quot;dimensionless_coeff * Bt_scale&quot; form.</span>
    
    <span class="c1"># Therefore, when calling TL_vec2mat here with TL_coef_raw, we should use the standard Bt_scale.</span>
    <span class="c1"># The resulting TL_coef_i_mat and TL_coef_e_mat will then be the dimensionless matrices.</span>
    <span class="c1"># This seems consistent with how nn_comp_3_fwd would use them with B_vec (which includes field strength).</span>

    <span class="n">TL_p_np</span><span class="p">,</span> <span class="n">TL_i_mat_np</span><span class="p">,</span> <span class="n">TL_e_mat_np</span> <span class="o">=</span> <span class="n">TL_vec2mat</span><span class="p">(</span><span class="n">TL_coef_raw_f32</span><span class="p">,</span> <span class="n">terms_A</span><span class="p">,</span> <span class="n">Bt_scale</span><span class="o">=</span><span class="mf">50000.0</span><span class="p">)</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">nn_comp_3_fwd</span><span class="p">(</span>
        <span class="n">B_unit_np</span><span class="p">,</span> <span class="n">B_vec_np</span><span class="p">,</span> <span class="n">B_vec_dot_np</span><span class="p">,</span>
        <span class="n">x_norm_for_fwd_transposed</span><span class="p">,</span> <span class="c1"># Already (features, samples) or (features, window, samples)</span>
        <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">model_nn</span><span class="p">,</span>
        <span class="n">TL_p_np</span><span class="p">,</span> <span class="n">TL_i_mat_np</span><span class="p">,</span> <span class="n">TL_e_mat_np</span><span class="p">,</span>
        <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span>
        <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span>
        <span class="n">use_nn</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># Always use NN for fwd_from_raw as it&#39;s part of the trained model</span>
        <span class="n">denorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="n">testmode</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">y_hat</span></div>

<div class="viewcode-block" id="nn_comp_3_test">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_3_test">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_3_test</span><span class="p">(</span>
    <span class="n">B_unit</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>      <span class="c1"># (3, samples)</span>
    <span class="n">B_vec</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>       <span class="c1"># (3, samples)</span>
    <span class="n">B_vec_dot</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>   <span class="c1"># (3, samples)</span>
    <span class="n">x_norm</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>      <span class="c1"># (features, samples) or (features, window, samples)</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>                                <span class="c1"># Raw target vector (samples,)</span>
    <span class="n">y_bias</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">y_scale</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">model_nn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span>
    <span class="n">TL_coef_p</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">TL_coef_i_mat</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">TL_coef_e_mat</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">y_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">use_nn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="c1"># In test, usually True if NN is part of the model</span>
    <span class="n">denorm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="c1"># Usually True for final error calculation</span>
    <span class="n">testmode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="c1"># Always True for test function</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate performance of neural network-based aeromagnetic compensation, model 3.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_flat</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">)]</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">nn_comp_3_fwd</span><span class="p">(</span>
        <span class="n">B_unit</span><span class="p">,</span> <span class="n">B_vec</span><span class="p">,</span> <span class="n">B_vec_dot</span><span class="p">,</span> <span class="n">x_norm</span><span class="p">,</span>
        <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">model_nn</span><span class="p">,</span>
        <span class="n">TL_coef_p</span><span class="p">,</span> <span class="n">TL_coef_i_mat</span><span class="p">,</span> <span class="n">TL_coef_e_mat</span><span class="p">,</span>
        <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span> <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span>
        <span class="n">use_nn</span><span class="o">=</span><span class="n">use_nn</span><span class="p">,</span> <span class="n">denorm</span><span class="o">=</span><span class="n">denorm</span><span class="p">,</span> <span class="n">testmode</span><span class="o">=</span><span class="n">testmode</span>
    <span class="p">)</span>
    
    <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="n">l_segs</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: sum(l_segs)=</span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span><span class="si">}</span><span class="s2"> != len(y)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">)</span><span class="si">}</span><span class="s2">. Using single segment.&quot;</span><span class="p">)</span>
        <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">)]</span>
        
    <span class="n">err_val</span> <span class="o">=</span> <span class="n">err_segs</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y_flat</span><span class="p">,</span> <span class="n">valid_l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_val</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_val</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M3 test error: </span><span class="si">{</span><span class="n">err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">err_val</span></div>


<div class="viewcode-block" id="nn_comp_3_test_from_raw">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_3_test_from_raw">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_3_test_from_raw</span><span class="p">(</span>
    <span class="n">A_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples, flux_components)</span>
    <span class="n">Bt_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>     <span class="c1"># (samples,)</span>
    <span class="n">B_dot_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># (samples, 3)</span>
    <span class="n">x_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples, features)</span>
    <span class="n">y_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># (samples,)</span>
    <span class="n">data_norms</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">model_nn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">y_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">TL_coef_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">terms_A</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">l_window</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># For get_temporal_data if model is temporal</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate performance of neural network-based aeromagnetic compensation, model 3, from raw inputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_raw_flat</span> <span class="o">=</span> <span class="n">y_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_raw_flat</span><span class="p">)]</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">nn_comp_3_fwd_from_raw</span><span class="p">(</span>
        <span class="n">A_raw</span><span class="p">,</span> <span class="n">Bt_raw</span><span class="p">,</span> <span class="n">B_dot_raw</span><span class="p">,</span> <span class="n">x_raw</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">model_nn</span><span class="p">,</span>
        <span class="n">model_type</span><span class="p">,</span> <span class="n">y_type</span><span class="p">,</span> <span class="n">TL_coef_raw</span><span class="p">,</span> <span class="n">terms_A</span><span class="p">,</span>
        <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs</span><span class="p">,</span> <span class="n">l_window</span><span class="o">=</span><span class="n">l_window</span> <span class="c1"># Pass l_segs for temporal data prep if needed</span>
    <span class="p">)</span>
    
    <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="n">l_segs</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_raw_flat</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: sum(l_segs)=</span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">l_segs</span><span class="p">)</span><span class="si">}</span><span class="s2"> != len(y)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y_raw_flat</span><span class="p">)</span><span class="si">}</span><span class="s2">. Using single segment.&quot;</span><span class="p">)</span>
        <span class="n">valid_l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_raw_flat</span><span class="p">)]</span>

    <span class="n">err_val</span> <span class="o">=</span> <span class="n">err_segs</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y_raw_flat</span><span class="p">,</span> <span class="n">valid_l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_val</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_val</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M3 test error (from raw): </span><span class="si">{</span><span class="n">err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">err_val</span></div>

<div class="viewcode-block" id="nn_comp_3_train">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.nn_comp_3_train">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">nn_comp_3_train</span><span class="p">(</span>
    <span class="n">A_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># Raw flux components (samples, 3)</span>
    <span class="n">Bt_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>     <span class="c1"># Raw total field (samples,)</span>
    <span class="n">B_dot_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># Raw flux derivatives (samples, 3)</span>
    <span class="n">x_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># Raw features (samples, features)</span>
    <span class="n">y_raw</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>      <span class="c1"># Raw target (samples,)</span>
    <span class="n">no_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;m3s&quot;</span><span class="p">,</span>
    <span class="n">norm_type_x</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;standardize&quot;</span><span class="p">,</span>
    <span class="n">norm_type_y</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;standardize&quot;</span><span class="p">,</span> <span class="c1"># Julia default :standardize for M3</span>
    <span class="n">TL_coef_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Full TL coefficient vector</span>
    <span class="n">terms_A</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Terms for TL_vec_split &amp; TL_vec2mat</span>
    <span class="n">y_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;d&quot;</span><span class="p">,</span>
    <span class="n">eta_adam</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="n">epoch_adam</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="n">epoch_lbfgs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">hidden</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">,</span>
    <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span>
    <span class="n">batchsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="n">frac_train</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">14</span><span class="o">/</span><span class="mi">17</span><span class="p">,</span>
    <span class="n">alpha_sgl</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="c1"># Note: SGL not fully implemented for M3 in Julia</span>
    <span class="n">lambda_sgl</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">k_pca</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">sigma_curriculum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">l_window</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="n">window_type_temporal</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sliding&quot;</span><span class="p">,</span> <span class="c1"># Renamed from window_type to avoid clash</span>
    <span class="n">tf_layer_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;postlayer&quot;</span><span class="p">,</span> <span class="c1"># Transformer specific</span>
    <span class="n">tf_norm_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;batch&quot;</span><span class="p">,</span>    <span class="c1"># Transformer specific</span>
    <span class="n">dropout_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>      <span class="c1"># Transformer specific</span>
    <span class="n">N_tf_head</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>             <span class="c1"># Transformer specific</span>
    <span class="n">tf_gain</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>           <span class="c1"># Transformer specific</span>
    <span class="n">data_norms_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">A_test_raw_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">Bt_test_raw_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">B_dot_test_raw_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">x_test_raw_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">y_test_raw_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">l_segs_test</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train neural network-based aeromagnetic compensation, model 3.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">terms_A</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">terms_A</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;permanent&quot;</span><span class="p">,</span> <span class="s2">&quot;induced&quot;</span><span class="p">,</span> <span class="s2">&quot;eddy&quot;</span><span class="p">]</span> <span class="c1"># Default if not provided</span>

    <span class="k">if</span> <span class="n">TL_coef_in</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Determine number of TL terms from a dummy A matrix based on terms_A</span>
        <span class="c1"># This requires a fully functional create_TL_A or a way to infer num_coeffs</span>
        <span class="c1"># For now, defaulting to 18 if not provided.</span>
        <span class="c1"># num_tl_terms = create_TL_A(np.ones((1,3)), terms=terms_A).shape[1] if terms_A else 18</span>
        <span class="n">num_tl_terms</span> <span class="o">=</span> <span class="mi">18</span> <span class="c1"># Fallback, ideally calculate from terms_A</span>
        <span class="n">TL_coef_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_tl_terms</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">alpha_sgl</span> <span class="o">!=</span> <span class="mf">1.0</span> <span class="ow">or</span> <span class="n">lambda_sgl</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARN: Sparse Group Lasso (SGL) is not fully implemented for nn_comp_3 in Python version yet.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported y_type = </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2"> for nn_comp_3&quot;</span><span class="p">)</span>

    <span class="c1"># Convert to Float32</span>
    <span class="n">A_f32</span> <span class="o">=</span> <span class="n">A_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">Bt_f32</span> <span class="o">=</span> <span class="n">Bt_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">B_dot_f32</span> <span class="o">=</span> <span class="n">B_dot_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x_f32</span> <span class="o">=</span> <span class="n">x_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">y_f32</span> <span class="o">=</span> <span class="n">y_raw</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">TL_coef_f32</span> <span class="o">=</span> <span class="n">TL_coef_in</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">A_test_f32</span> <span class="o">=</span> <span class="n">A_test_raw_in</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">A_test_raw_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="n">A_f32</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">Bt_test_f32</span> <span class="o">=</span> <span class="n">Bt_test_raw_in</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">if</span> <span class="n">Bt_test_raw_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">B_dot_test_f32</span> <span class="o">=</span> <span class="n">B_dot_test_raw_in</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">B_dot_test_raw_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="n">B_dot_f32</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x_test_f32</span> <span class="o">=</span> <span class="n">x_test_raw_in</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">x_test_raw_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="n">x_f32</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">y_test_f32</span> <span class="o">=</span> <span class="n">y_test_raw_in</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">if</span> <span class="n">y_test_raw_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">no_norm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">no_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x_f32</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_f32</span><span class="p">)]</span>
    <span class="k">if</span> <span class="n">l_segs_test</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">l_segs_test</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test_f32</span><span class="p">)]</span> <span class="k">if</span> <span class="n">y_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">[]</span>


    <span class="n">Nf_x</span> <span class="o">=</span> <span class="n">x_f32</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># number of features for x</span>

    <span class="c1"># Initial TL coefficient split (physical units, Bt_scale=1 for vec2mat if coeffs are already physical)</span>
    <span class="c1"># The TL_coef_f32 is the full coefficient vector.</span>
    <span class="c1"># TL_vec2mat expects the vector form where induced/eddy parts are scaled by Bt_scale.</span>
    <span class="c1"># If TL_coef_f32 is already in physical units (e.g. from tolles_lawson_train),</span>
    <span class="c1"># then for TL_vec2mat to return dimensionless matrices (which nn_comp_3_fwd expects for i_mat, e_mat),</span>
    <span class="c1"># we should use the actual Bt_scale.</span>
    <span class="n">Bt_scale_val</span> <span class="o">=</span> <span class="mf">50000.0</span> <span class="c1"># Standard scaling</span>
    <span class="n">TL_p_np</span><span class="p">,</span> <span class="n">TL_i_mat_np</span><span class="p">,</span> <span class="n">TL_e_mat_np</span> <span class="o">=</span> <span class="n">TL_vec2mat</span><span class="p">(</span><span class="n">TL_coef_f32</span><span class="p">,</span> <span class="n">terms_A</span><span class="p">,</span> <span class="n">Bt_scale</span><span class="o">=</span><span class="n">Bt_scale_val</span><span class="p">)</span>

    <span class="c1"># Construct B_unit, B_vec from raw A (fluxes) and Bt</span>
    <span class="n">norm_A_f32</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A_f32</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">norm_A_f32</span><span class="p">[</span><span class="n">norm_A_f32</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-9</span>
    <span class="n">B_unit_np_T</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_f32</span> <span class="o">/</span> <span class="n">norm_A_f32</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="c1"># (3, samples)</span>
    <span class="n">B_vec_np_T</span> <span class="o">=</span> <span class="n">B_unit_np_T</span> <span class="o">*</span> <span class="n">Bt_f32</span>    <span class="c1"># (3, samples)</span>
    <span class="n">B_vec_dot_np_T</span> <span class="o">=</span> <span class="n">B_dot_f32</span><span class="o">.</span><span class="n">T</span>         <span class="c1"># (3, samples)</span>

    <span class="n">B_unit_test_np_T</span><span class="p">,</span> <span class="n">B_vec_test_np_T</span><span class="p">,</span> <span class="n">B_vec_dot_test_np_T</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">A_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">Bt_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">norm_A_test_f32</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A_test_f32</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">norm_A_test_f32</span><span class="p">[</span><span class="n">norm_A_test_f32</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-9</span>
        <span class="n">B_unit_test_np_T</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_test_f32</span> <span class="o">/</span> <span class="n">norm_A_test_f32</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">B_vec_test_np_T</span> <span class="o">=</span> <span class="n">B_unit_test_np_T</span> <span class="o">*</span> <span class="n">Bt_test_f32</span>
    <span class="k">if</span> <span class="n">B_dot_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">B_vec_dot_test_np_T</span> <span class="o">=</span> <span class="n">B_dot_test_f32</span><span class="o">.</span><span class="n">T</span>


    <span class="c1"># Normalization of x and y</span>
    <span class="n">v_scale_pca</span><span class="p">,</span> <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span><span class="o">*</span><span class="mi">5</span>
    <span class="k">if</span> <span class="n">data_norms_in</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">data_norms_in</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># y_scale is last</span>
        <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">x_norm_np_orig</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">x_f32</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_x</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm</span><span class="p">)</span>
        <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">y_norm_np</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">y_f32</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_y</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">k_pca</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">k_pca</span> <span class="o">&gt;</span> <span class="n">Nf_x</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: reducing k_pca from </span><span class="si">{</span><span class="n">k_pca</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">Nf_x</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">k_pca</span> <span class="o">=</span> <span class="n">Nf_x</span>
            <span class="k">if</span> <span class="n">x_norm_np_orig</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">cov_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x_norm_np_orig</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">S_svd</span><span class="p">,</span> <span class="n">V_svd_T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">cov_x</span><span class="p">)</span>
                <span class="n">V_svd</span> <span class="o">=</span> <span class="n">V_svd_T</span><span class="o">.</span><span class="n">T</span>
                <span class="n">S_svd_padded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">S_svd</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k_pca</span> <span class="o">-</span> <span class="n">S_svd</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span> <span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
                <span class="n">v_scale_pca</span> <span class="o">=</span> <span class="n">V_svd</span><span class="p">[:,</span> <span class="p">:</span><span class="n">k_pca</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S_svd_padded</span><span class="p">[:</span><span class="n">k_pca</span><span class="p">]))</span>
                <span class="n">var_ret</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S_svd_padded</span><span class="p">[:</span><span class="n">k_pca</span><span class="p">]))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S_svd_padded</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: k_pca = </span><span class="si">{</span><span class="n">k_pca</span><span class="si">}</span><span class="s2"> of </span><span class="si">{</span><span class="n">Nf_x</span><span class="si">}</span><span class="s2">, variance retained: </span><span class="si">{</span><span class="n">var_ret</span><span class="si">}</span><span class="s2"> %&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WARN: Not enough samples for PCA. Using identity for v_scale_pca.&quot;</span><span class="p">)</span>
                <span class="n">v_scale_pca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">Nf_x</span><span class="p">,</span> <span class="n">k_pca</span> <span class="k">if</span> <span class="n">k_pca</span> <span class="o">&lt;=</span> <span class="n">Nf_x</span> <span class="k">else</span> <span class="n">Nf_x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">v_scale_pca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">Nf_x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="n">x_norm_pca_T</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_norm_np_orig</span> <span class="o">@</span> <span class="n">v_scale_pca</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="c1"># (PCA_features, samples)</span>
        <span class="n">y_norm_T</span> <span class="o">=</span> <span class="n">y_norm_np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>         <span class="c1"># (1, samples)</span>
        <span class="c1"># For M3, data_norms typically stores (_,_,v_scale_pca,x_bias,x_scale,y_bias,y_scale)</span>
        <span class="c1"># The first two are placeholders in Julia. We&#39;ll store None or zeros.</span>
        <span class="n">data_norms_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">v_scale_pca</span><span class="p">,</span> <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">v_scale_pca</span><span class="p">,</span> <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="n">unpack_data_norms</span><span class="p">(</span><span class="n">data_norms_in</span><span class="p">)</span> <span class="c1"># type: ignore</span>
        <span class="n">x_norm_orig</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_f32</span> <span class="o">-</span> <span class="n">x_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">x_norm_pca_T</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_norm_orig</span> <span class="o">@</span> <span class="n">v_scale_pca</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">y_norm_T</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_f32</span> <span class="o">-</span> <span class="n">y_bias</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_scale</span> <span class="k">if</span> <span class="n">y_scale</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">data_norms_out</span> <span class="o">=</span> <span class="n">data_norms_in</span>

    <span class="c1"># Temporal data preparation</span>
    <span class="n">x_norm_final_T</span> <span class="o">=</span> <span class="n">x_norm_pca_T</span> <span class="c1"># (PCA_features, samples)</span>
    <span class="n">x_test_norm_final_T</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span>
        <span class="n">x_norm_final_T</span> <span class="o">=</span> <span class="n">get_temporal_data</span><span class="p">(</span><span class="n">x_norm_pca_T</span><span class="p">,</span> <span class="n">l_segs</span><span class="p">,</span> <span class="n">l_window</span><span class="p">)</span> <span class="c1"># (PCA_features, window, samples)</span>
        <span class="k">if</span> <span class="n">x_test_raw_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x_test_raw_in</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">x_test_norm_orig</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_test_f32</span> <span class="o">-</span> <span class="n">x_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">x_test_norm_pca_T</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_test_norm_orig</span> <span class="o">@</span> <span class="n">v_scale_pca</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="k">if</span> <span class="n">l_segs_test</span><span class="p">:</span>
                 <span class="n">x_test_norm_final_T</span> <span class="o">=</span> <span class="n">get_temporal_data</span><span class="p">(</span><span class="n">x_test_norm_pca_T</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="p">,</span> <span class="n">l_window</span><span class="p">)</span>

    <span class="c1"># PyTorch Tensors for training</span>
    <span class="c1"># DataLoader expects (samples, ...)</span>
    <span class="c1"># B_unit_np_T, B_vec_np_T, B_vec_dot_np_T are (3, samples)</span>
    <span class="c1"># x_norm_final_T is (PCA_features, samples) or (PCA_features, window, samples)</span>
    <span class="c1"># y_norm_T is (1, samples)</span>

    <span class="n">B_unit_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">B_unit_np_T</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> <span class="c1"># (samples, 3)</span>
    <span class="n">B_vec_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">B_vec_np_T</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>    <span class="c1"># (samples, 3)</span>
    <span class="n">B_vec_dot_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">B_vec_dot_np_T</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="c1"># (samples, 3)</span>
    
    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span> <span class="c1"># (PCA_features, window, samples) -&gt; (samples, window, PCA_features)</span>
        <span class="n">x_torch_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">x_norm_final_T</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># (PCA_features, samples) -&gt; (samples, PCA_features)</span>
        <span class="n">x_torch_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_norm_final_T</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        
    <span class="n">y_torch_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_norm_T</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> <span class="c1"># (samples,)</span>

    <span class="c1"># Train/Val Split</span>
    <span class="c1"># Note: For temporal data, splitting needs to be careful not to break sequences if window_type is &#39;contiguous&#39;</span>
    <span class="c1"># get_split handles this based on window_type.</span>
    <span class="n">num_total_samples</span> <span class="o">=</span> <span class="n">x_torch_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="c1"># Curriculum learning indices (applied to the training portion after frac_train split)</span>
    <span class="n">ind_cur_train</span><span class="p">,</span> <span class="n">ind_nn_train</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span> <span class="c1"># Placeholders for indices within the training set</span>

    <span class="k">if</span> <span class="n">frac_train</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># For M3, the split is done on the original sample dimension N</span>
        <span class="c1"># If temporal, N is size(x_norm,3) before permuting for DataLoader</span>
        <span class="n">N_for_split</span> <span class="o">=</span> <span class="n">x_norm_final_T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="n">x_norm_final_T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Use &#39;window_type_temporal&#39; for get_split if model is temporal</span>
        <span class="n">current_window_type_for_split</span> <span class="o">=</span> <span class="n">window_type_temporal</span> <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="s2">&quot;none&quot;</span>
        <span class="n">l_window_for_split</span> <span class="o">=</span> <span class="n">l_window</span> <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="mi">0</span>
        
        <span class="n">p_train_idx</span><span class="p">,</span> <span class="n">p_val_idx</span> <span class="o">=</span> <span class="n">get_split</span><span class="p">(</span><span class="n">N_for_split</span><span class="p">,</span> <span class="n">frac_train</span><span class="p">,</span> <span class="n">current_window_type_for_split</span><span class="p">,</span> <span class="n">l_window</span><span class="o">=</span><span class="n">l_window_for_split</span><span class="p">)</span>

        <span class="n">B_unit_train_th</span><span class="p">,</span> <span class="n">B_vec_train_th</span><span class="p">,</span> <span class="n">B_vec_dot_train_th</span> <span class="o">=</span> <span class="n">B_unit_torch</span><span class="p">[</span><span class="n">p_train_idx</span><span class="p">],</span> <span class="n">B_vec_torch</span><span class="p">[</span><span class="n">p_train_idx</span><span class="p">],</span> <span class="n">B_vec_dot_torch</span><span class="p">[</span><span class="n">p_train_idx</span><span class="p">]</span>
        <span class="n">x_train_th</span><span class="p">,</span> <span class="n">y_train_th</span> <span class="o">=</span> <span class="n">x_torch_train</span><span class="p">[</span><span class="n">p_train_idx</span><span class="p">],</span> <span class="n">y_torch_train</span><span class="p">[</span><span class="n">p_train_idx</span><span class="p">]</span>
        
        <span class="n">B_unit_val_th</span><span class="p">,</span> <span class="n">B_vec_val_th</span><span class="p">,</span> <span class="n">B_vec_dot_val_th</span> <span class="o">=</span> <span class="n">B_unit_torch</span><span class="p">[</span><span class="n">p_val_idx</span><span class="p">],</span> <span class="n">B_vec_torch</span><span class="p">[</span><span class="n">p_val_idx</span><span class="p">],</span> <span class="n">B_vec_dot_torch</span><span class="p">[</span><span class="n">p_val_idx</span><span class="p">]</span>
        <span class="n">x_val_th</span><span class="p">,</span> <span class="n">y_val_th</span> <span class="o">=</span> <span class="n">x_torch_train</span><span class="p">[</span><span class="n">p_val_idx</span><span class="p">],</span> <span class="n">y_torch_train</span><span class="p">[</span><span class="n">p_val_idx</span><span class="p">]</span>

        <span class="c1"># Curriculum learning for m3sc, m3vc (applied on the p_train_idx portion)</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3sc&quot;</span><span class="p">,</span> <span class="s2">&quot;m3vc&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INFO: M3 making curriculum&quot;</span><span class="p">)</span>
            <span class="c1"># Calculate TL estimate on the p_train_idx part of the data</span>
            <span class="c1"># Need raw y for this, corresponding to p_train_idx</span>
            <span class="n">y_raw_train_subset</span> <span class="o">=</span> <span class="n">y_f32</span><span class="p">[</span><span class="n">p_train_idx</span><span class="p">]</span>
            
            <span class="c1"># We need B_unit, B_vec, B_vec_dot, x_norm for this subset to call nn_comp_3_fwd</span>
            <span class="c1"># These should be in their (features, samples) or (features, window, samples) format</span>
            <span class="n">B_unit_train_subset_T</span> <span class="o">=</span> <span class="n">B_unit_np_T</span><span class="p">[:,</span> <span class="n">p_train_idx</span><span class="p">]</span>
            <span class="n">B_vec_train_subset_T</span> <span class="o">=</span> <span class="n">B_vec_np_T</span><span class="p">[:,</span> <span class="n">p_train_idx</span><span class="p">]</span>
            <span class="n">B_vec_dot_train_subset_T</span> <span class="o">=</span> <span class="n">B_vec_dot_np_T</span><span class="p">[:,</span> <span class="n">p_train_idx</span><span class="p">]</span>
            
            <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span> <span class="c1"># x_norm_final_T is (feat, win, samp)</span>
                 <span class="n">x_norm_train_subset_T</span> <span class="o">=</span> <span class="n">x_norm_final_T</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">p_train_idx</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># x_norm_final_T is (feat, samp)</span>
                 <span class="n">x_norm_train_subset_T</span> <span class="o">=</span> <span class="n">x_norm_final_T</span><span class="p">[:,</span> <span class="n">p_train_idx</span><span class="p">]</span>

            <span class="n">y_TL_hat_train_subset</span> <span class="o">=</span> <span class="n">nn_comp_3_fwd</span><span class="p">(</span>
                <span class="n">B_unit_train_subset_T</span><span class="p">,</span> <span class="n">B_vec_train_subset_T</span><span class="p">,</span> <span class="n">B_vec_dot_train_subset_T</span><span class="p">,</span>
                <span class="n">x_norm_train_subset_T</span><span class="p">,</span> 
                <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="c1"># Use overall y_bias, y_scale for denormalization</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(),</span> <span class="c1"># Dummy NN model for TL-only part</span>
                <span class="n">TL_p_np</span><span class="p">,</span> <span class="n">TL_i_mat_np</span><span class="p">,</span> <span class="n">TL_e_mat_np</span><span class="p">,</span> <span class="c1"># Initial physical TL coeffs</span>
                <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;m3tl&quot;</span><span class="p">,</span> <span class="c1"># Force TL-only behavior for this calc</span>
                <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span>
                <span class="n">use_nn</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">denorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">testmode</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">TL_diff_train_subset</span> <span class="o">=</span> <span class="n">y_raw_train_subset</span> <span class="o">-</span> <span class="n">y_TL_hat_train_subset</span>
            <span class="n">ind_cur_train</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_curriculum_ind</span><span class="p">(</span><span class="n">TL_diff_train_subset</span><span class="p">,</span> <span class="n">sigma_curriculum</span><span class="p">)</span> <span class="c1"># Boolean mask for p_train_idx</span>

            <span class="c1"># Create DataLoaders: one for curriculum, one for full training (used later)</span>
            <span class="n">train_dataset_cur</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span>
                <span class="n">B_unit_train_th</span><span class="p">[</span><span class="n">ind_cur_train</span><span class="p">],</span> <span class="n">B_vec_train_th</span><span class="p">[</span><span class="n">ind_cur_train</span><span class="p">],</span> <span class="n">B_vec_dot_train_th</span><span class="p">[</span><span class="n">ind_cur_train</span><span class="p">],</span>
                <span class="n">x_train_th</span><span class="p">[</span><span class="n">ind_cur_train</span><span class="p">],</span> <span class="n">y_train_th</span><span class="p">[</span><span class="n">ind_cur_train</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">train_loader_cur</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset_cur</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            
            <span class="n">train_dataset_full</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">B_unit_train_th</span><span class="p">,</span> <span class="n">B_vec_train_th</span><span class="p">,</span> <span class="n">B_vec_dot_train_th</span><span class="p">,</span> <span class="n">x_train_th</span><span class="p">,</span> <span class="n">y_train_th</span><span class="p">)</span>
            <span class="n">train_loader_full</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset_full</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            
            <span class="c1"># Initial training will use train_loader_cur</span>
            <span class="n">current_train_loader</span> <span class="o">=</span> <span class="n">train_loader_cur</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">B_unit_train_th</span><span class="p">,</span> <span class="n">B_vec_train_th</span><span class="p">,</span> <span class="n">B_vec_dot_train_th</span><span class="p">,</span> <span class="n">x_train_th</span><span class="p">,</span> <span class="n">y_train_th</span><span class="p">)</span>
            <span class="n">current_train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">train_loader_full</span> <span class="o">=</span> <span class="n">current_train_loader</span> <span class="c1"># For consistency later</span>

        <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">B_unit_val_th</span><span class="p">,</span> <span class="n">B_vec_val_th</span><span class="p">,</span> <span class="n">B_vec_dot_val_th</span><span class="p">,</span> <span class="n">x_val_th</span><span class="p">,</span> <span class="n">y_val_th</span><span class="p">)</span>
        <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># frac_train == 1</span>
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">B_unit_torch</span><span class="p">,</span> <span class="n">B_vec_torch</span><span class="p">,</span> <span class="n">B_vec_dot_torch</span><span class="p">,</span> <span class="n">x_torch_train</span><span class="p">,</span> <span class="n">y_torch_train</span><span class="p">)</span>
        <span class="n">current_train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">train_loader_full</span> <span class="o">=</span> <span class="n">current_train_loader</span>
        <span class="n">val_loader</span> <span class="o">=</span> <span class="n">current_train_loader</span> <span class="c1"># Validate on the full training set</span>

    <span class="c1"># Setup NN</span>
    <span class="n">current_nn_model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span>
    <span class="c1"># Input features to NN is number of PCA features (x_norm_final_T.shape[0])</span>
    <span class="c1"># Or if temporal, it&#39;s x_norm_final_T.shape[0] (features) * x_norm_final_T.shape[1] (window) if MLP based on window</span>
    <span class="c1"># But get_nn_m for temporal models in Julia seems to take Nf (original features before windowing)</span>
    <span class="c1"># and handles windowing internally or via layer type.</span>
    <span class="c1"># For PyTorch, if using LSTM/Transformer, input_size to get_nn_m is num_features_per_step.</span>
    <span class="c1"># If x_norm_final_T is (PCA_features, window, samples), then input to NN is (PCA_features) if batch_first=False, seq_len=window</span>
    <span class="c1"># Or (window, PCA_features) if batch_first=True for Transformer.</span>
    <span class="c1"># Let&#39;s assume get_nn_m expects num_features_per_step.</span>
    
    <span class="n">nn_input_features_count</span> <span class="o">=</span> <span class="n">x_norm_final_T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># This is num_pca_components</span>

    <span class="n">Ny_nn</span> <span class="o">=</span> <span class="mi">3</span> <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3v&quot;</span><span class="p">,</span> <span class="s2">&quot;m3vc&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="mi">1</span> <span class="c1"># NN output: 3 for vector, 1 for scalar correction</span>
    
    <span class="k">if</span> <span class="n">model_in</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">list</span><span class="p">(</span><span class="n">model_in</span><span class="o">.</span><span class="n">children</span><span class="p">()):</span>
        <span class="n">current_nn_model</span> <span class="o">=</span> <span class="n">get_nn_m</span><span class="p">(</span>
            <span class="n">nn_input_features_count</span><span class="p">,</span> <span class="n">Ny_nn</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="n">hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span> <span class="c1"># Pass model_type for potential internal logic in get_nn_m</span>
            <span class="n">l_window</span><span class="o">=</span><span class="n">l_window</span><span class="p">,</span> 
            <span class="n">tf_layer_type</span><span class="o">=</span><span class="n">tf_layer_type</span><span class="p">,</span> <span class="n">tf_norm_type</span><span class="o">=</span><span class="n">tf_norm_type</span><span class="p">,</span>
            <span class="n">dropout_prob</span><span class="o">=</span><span class="n">dropout_prob</span><span class="p">,</span> <span class="n">N_tf_head</span><span class="o">=</span><span class="n">N_tf_head</span><span class="p">,</span> <span class="n">tf_gain</span><span class="o">=</span><span class="n">tf_gain</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">current_nn_model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model_in</span><span class="p">)</span>

    <span class="c1"># TL_coef_f32 is the full vector. Split it into p, i, e components for M3Struct</span>
    <span class="c1"># These components are parameters of M3Struct and will be trained.</span>
    <span class="c1"># They are already in physical units.</span>
    <span class="n">TL_p_param</span><span class="p">,</span> <span class="n">TL_i_param</span><span class="p">,</span> <span class="n">TL_e_param</span> <span class="o">=</span> <span class="n">TL_vec_split</span><span class="p">(</span><span class="n">TL_coef_f32</span><span class="p">,</span> <span class="n">terms_A</span><span class="p">)</span>
    
    <span class="n">s_model</span> <span class="o">=</span> <span class="n">M3Struct</span><span class="p">(</span><span class="n">current_nn_model</span><span class="p">,</span> <span class="n">TL_p_param</span><span class="p">,</span> <span class="n">TL_i_param</span><span class="p">,</span> <span class="n">TL_e_param</span> <span class="k">if</span> <span class="n">TL_e_param</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>


    <span class="c1"># Loss function for M3</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss_val_m3</span><span class="p">(</span><span class="n">model_wrapper</span><span class="p">:</span> <span class="n">M3Struct</span><span class="p">,</span> <span class="n">loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">current_use_nn</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">model_wrapper</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">B_u_b</span><span class="p">,</span> <span class="n">B_v_b</span><span class="p">,</span> <span class="n">B_vd_b</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="n">y_b_target</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
                <span class="c1"># Inputs to nn_comp_3_fwd need to be (features, batch_size) or (features, window, batch_size)</span>
                <span class="c1"># DataLoader gives (batch_size, features) or (batch_size, window, features)</span>
                
                <span class="c1"># Transpose B_u_b, B_v_b, B_vd_b from (batch, 3) to (3, batch)</span>
                <span class="c1"># Transpose/permute x_b based on model_type</span>
                <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span> <span class="c1"># x_b is (batch, window, features)</span>
                    <span class="n">x_b_fwd</span> <span class="o">=</span> <span class="n">x_b</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># (features, window, batch)</span>
                <span class="k">else</span><span class="p">:</span> <span class="c1"># x_b is (batch, features)</span>
                    <span class="n">x_b_fwd</span> <span class="o">=</span> <span class="n">x_b</span><span class="o">.</span><span class="n">T</span> <span class="c1"># (features, batch)</span>

                <span class="c1"># Reconstruct TL coefficient matrices from model_wrapper parameters</span>
                <span class="n">_current_TL_p_np</span> <span class="o">=</span> <span class="n">model_wrapper</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">_current_TL_i_vec_np</span> <span class="o">=</span> <span class="n">model_wrapper</span><span class="o">.</span><span class="n">TL_i</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">_current_TL_e_vec_np</span> <span class="o">=</span> <span class="n">model_wrapper</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">model_wrapper</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

                <span class="n">_full_TL_coef_vec_parts</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="n">_current_TL_p_np</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">_full_TL_coef_vec_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_current_TL_p_np</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">_current_TL_i_vec_np</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">_full_TL_coef_vec_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_current_TL_i_vec_np</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">_current_TL_e_vec_np</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">_full_TL_coef_vec_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_current_TL_e_vec_np</span><span class="p">)</span>

                <span class="n">_p_fwd_th</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
                <span class="n">_i_mat_fwd_th</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
                <span class="n">_e_mat_fwd_th</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="n">_full_TL_coef_vec_parts</span><span class="p">:</span>
                    <span class="c1"># This case should ideally not happen if TL params are part of the model</span>
                    <span class="n">_p_fwd_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">model_wrapper</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">_i_mat_fwd_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">model_wrapper</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">_e_mat_fwd_th</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">SILENT_DEBUG</span><span class="p">:</span> <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No TL coefficient parts found in model_wrapper for loss calculation.&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">_current_full_TL_coef_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">_full_TL_coef_vec_parts</span><span class="p">)</span>
                    <span class="c1"># Bt_scale_val should be defined in the outer scope of nn_comp_3_train</span>
                    <span class="n">_p_fwd_np</span><span class="p">,</span> <span class="n">_i_mat_fwd_np</span><span class="p">,</span> <span class="n">_e_mat_fwd_np</span> <span class="o">=</span> <span class="n">TL_vec2mat</span><span class="p">(</span><span class="n">_current_full_TL_coef_np</span><span class="p">,</span> <span class="n">terms_A</span><span class="p">,</span> <span class="n">Bt_scale_val</span><span class="p">)</span>
                    
                    <span class="n">_p_fwd_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_p_fwd_np</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model_wrapper</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">_i_mat_fwd_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_i_mat_fwd_np</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model_wrapper</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">_e_mat_fwd_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_e_mat_fwd_np</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model_wrapper</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">_e_mat_fwd_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_e_mat_fwd_np</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>

                <span class="n">y_hat_b_norm</span> <span class="o">=</span> <span class="n">nn_comp_3_fwd</span><span class="p">(</span>
                    <span class="n">B_u_b</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">B_v_b</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">B_vd_b</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">x_b_fwd</span><span class="p">,</span>
                    <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="c1"># Dummy y_bias, y_scale for normalized output</span>
                    <span class="n">model_wrapper</span><span class="o">.</span><span class="n">m</span><span class="p">,</span>
                    <span class="n">_p_fwd_th</span><span class="p">,</span>
                    <span class="n">_i_mat_fwd_th</span><span class="p">,</span>
                    <span class="n">_e_mat_fwd_th</span><span class="p">,</span>
                    <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span> <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span>
                    <span class="n">use_nn</span><span class="o">=</span><span class="n">current_use_nn</span><span class="p">,</span> <span class="n">denorm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">testmode</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
                <span class="n">y_hat_b_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_hat_b_norm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
                
                <span class="n">current_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat_b_norm_torch</span><span class="p">,</span> <span class="n">y_b_target</span><span class="p">)</span>
                <span class="c1"># SGL not implemented for M3 in Julia, so skipping here too for now</span>
                
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">current_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x_b</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">count</span> <span class="o">+=</span> <span class="n">x_b</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">count</span> <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span>

    <span class="c1"># Optimizer</span>
    <span class="n">optimizer_adam</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">eta_adam</span><span class="p">)</span>

    <span class="c1"># Training loop (Adam)</span>
    <span class="n">best_model_state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
    <span class="n">best_loss_val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span> <span class="c1"># Initialize with a high value</span>

    <span class="c1"># Initial use_nn state for curriculum learning</span>
    <span class="n">current_use_nn_for_loss</span> <span class="o">=</span> <span class="kc">False</span> <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3sc&quot;</span><span class="p">,</span> <span class="s2">&quot;m3vc&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tl&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="kc">True</span>
    
    <span class="c1"># Calculate initial validation loss</span>
    <span class="n">best_loss_val</span> <span class="o">=</span> <span class="n">compute_loss_val_m3</span><span class="p">(</span><span class="n">s_model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">current_use_nn_for_loss</span><span class="p">)</span>


    <span class="n">best_test_error_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">x_test_raw_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x_test_raw_in</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">y_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> \
       <span class="n">A_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">Bt_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">:</span> <span class="c1"># B_dot_test can be empty</span>
        
        <span class="c1"># Prepare test x_norm</span>
        <span class="n">x_test_norm_orig_np</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_test_f32</span> <span class="o">-</span> <span class="n">x_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">x_test_norm_pca_np_T</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_test_norm_orig_np</span> <span class="o">@</span> <span class="n">v_scale_pca</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="c1"># (PCA_feat, samples)</span>
        
        <span class="n">x_test_norm_final_eval_T</span> <span class="o">=</span> <span class="n">x_test_norm_pca_np_T</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span>
             <span class="k">if</span> <span class="n">l_segs_test</span><span class="p">:</span>
                <span class="n">x_test_norm_final_eval_T</span> <span class="o">=</span> <span class="n">get_temporal_data</span><span class="p">(</span><span class="n">x_test_norm_pca_np_T</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="p">,</span> <span class="n">l_window</span><span class="p">)</span>


        <span class="n">_</span><span class="p">,</span> <span class="n">err_test_init</span> <span class="o">=</span> <span class="n">nn_comp_3_test</span><span class="p">(</span>
            <span class="n">B_unit_test_np_T</span><span class="p">,</span> <span class="n">B_vec_test_np_T</span><span class="p">,</span> <span class="n">B_vec_dot_test_np_T</span><span class="p">,</span>
            <span class="n">x_test_norm_final_eval_T</span><span class="p">,</span> 
            <span class="n">y_test_f32</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span>
            <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">_p_fwd_np</span><span class="p">,</span>
            <span class="n">_i_mat_fwd_np</span><span class="p">,</span>
            <span class="n">_e_mat_fwd_np</span> <span class="k">if</span> <span class="n">_e_mat_fwd_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_e_mat_fwd_np</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">model_type</span><span class="p">,</span> <span class="n">y_type</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_test</span><span class="p">,</span> <span class="n">use_nn</span><span class="o">=</span><span class="n">current_use_nn_for_loss</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span>
        <span class="p">)</span>
        <span class="n">best_test_error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_test_init</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_test_init</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M3 epoch 0: loss = </span><span class="si">{</span><span class="n">best_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Curriculum learning schedule for Adam epochs</span>
    <span class="c1"># Julia: epoch_adam_cur = ceil.(Int, epoch_adam * [1, 2, 3, 6] / 10)</span>
    <span class="c1"># Example: epoch_adam = 100 -&gt; cur = [10, 20, 30, 60]</span>
    <span class="c1"># Example: epoch_adam = 5   -&gt; cur = [1, 1, 2, 3] (ceil makes it tricky for small epochs)</span>
    <span class="c1"># Let&#39;s use fractions directly for epoch stages</span>
    <span class="n">epoch_stages_frac</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]</span> 
    <span class="n">epoch_stages</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">epoch_adam</span> <span class="o">*</span> <span class="n">frac</span><span class="p">))</span> <span class="k">for</span> <span class="n">frac</span> <span class="ow">in</span> <span class="n">epoch_stages_frac</span><span class="p">]</span>
    <span class="c1"># Ensure stages are at least 1 and distinct if epoch_adam is small</span>
    <span class="k">for</span> <span class="n">k_stage</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">epoch_stages</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">k_stage</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">epoch_stages</span><span class="p">[</span><span class="n">k_stage</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">epoch_stages</span><span class="p">[</span><span class="n">k_stage</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">epoch_stages</span><span class="p">[</span><span class="n">k_stage</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch_stages</span><span class="p">[</span><span class="n">k_stage</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">epoch_stages</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">ep</span><span class="p">,</span> <span class="n">epoch_adam</span><span class="p">)</span> <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="n">epoch_stages</span><span class="p">]</span> <span class="c1"># Cap at epoch_adam</span>


    <span class="k">for</span> <span class="n">i_epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epoch_adam</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">s_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        
        <span class="c1"># Curriculum logic for m3sc, m3vc</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3sc&quot;</span><span class="p">,</span> <span class="s2">&quot;m3vc&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">i_epoch</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="c1"># Stage 0: Train P only, NN frozen</span>
                <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">TL_i</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">current_use_nn_for_loss</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">active_train_loader</span> <span class="o">=</span> <span class="n">train_loader_cur</span> <span class="k">if</span> <span class="s1">&#39;train_loader_cur&#39;</span> <span class="ow">in</span> <span class="nb">locals</span><span class="p">()</span> <span class="k">else</span> <span class="n">train_loader_full</span>
            <span class="k">elif</span> <span class="n">i_epoch</span> <span class="o">==</span> <span class="n">epoch_stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="c1"># Stage 1: Train P, I; NN frozen</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">TL_i</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="n">i_epoch</span> <span class="o">==</span> <span class="n">epoch_stages</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="c1"># Stage 2: Train P, I, E; NN frozen</span>
                <span class="k">if</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">:</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="n">i_epoch</span> <span class="o">==</span> <span class="n">epoch_stages</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="c1"># Stage 3: Train NN only; TL frozen, use_nn=True, full data</span>
                <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">TL_i</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">if</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">:</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">current_use_nn_for_loss</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">active_train_loader</span> <span class="o">=</span> <span class="n">train_loader_full</span>
            <span class="k">elif</span> <span class="n">i_epoch</span> <span class="o">==</span> <span class="n">epoch_stages</span><span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="c1"># Stage 4: Train all; use_nn=True, full data</span>
                <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">TL_i</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">:</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">current_use_nn_for_loss</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">active_train_loader</span> <span class="o">=</span> <span class="n">train_loader_full</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;m3tl&quot;</span><span class="p">:</span> <span class="c1"># Only TL terms are trained</span>
             <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
             <span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
             <span class="n">s_model</span><span class="o">.</span><span class="n">TL_i</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
             <span class="k">if</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">:</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
             <span class="n">current_use_nn_for_loss</span> <span class="o">=</span> <span class="kc">False</span>
             <span class="n">active_train_loader</span> <span class="o">=</span> <span class="n">train_loader_full</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># m3s, m3v, m3w, m3tf: train all from start</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">s_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># Ensure all are trainable</span>
            <span class="n">current_use_nn_for_loss</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">active_train_loader</span> <span class="o">=</span> <span class="n">train_loader_full</span>


        <span class="k">for</span> <span class="n">B_u_b</span><span class="p">,</span> <span class="n">B_v_b</span><span class="p">,</span> <span class="n">B_vd_b</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="n">y_b_target</span> <span class="ow">in</span> <span class="n">active_train_loader</span><span class="p">:</span>
            <span class="n">optimizer_adam</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            
            <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span> <span class="n">x_b_fwd</span> <span class="o">=</span> <span class="n">x_b</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> <span class="n">x_b_fwd</span> <span class="o">=</span> <span class="n">x_b</span><span class="o">.</span><span class="n">T</span>

            <span class="c1"># Reconstruct TL coefficient matrices from current s_model parameters for this training step</span>
            <span class="n">_current_TL_p_np_train</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">_current_TL_i_vec_np_train</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_i</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">_current_TL_e_vec_np_train</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

            <span class="n">_full_TL_coef_vec_parts_train</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">_current_TL_p_np_train</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">_full_TL_coef_vec_parts_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_current_TL_p_np_train</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">_current_TL_i_vec_np_train</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">_full_TL_coef_vec_parts_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_current_TL_i_vec_np_train</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">_current_TL_e_vec_np_train</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">_full_TL_coef_vec_parts_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_current_TL_e_vec_np_train</span><span class="p">)</span>
            
            <span class="n">_p_fwd_np_train</span><span class="p">,</span> <span class="n">_i_mat_fwd_np_train</span><span class="p">,</span> <span class="n">_e_mat_fwd_np_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
            <span class="k">if</span> <span class="n">_full_TL_coef_vec_parts_train</span><span class="p">:</span>
                <span class="n">_current_full_TL_coef_np_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">_full_TL_coef_vec_parts_train</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">_current_full_TL_coef_np_train</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">_p_fwd_np_train</span><span class="p">,</span> <span class="n">_i_mat_fwd_np_train</span><span class="p">,</span> <span class="n">_e_mat_fwd_np_train</span> <span class="o">=</span> <span class="n">TL_vec2mat</span><span class="p">(</span>
                        <span class="n">_current_full_TL_coef_np_train</span><span class="p">,</span> <span class="n">terms_A</span><span class="p">,</span> <span class="n">Bt_scale_val</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># Default if TL coeffs are empty</span>
                <span class="n">_p_fwd_np_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

            <span class="n">_p_fwd_th_train</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span> <span class="c1"># Already a tensor parameter</span>
            <span class="n">_i_mat_fwd_th_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_i_mat_fwd_np_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">_i_mat_fwd_np_train</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">_e_mat_fwd_th_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_e_mat_fwd_np_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">_e_mat_fwd_np_train</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_e_mat_fwd_np_train</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>

            <span class="n">y_hat_b_norm</span> <span class="o">=</span> <span class="n">nn_comp_3_fwd</span><span class="p">(</span>
                <span class="n">B_u_b</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">B_v_b</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">B_vd_b</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">x_b_fwd</span><span class="p">,</span>
                <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="c1"># Dummy for normalized output</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span>
                <span class="n">_p_fwd_th_train</span><span class="p">,</span>
                <span class="n">_i_mat_fwd_th_train</span><span class="p">,</span>
                <span class="n">_e_mat_fwd_th_train</span><span class="p">,</span>
                <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span> <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span>
                <span class="n">use_nn</span><span class="o">=</span><span class="n">current_use_nn_for_loss</span><span class="p">,</span> <span class="n">denorm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">testmode</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">y_hat_b_norm_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_hat_b_norm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            
            <span class="n">loss_train_val</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat_b_norm_torch</span><span class="p">,</span> <span class="n">y_b_target</span><span class="p">)</span>
            <span class="c1"># SGL skipped for M3</span>
            <span class="n">loss_train_val</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer_adam</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">current_loss_val</span> <span class="o">=</span> <span class="n">compute_loss_val_m3</span><span class="p">(</span><span class="n">s_model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">current_use_nn_for_loss</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">x_test_raw_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x_test_raw_in</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">y_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> \
                <span class="n">A_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">Bt_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span> <span class="c1"># No test set</span>
            <span class="k">if</span> <span class="n">current_loss_val</span> <span class="o">&lt;</span> <span class="n">best_loss_val</span><span class="p">:</span>
                <span class="n">best_loss_val</span> <span class="o">=</span> <span class="n">current_loss_val</span>
                <span class="n">best_model_state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">i_epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M3 epoch </span><span class="si">{</span><span class="n">i_epoch</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">best_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># With test set</span>
            <span class="n">x_test_norm_final_eval_T_th</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span>
                 <span class="k">if</span> <span class="n">x_test_norm_final_eval_T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">x_test_norm_final_eval_T_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">x_test_norm_final_eval_T</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">x_test_norm_pca_np_T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                 <span class="n">x_test_norm_final_eval_T_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_test_norm_pca_np_T</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>


            <span class="k">if</span> <span class="n">B_unit_test_np_T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x_test_norm_final_eval_T_th</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="p">:</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">err_test_current</span> <span class="o">=</span> <span class="n">nn_comp_3_test</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">B_unit_test_np_T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span> 
                    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">B_vec_test_np_T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span> 
                    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">B_vec_dot_test_np_T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> <span class="k">if</span> <span class="n">B_vec_dot_test_np_T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                    <span class="n">x_test_norm_final_eval_T_th</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="c1"># nn_comp_3_test expects (features, samples)</span>
                    <span class="n">y_test_f32</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span>
                    <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_p_fwd_np</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_i_mat_fwd_np</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_e_mat_fwd_np</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">_e_mat_fwd_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_e_mat_fwd_np</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">model_type</span><span class="p">,</span> <span class="n">y_type</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_test</span><span class="p">,</span> <span class="n">use_nn</span><span class="o">=</span><span class="n">current_use_nn_for_loss</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span>
                <span class="p">)</span>
                <span class="n">current_test_error_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_test_current</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_test_current</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">best_test_error_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">current_test_error_std</span> <span class="o">&lt;</span> <span class="n">best_test_error_std</span><span class="p">:</span>
                    <span class="n">best_test_error_std</span> <span class="o">=</span> <span class="n">current_test_error_std</span>
                    <span class="n">best_model_state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
                
                <span class="k">if</span> <span class="n">i_epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M3 epoch </span><span class="si">{</span><span class="n">i_epoch</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">current_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, test error = </span><span class="si">{</span><span class="n">best_test_error_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span> <span class="k">if</span> <span class="n">best_test_error_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;INFO: M3 epoch </span><span class="si">{</span><span class="n">i_epoch</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">current_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">i_epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent</span> <span class="p">:</span>
                 <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M3 epoch </span><span class="si">{</span><span class="n">i_epoch</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">current_loss_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> (Test data missing for error calc)&quot;</span><span class="p">)</span>


        <span class="k">if</span> <span class="n">i_epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
            <span class="c1"># Full training data for nn_comp_3_test needs (features, samples) or (features, window, samples)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">train_err_np</span> <span class="o">=</span> <span class="n">nn_comp_3_test</span><span class="p">(</span>
                <span class="n">B_unit_np_T</span><span class="p">,</span> <span class="n">B_vec_np_T</span><span class="p">,</span> <span class="n">B_vec_dot_np_T</span><span class="p">,</span>
                <span class="n">x_norm_final_T</span><span class="p">,</span> <span class="c1"># This is already (features, [window,] samples)</span>
                <span class="n">y_f32</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> 
                <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_p_fwd_np</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_i_mat_fwd_np</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_e_mat_fwd_np</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">_e_mat_fwd_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_e_mat_fwd_np</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">model_type</span><span class="p">,</span> <span class="n">y_type</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs</span><span class="p">,</span> <span class="n">use_nn</span><span class="o">=</span><span class="n">current_use_nn_for_loss</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">train_err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_err_np</span><span class="p">)</span> <span class="k">if</span> <span class="n">train_err_np</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M3 </span><span class="si">{</span><span class="n">i_epoch</span><span class="si">}</span><span class="s2"> train error: </span><span class="si">{</span><span class="n">train_err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>

    <span class="n">s_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_state</span><span class="p">)</span>
    
    <span class="c1"># Combine trained TL_p, TL_i, TL_e back into a single TL_coef vector</span>
    <span class="c1"># The M3Struct stores them as separate tensors.</span>
    <span class="c1"># TL_mat2vec expects physical coefficient matrices/vectors.</span>
    <span class="c1"># The s_model.TL_p, s_model.TL_i (vector form), s_model.TL_e (vector form) are already the parameters.</span>
    <span class="n">final_TL_p_trained</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">final_TL_i_trained_vec</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_i</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># This is the vector form (e.g., 6 elements for i6)</span>
    <span class="n">final_TL_e_trained_vec</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="c1"># Reconstruct the full TL_coef vector based on the order defined by terms_A</span>
    <span class="c1"># This is a bit manual, assuming P then I then E.</span>
    <span class="c1"># A more robust way would be to use the logic from TL_mat2vec in reverse, or store indices.</span>
    <span class="n">temp_TL_coef_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">final_TL_p_trained</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">final_TL_i_trained_vec</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">temp_TL_coef_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_TL_i_trained_vec</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">final_TL_e_trained_vec</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">temp_TL_coef_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_TL_e_trained_vec</span><span class="p">)</span>
    <span class="n">final_TL_coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">temp_TL_coef_list</span><span class="p">)</span>


    <span class="c1"># LBFGS optimization (if epoch_lbfgs &gt; 0)</span>
    <span class="k">if</span> <span class="n">epoch_lbfgs</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">model_type</span> <span class="o">!=</span> <span class="s2">&quot;m3tl&quot;</span><span class="p">:</span> <span class="c1"># LBFGS not supported for m3tl in Julia</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INFO: M3 LBFGS training started.&quot;</span><span class="p">)</span>
        <span class="c1"># Ensure all relevant parameters are trainable for LBFGS</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">s_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">current_use_nn_for_loss_lbfgs</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># Usually train all with LBFGS</span>

        <span class="n">optimizer_lbfgs</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">closure_lbfgs_m3</span><span class="p">():</span>
            <span class="n">optimizer_lbfgs</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="c1"># Use full training dataset for LBFGS</span>
            <span class="c1"># Inputs to nn_comp_3_fwd need to be (features, batch_size) or (features, window, batch_size)</span>
            <span class="c1"># B_unit_torch, B_vec_torch, B_vec_dot_torch are (samples, 3)</span>
            <span class="c1"># x_torch_train is (samples, features) or (samples, window, features)</span>
            <span class="c1"># y_torch_train is (samples,)</span>
            
            <span class="n">x_fwd_lbfgs</span> <span class="o">=</span> <span class="n">x_torch_train</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">x_torch_train</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span> <span class="k">else</span> <span class="n">x_torch_train</span><span class="o">.</span><span class="n">T</span>

            <span class="n">y_hat_norm_lbfgs</span> <span class="o">=</span> <span class="n">nn_comp_3_fwd</span><span class="p">(</span>
                <span class="n">B_unit_torch</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">B_vec_torch</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">B_vec_dot_torch</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> 
                <span class="n">x_fwd_lbfgs</span><span class="p">,</span>
                <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="c1"># Dummy for normalized output</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_i_mat_fwd_np</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">_e_mat_fwd_np</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">_e_mat_fwd_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">_e_mat_fwd_np</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span> <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span>
                <span class="n">use_nn</span><span class="o">=</span><span class="n">current_use_nn_for_loss_lbfgs</span><span class="p">,</span> <span class="n">denorm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">testmode</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">y_hat_norm_lbfgs_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_hat_norm_lbfgs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            
            <span class="n">loss_val</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat_norm_lbfgs_torch</span><span class="p">,</span> <span class="n">y_torch_train</span><span class="p">)</span>
            <span class="n">loss_val</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">loss_val</span>

        <span class="k">for</span> <span class="n">i_lbfgs</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_lbfgs</span><span class="p">):</span>
            <span class="n">optimizer_lbfgs</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure_lbfgs_m3</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i_lbfgs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">current_loss_lbfgs</span> <span class="o">=</span> <span class="n">closure_lbfgs_m3</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M3 LBFGS epoch </span><span class="si">{</span><span class="n">i_lbfgs</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: loss = </span><span class="si">{</span><span class="n">current_loss_lbfgs</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INFO: M3 LBFGS training finished.&quot;</span><span class="p">)</span>
        
        <span class="c1"># Update final_TL_coef after LBFGS</span>
        <span class="n">final_TL_p_trained</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_p</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">final_TL_i_trained_vec</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_i</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">final_TL_e_trained_vec</span> <span class="o">=</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">s_model</span><span class="o">.</span><span class="n">TL_e</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">temp_TL_coef_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">final_TL_p_trained</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">final_TL_i_trained_vec</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">temp_TL_coef_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_TL_i_trained_vec</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">final_TL_e_trained_vec</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">temp_TL_coef_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_TL_e_trained_vec</span><span class="p">)</span>
        <span class="n">final_TL_coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">temp_TL_coef_list</span><span class="p">)</span>


    <span class="c1"># Final evaluation on training data</span>
    <span class="n">final_TL_p_eval</span><span class="p">,</span> <span class="n">final_TL_i_mat_eval</span><span class="p">,</span> <span class="n">final_TL_e_mat_eval</span> <span class="o">=</span> <span class="n">TL_vec2mat</span><span class="p">(</span><span class="n">final_TL_coef</span><span class="p">,</span> <span class="n">terms_A</span><span class="p">,</span> <span class="n">Bt_scale</span><span class="o">=</span><span class="n">Bt_scale_val</span><span class="p">)</span>

    <span class="n">y_hat_final</span><span class="p">,</span> <span class="n">err_final</span> <span class="o">=</span> <span class="n">nn_comp_3_test</span><span class="p">(</span>
        <span class="n">B_unit_np_T</span><span class="p">,</span> <span class="n">B_vec_np_T</span><span class="p">,</span> <span class="n">B_vec_dot_np_T</span><span class="p">,</span>
        <span class="n">x_norm_final_T</span><span class="p">,</span> <span class="c1"># (features, [window,] samples)</span>
        <span class="n">y_f32</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> 
        <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> 
        <span class="n">final_TL_p_eval</span><span class="p">,</span> <span class="n">final_TL_i_mat_eval</span><span class="p">,</span> <span class="n">final_TL_e_mat_eval</span><span class="p">,</span>
        <span class="n">model_type</span><span class="p">,</span> <span class="n">y_type</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs</span><span class="p">,</span> 
        <span class="n">use_nn</span><span class="o">=</span><span class="p">(</span><span class="kc">True</span> <span class="k">if</span> <span class="n">model_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3tl&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="kc">False</span><span class="p">),</span> <span class="c1"># Use NN unless it&#39;s pure TL</span>
        <span class="n">silent</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> 
        <span class="n">err_std_final</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_final</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_final</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: M3 final train error: </span><span class="si">{</span><span class="n">err_std_final</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>

    <span class="c1"># Final evaluation on test data if provided</span>
    <span class="k">if</span> <span class="n">x_test_raw_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x_test_raw_in</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">y_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> \
       <span class="n">A_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">Bt_test_f32</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        
        <span class="n">x_test_norm_final_eval_T_th</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># Re-prepare for test</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3w&quot;</span><span class="p">,</span> <span class="s2">&quot;m3tf&quot;</span><span class="p">]:</span>
             <span class="k">if</span> <span class="n">x_test_norm_final_eval_T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># This was (feat, win, samp)</span>
                <span class="n">x_test_norm_final_eval_T_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_test_norm_final_eval_T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">x_test_norm_pca_np_T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># This was (feat, samp)</span>
             <span class="n">x_test_norm_final_eval_T_th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_test_norm_pca_np_T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">B_unit_test_np_T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x_test_norm_final_eval_T_th</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">nn_comp_3_test</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">B_unit_test_np_T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span> 
                <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">B_vec_test_np_T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)),</span> 
                <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">B_vec_dot_test_np_T</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> <span class="k">if</span> <span class="n">B_vec_dot_test_np_T</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">x_test_norm_final_eval_T_th</span><span class="p">,</span> <span class="c1"># nn_comp_3_test expects (features, [win,] samples)</span>
                <span class="n">y_test_f32</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span>
                <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> 
                <span class="n">final_TL_p_eval_th</span><span class="p">,</span>
                <span class="n">final_TL_i_mat_eval_th</span><span class="p">,</span>
                <span class="n">final_TL_e_mat_eval_th</span> <span class="k">if</span> <span class="n">final_TL_e_mat_eval_th</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">model_type</span><span class="p">,</span> <span class="n">y_type</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_test</span><span class="p">,</span> 
                <span class="n">use_nn</span><span class="o">=</span><span class="p">(</span><span class="kc">True</span> <span class="k">if</span> <span class="n">model_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;m3tl&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="kc">False</span><span class="p">),</span> 
                <span class="n">silent</span><span class="o">=</span><span class="n">silent</span> 
            <span class="p">)</span>
        
    <span class="k">return</span> <span class="n">s_model</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">final_TL_coef</span><span class="p">,</span> <span class="n">data_norms_out</span><span class="p">,</span> <span class="n">y_hat_final</span><span class="p">,</span> <span class="n">err_final</span></div>

<div class="viewcode-block" id="plsr_fit">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.plsr_fit">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">plsr_fit</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
    <span class="n">no_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">data_norms_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_set</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># If true, returns coef_set instead</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fit a multi-input, single-output (MISO for now) partial least squares regression (PLSR) model.</span>
<span class="sd">    Python translation of MagNav.jl&#39;s plsr_fit.</span>
<span class="sd">    Note: The Julia version supports MIMO (Ny &gt; 1), this Python version is simplified</span>
<span class="sd">    to MISO (Ny=1) for now, as y is typically a 1D vector in this context.</span>
<span class="sd">    If MIMO is needed, q_out and coef_set dimensions would need adjustment.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">y_proc</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Ensure y is 2D (N, 1) for consistency</span>
    <span class="k">elif</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">y_proc</span> <span class="o">=</span> <span class="n">y</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;y must be a 1D array or 2D array with one column, got </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># Default to number of features</span>

    <span class="n">Nf</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">Ny</span> <span class="o">=</span> <span class="n">y_proc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># Should be 1 for MISO</span>

    <span class="k">if</span> <span class="n">no_norm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">no_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Nf</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>


    <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="n">Nf</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: reducing k from </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">Nf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">Nf</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;=</span><span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: k must be &gt; 0. Setting k=1.&quot;</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span>


    <span class="n">norm_type_x</span> <span class="o">=</span> <span class="s2">&quot;standardize&quot;</span>
    <span class="n">norm_type_y</span> <span class="o">=</span> <span class="s2">&quot;standardize&quot;</span>
    <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span><span class="o">*</span><span class="mi">4</span>


    <span class="k">if</span> <span class="n">data_norms_in</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">data_norms_in</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># y_scale is last</span>
        <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">x_norm</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_x</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm</span><span class="p">)</span>
        <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">y_norm</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">y_proc</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_y</span><span class="p">)</span>
        <span class="n">data_norms_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="n">unpack_data_norms</span><span class="p">(</span><span class="n">data_norms_in</span><span class="p">)</span> <span class="c1"># type: ignore</span>
        <span class="n">x_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">y_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_proc</span> <span class="o">-</span> <span class="n">y_bias</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_scale</span> <span class="k">if</span> <span class="n">y_scale</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span> <span class="c1"># y_bias/scale are scalar for 1D y</span>
        <span class="n">data_norms_out</span> <span class="o">=</span> <span class="n">data_norms_in</span>
    
    <span class="c1"># Ensure y_norm is 2D (N,1)</span>
    <span class="k">if</span> <span class="n">y_norm</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">y_norm</span> <span class="o">=</span> <span class="n">y_norm</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># PLS algorithm (NIPALS-based approach as in Julia example)</span>
    <span class="n">x_current</span> <span class="o">=</span> <span class="n">x_norm</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">y_current</span> <span class="o">=</span> <span class="n">y_norm</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    
    <span class="n">T_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">k</span><span class="p">))</span> <span class="c1"># Input scores</span>
    <span class="n">P_loadings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Nf</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>       <span class="c1"># Input loadings</span>
    <span class="n">Q_loadings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Ny</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>       <span class="c1"># Output loadings (for MISO, Ny=1, so (1,k))</span>
    <span class="n">W_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Nf</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>        <span class="c1"># Weights</span>

    <span class="k">if</span> <span class="n">return_set</span><span class="p">:</span> <span class="c1"># For MIMO PLS, coef_set would be (Nf, Ny, k)</span>
        <span class="n">coef_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Nf</span><span class="p">,</span> <span class="n">Ny</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>


    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x_current</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">y_current</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">break</span> <span class="c1"># No data left</span>

        <span class="c1"># Calculate weights w: X&#39;y / ||X&#39;y|| (simplified for MISO y_current is (N,1))</span>
        <span class="c1"># For MISO, y_current.T @ x_current would be (1, Nf). We need X&#39;y.</span>
        <span class="c1"># So, x_current.T @ y_current gives (Nf, 1)</span>
        <span class="n">xy_cov</span> <span class="o">=</span> <span class="n">x_current</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y_current</span> <span class="c1"># (Nf, Ny)</span>
        
        <span class="c1"># For MISO (Ny=1), xy_cov is (Nf, 1).</span>
        <span class="c1"># The SVD approach in Julia `svd(Cyx&#39;)` where Cyx is Ny x Nf.</span>
        <span class="c1"># `Cyx&#39;` is Nf x Ny. U from svd(Cyx&#39;) is Nf x min(Nf,Ny). u = U[:,0]</span>
        <span class="c1"># Here, for MISO, we can directly use xy_cov as the direction.</span>
        <span class="k">if</span> <span class="n">xy_cov</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">continue</span> <span class="c1"># No features left or data</span>
        
        <span class="c1"># w_i = xy_cov[:,0] / np.linalg.norm(xy_cov[:,0]) # Weight for this component (Nf,)</span>
        <span class="c1"># A common way for PLS1 (single y): w = X&#39;y</span>
        <span class="n">w_i</span> <span class="o">=</span> <span class="n">x_current</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y_current</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># (Nf,)</span>
        <span class="n">w_i</span> <span class="o">=</span> <span class="n">w_i</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">w_i</span><span class="p">)</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">w_i</span><span class="p">)</span> <span class="o">!=</span><span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">W_weights</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">w_i</span>

        <span class="c1"># Calculate scores t = Xw / ||w|| (or Xw / w&#39;w if w not normalized, but here it is)</span>
        <span class="n">t_i</span> <span class="o">=</span> <span class="n">x_current</span> <span class="o">@</span> <span class="n">w_i</span> <span class="c1"># (N,)</span>
        <span class="n">T_scores</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">t_i</span>

        <span class="c1"># Calculate loadings p = X&#39;t / t&#39;t</span>
        <span class="n">p_i</span> <span class="o">=</span> <span class="n">x_current</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">t_i</span> <span class="o">/</span> <span class="p">(</span><span class="n">t_i</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">t_i</span> <span class="k">if</span> <span class="n">t_i</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">t_i</span> <span class="o">!=</span><span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span> <span class="c1"># (Nf,)</span>
        <span class="n">P_loadings</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_i</span>

        <span class="c1"># Calculate output loadings q = Y&#39;t / t&#39;t</span>
        <span class="n">q_i</span> <span class="o">=</span> <span class="n">y_current</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">t_i</span> <span class="o">/</span> <span class="p">(</span><span class="n">t_i</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">t_i</span> <span class="k">if</span> <span class="n">t_i</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">t_i</span> <span class="o">!=</span><span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span> <span class="c1"># (Ny,) -&gt; (1,) for MISO</span>
        <span class="n">Q_loadings</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">q_i</span> <span class="c1"># q_i is (1,)</span>

        <span class="c1"># Deflate X and Y</span>
        <span class="n">x_current</span> <span class="o">=</span> <span class="n">x_current</span> <span class="o">-</span> <span class="n">t_i</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">@</span> <span class="n">p_i</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
        <span class="n">y_current</span> <span class="o">=</span> <span class="n">y_current</span> <span class="o">-</span> <span class="n">t_i</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">@</span> <span class="n">q_i</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">.</span><span class="n">T</span> <span class="c1"># q_i is (1,)</span>

        <span class="k">if</span> <span class="n">return_set</span><span class="p">:</span>
            <span class="c1"># Regression coefficients B = W(P&#39;W)^-1 Q&#39;</span>
            <span class="c1"># This computes B for the current number of components i+1</span>
            <span class="c1"># W_subset is (Nf, i+1), P_subset is (Nf, i+1), Q_subset is (Ny, i+1)</span>
            <span class="n">W_sub</span> <span class="o">=</span> <span class="n">W_weights</span><span class="p">[:,</span> <span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">P_sub</span> <span class="o">=</span> <span class="n">P_loadings</span><span class="p">[:,</span> <span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">Q_sub</span> <span class="o">=</span> <span class="n">Q_loadings</span><span class="p">[:,</span> <span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># (Ny, i+1)</span>
            
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># B_i = W_sub @ np.linalg.inv(P_sub.T @ W_sub) @ Q_sub.T # (Nf, Ny)</span>
                <span class="c1"># For MISO, Q_sub.T is (i+1, 1)</span>
                <span class="c1"># Result B_i is (Nf, 1)</span>
                <span class="n">term_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">P_sub</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">W_sub</span><span class="p">)</span>
                <span class="n">B_i</span> <span class="o">=</span> <span class="n">W_sub</span> <span class="o">@</span> <span class="n">term_inv</span> <span class="o">@</span> <span class="n">Q_sub</span><span class="o">.</span><span class="n">T</span>
                <span class="n">coef_set</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">B_i</span>
            <span class="k">except</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
                 <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WARN: Singular matrix in PLSR coefficient calculation at component </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">. Using pseudo-inverse.&quot;</span><span class="p">)</span>
                 <span class="n">term_pinv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">P_sub</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">W_sub</span><span class="p">)</span>
                 <span class="n">B_i</span> <span class="o">=</span> <span class="n">W_sub</span> <span class="o">@</span> <span class="n">term_pinv</span> <span class="o">@</span> <span class="n">Q_sub</span><span class="o">.</span><span class="n">T</span>
                 <span class="n">coef_set</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">B_i</span>

    <span class="k">if</span> <span class="n">return_set</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">coef_set</span>

    <span class="c1"># Final regression coefficients B = W(P&#39;W)^-1 Q&#39;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">final_coeffs</span> <span class="o">=</span> <span class="n">W_weights</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">P_loadings</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">W_weights</span><span class="p">)</span> <span class="o">@</span> <span class="n">Q_loadings</span><span class="o">.</span><span class="n">T</span>
    <span class="k">except</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARN: Singular matrix in final PLSR coefficient calculation. Using pseudo-inverse.&quot;</span><span class="p">)</span>
        <span class="n">final_coeffs</span> <span class="o">=</span> <span class="n">W_weights</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">P_loadings</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">W_weights</span><span class="p">)</span> <span class="o">@</span> <span class="n">Q_loadings</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># For MISO, final_coeffs will be (Nf, 1). We want (Nf,).</span>
    <span class="n">model_coeffs</span> <span class="o">=</span> <span class="n">final_coeffs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">model_bias</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># PLS on centered data, bias is effectively handled by y_bias</span>
    <span class="n">model_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">model_coeffs</span><span class="p">,</span> <span class="n">model_bias</span><span class="p">)</span>

    <span class="c1"># Get results on the full (untrimmed, but normalized if applicable) dataset</span>
    <span class="c1"># linear_test expects x_norm, y_raw, y_bias, y_scale, model</span>
    <span class="n">y_hat_full</span><span class="p">,</span> <span class="n">err_full</span> <span class="o">=</span> <span class="n">linear_test</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">y_proc</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">model_out</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_full</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_full</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
        <span class="c1"># The Julia version prints input/output residue variance. This is a bit more involved.</span>
        <span class="c1"># For now, just print the fit error.</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: PLSR fit error: </span><span class="si">{</span><span class="n">err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>
             
    <span class="k">return</span> <span class="n">model_out</span><span class="p">,</span> <span class="n">data_norms_out</span><span class="p">,</span> <span class="n">y_hat_full</span><span class="p">,</span> <span class="n">err_full</span></div>


<div class="viewcode-block" id="elasticnet_fit">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.elasticnet_fit">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">elasticnet_fit</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> 
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">,</span> <span class="c1"># L1 ratio (0 for Ridge, 1 for Lasso)</span>
    <span class="n">no_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">lambda_val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="c1"># Renamed from λ. If -1, use CV.</span>
    <span class="n">data_norms_in</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">l_segs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fit an elastic net (ridge regression and/or Lasso) model to data.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: N x Nf data matrix (Nf is number of features)</span>
<span class="sd">        y: length-N target vector</span>
<span class="sd">        alpha: (optional) ElasticNet mixing parameter, with 0 &lt;= alpha &lt;= 1.</span>
<span class="sd">                alpha=0 is L2 penalty (Ridge), alpha=1 is L1 penalty (Lasso).</span>
<span class="sd">        no_norm: (optional) length-Nf Boolean indices of features to not be normalized</span>
<span class="sd">        lambda_val: (optional) elastic net regularization strength. </span>
<span class="sd">                     If -1, determine with cross-validation.</span>
<span class="sd">        data_norms_in: (optional) length-4 tuple of data normalizations, (x_bias,x_scale,y_bias,y_scale)</span>
<span class="sd">        l_segs: (optional) length-N_lines vector of lengths of lines, sum(l_segs) = N</span>
<span class="sd">        silent: (optional) if true, no print outs</span>

<span class="sd">    Returns:</span>
<span class="sd">        model: length-2 tuple of elastic net model, (length-Nf coefficients, bias)</span>
<span class="sd">        data_norms_out: length-4 tuple of data normalizations, (x_bias,x_scale,y_bias,y_scale)</span>
<span class="sd">        y_hat: length-N prediction vector</span>
<span class="sd">        err: length-N mean-corrected (per line) error</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;elasticnet_fit expects a 1D target vector y, but got shape </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">y_flat</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">no_norm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">no_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">l_segs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">l_segs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">y_flat</span><span class="p">)]</span>

    <span class="n">norm_type_x</span> <span class="o">=</span> <span class="s2">&quot;standardize&quot;</span> <span class="c1"># ElasticNet benefits from standardized features</span>
    <span class="n">norm_type_y</span> <span class="o">=</span> <span class="s2">&quot;standardize&quot;</span> <span class="c1"># Standardize y as well</span>
    <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span><span class="o">*</span><span class="mi">4</span>


    <span class="k">if</span> <span class="n">data_norms_in</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">data_norms_in</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># y_scale is last</span>
        <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">x_norm</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_x</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm</span><span class="p">)</span>
        <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">y_norm_flat</span> <span class="o">=</span> <span class="n">norm_sets</span><span class="p">(</span><span class="n">y_flat</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="n">norm_type_y</span><span class="p">)</span>
        <span class="n">data_norms_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x_bias</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span> <span class="o">=</span> <span class="n">unpack_data_norms</span><span class="p">(</span><span class="n">data_norms_in</span><span class="p">)</span> <span class="c1"># type: ignore</span>
        <span class="n">x_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">x_scale</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">y_norm_flat</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_flat</span> <span class="o">-</span> <span class="n">y_bias</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_scale</span> <span class="k">if</span> <span class="n">y_scale</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">data_norms_out</span> <span class="o">=</span> <span class="n">data_norms_in</span>
    
    <span class="k">if</span> <span class="n">x_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># No data</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARN: No data for elasticnet_fit. Returning zero coefficients.&quot;</span><span class="p">)</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">intercept</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">model_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">intercept</span><span class="p">)</span>
        <span class="n">y_hat_full</span><span class="p">,</span> <span class="n">err_full</span> <span class="o">=</span> <span class="n">linear_test</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">y_flat</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">model_out</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_out</span><span class="p">,</span> <span class="n">data_norms_out</span><span class="p">,</span> <span class="n">y_hat_full</span><span class="p">,</span> <span class="n">err_full</span>

    <span class="c1"># Scikit-learn&#39;s ElasticNet: alpha is l1_ratio, lambda is the overall strength alpha (confusingly named)</span>
    <span class="c1"># Julia&#39;s GLMNet: alpha is mixing (0=ridge, 1=lasso), lambda is strength</span>
    <span class="c1"># sklearn ElasticNet: alpha parameter is `l1_ratio`. Total penalty is `alpha * (l1_ratio * L1 + 0.5 * (1 - l1_ratio) * L2)`</span>
    <span class="c1"># So, sklearn `l1_ratio` corresponds to Julia `alpha`.</span>
    <span class="c1"># Sklearn `alpha` (strength) corresponds to Julia `lambda`.</span>

    <span class="k">if</span> <span class="n">lambda_val</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># Use cross-validation to find best lambda (alpha in sklearn)</span>
        <span class="c1"># ElasticNetCV finds the best alpha (strength) and l1_ratio (mixing)</span>
        <span class="c1"># We want to fix l1_ratio (Julia&#39;s alpha) and find best strength (Julia&#39;s lambda)</span>
        <span class="c1"># If we want to fix l1_ratio = alpha (from arg), we can pass it as a list: [alpha]</span>
        <span class="c1"># cv_model = ElasticNetCV(l1_ratio=[alpha] if 0 &lt; alpha &lt; 1 else alpha, # handles pure Lasso/Ridge</span>
        <span class="c1">#                         alphas=None, # Let CV find best strength</span>
        <span class="c1">#                         cv=5, random_state=0, fit_intercept=True,</span>
        <span class="c1">#                         # sklearn ElasticNetCV standardizes X by default if fit_intercept=True</span>
        <span class="c1">#                         # but we have already standardized X, so normalize=False (deprecated) or handle carefully.</span>
        <span class="c1">#                         # It&#39;s safer to pass pre-standardized X and set fit_intercept=True.</span>
        <span class="c1">#                         # The `normalize` parameter is deprecated.</span>
        <span class="c1">#                         # If X is already standardized, fit_intercept=True will work correctly.</span>
        <span class="c1">#                         )</span>
        <span class="c1"># Simpler: if lambda_val is -1, we might need to define a set of lambdas to try,</span>
        <span class="c1"># or use a simpler approach if only strength is CV&#39;d.</span>
        <span class="c1"># The Julia code `glmnetcv` finds the best lambda for a fixed alpha.</span>
        <span class="c1"># `ElasticNetCV` in sklearn can find best `alpha` (strength) for given `l1_ratio`(s).</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: ElasticNet using Cross-Validation to find lambda for l1_ratio=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">cv_model</span> <span class="o">=</span> <span class="n">ElasticNetCV</span><span class="p">(</span><span class="n">l1_ratio</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_alphas</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
        <span class="n">cv_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">y_norm_flat</span><span class="p">)</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="n">cv_model</span><span class="o">.</span><span class="n">coef_</span>
        <span class="n">intercept</span> <span class="o">=</span> <span class="n">cv_model</span><span class="o">.</span><span class="n">intercept_</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: ElasticNetCV selected lambda (strength): </span><span class="si">{</span><span class="n">cv_model</span><span class="o">.</span><span class="n">alpha_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Use provided lambda_val (strength)</span>
        <span class="c1"># sklearn ElasticNet: alpha is strength, l1_ratio is mixing</span>
        <span class="n">model_sk</span> <span class="o">=</span> <span class="n">ElasticNet</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">lambda_val</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
        <span class="n">model_sk</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">y_norm_flat</span><span class="p">)</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="n">model_sk</span><span class="o">.</span><span class="n">coef_</span>
        <span class="n">intercept</span> <span class="o">=</span> <span class="n">model_sk</span><span class="o">.</span><span class="n">intercept_</span>

    <span class="c1"># The model from scikit-learn includes an intercept.</span>
    <span class="c1"># The Julia version via MLJLinearModels also fits an intercept.</span>
    <span class="c1"># The `linear_test` function expects model as (coeffs, bias_val=0.0) if bias is handled by y_norm.</span>
    <span class="c1"># If y_norm was (y - y_mean) / y_std, then prediction is (X_norm @ coef + intercept_norm) * y_std + y_mean.</span>
    <span class="c1"># Our `linear_fwd` and `linear_test` assume the intercept is part of the normalized prediction.</span>
    <span class="c1"># So, the intercept from ElasticNet (which is on y_norm scale) is the &#39;bias&#39; for linear_fwd.</span>
    <span class="n">model_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">intercept</span><span class="p">)</span>

    <span class="n">y_hat_full</span><span class="p">,</span> <span class="n">err_full</span> <span class="o">=</span> <span class="n">linear_test</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">y_flat</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span> <span class="n">y_scale</span><span class="p">,</span> <span class="n">model_out</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_full</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_full</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: ElasticNet fit error: </span><span class="si">{</span><span class="n">err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>
             
    <span class="k">return</span> <span class="n">model_out</span><span class="p">,</span> <span class="n">data_norms_out</span><span class="p">,</span> <span class="n">y_hat_full</span><span class="p">,</span> <span class="n">err_full</span></div>


<span class="k">def</span><span class="w"> </span><span class="nf">comp_train</span><span class="p">(</span>
    <span class="n">comp_params</span><span class="p">:</span> <span class="n">CompParams</span><span class="p">,</span> 
    <span class="n">xyz</span><span class="p">:</span> <span class="n">XYZ</span><span class="p">,</span> 
    <span class="n">ind</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">mapS</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">mapS_null</span><span class="p">,</span> <span class="c1"># Union[MapS, MapSd, MapS3D]</span>
    <span class="n">temp_params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TempParams</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">xyz_test</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">XYZ</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ind_test</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">CompParams</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train an aeromagnetic compensation model.</span>
<span class="sd">    Base version taking XYZ and ind.</span>

<span class="sd">    Args:</span>
<span class="sd">        comp_params: CompParams object (NNCompParams or LinCompParams).</span>
<span class="sd">        xyz: XYZ flight data struct.</span>
<span class="sd">        ind: Selected data indices for training.</span>
<span class="sd">        mapS: (optional) MapS struct, only used for y_type = &#39;b&#39;, &#39;c&#39;.</span>
<span class="sd">        temp_params: (optional) TempParams struct.</span>
<span class="sd">        xyz_test: (optional) XYZ held-out test data struct.</span>
<span class="sd">        ind_test: (optional) Indices for test data struct.</span>
<span class="sd">        silent: (optional) If true, no print outs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        comp_params: Updated CompParams object.</span>
<span class="sd">        y: Target vector.</span>
<span class="sd">        y_hat: Prediction vector.</span>
<span class="sd">        err: Compensation error.</span>
<span class="sd">        features: List of feature names used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># for reproducibility</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">temp_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">temp_params</span> <span class="o">=</span> <span class="n">TempParams</span><span class="p">()</span> <span class="c1"># Use default TempParams if None</span>

    <span class="c1"># Unpack parameters common to both or specific to NNCompParams/LinCompParams</span>
    <span class="c1"># This needs to be done carefully based on the type of comp_params</span>
    
    <span class="c1"># Common attributes</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">model_type</span>
    <span class="n">y_type</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">y_type</span>
    <span class="n">use_mag</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">use_mag</span>
    <span class="n">use_vec</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">use_vec</span>
    <span class="n">data_norms</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="c1"># This will be updated</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="c1"># This will be updated</span>
    <span class="n">terms</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">terms</span>
    <span class="n">terms_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">terms_A</span><span class="p">)</span> <span class="c1"># Ensure it&#39;s a mutable list</span>
    <span class="n">sub_diurnal</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">sub_diurnal</span>
    <span class="n">sub_igrf</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">sub_igrf</span>
    <span class="n">bpf_mag</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">bpf_mag</span>
    <span class="n">reorient_vec</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">reorient_vec</span> <span class="c1"># Not directly used in this dispatch, but part of params</span>
    <span class="n">norm_type_A</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">norm_type_A</span>
    <span class="n">norm_type_x</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">norm_type_x</span>
    <span class="n">norm_type_y</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">norm_type_y</span>
    <span class="n">features_setup</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">features_setup</span><span class="p">)</span>
    <span class="n">features_no_norm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">features_no_norm</span><span class="p">)</span>


    <span class="c1"># NNCompParams specific</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">):</span>
        <span class="n">TL_coef_nn</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span> <span class="c1"># Specific to NN models that might use it</span>
        <span class="n">eta_adam</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">η_adam</span>
        <span class="n">epoch_adam</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_adam</span>
        <span class="n">epoch_lbfgs</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_lbfgs</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">hidden</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">activation</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">loss</span> <span class="c1"># Renamed to loss_fn in train functions</span>
        <span class="n">batchsize</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">batchsize</span>
        <span class="n">frac_train</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">frac_train</span>
        <span class="n">alpha_sgl</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">α_sgl</span>
        <span class="n">lambda_sgl</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">λ_sgl</span>
        <span class="n">k_pca</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">k_pca</span>
        <span class="n">drop_fi</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi</span>
        <span class="n">drop_fi_bson</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi_bson</span>
        <span class="n">drop_fi_csv</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi_csv</span>
        <span class="c1"># perm_fi = comp_params.perm_fi # Not used in comp_train in Julia</span>
        <span class="c1"># perm_fi_csv = comp_params.perm_fi_csv</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">LinCompParams</span><span class="p">):</span>
        <span class="n">k_plsr</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">k_plsr</span>
        <span class="n">lambda_TL</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">λ_TL</span> <span class="c1"># This is lambda_ridge for linear_fit with TL</span>
        <span class="c1"># Set defaults for NN params not in LinCompParams to avoid UnboundLocalError later if logic paths are complex</span>
        <span class="c1"># Though ideally, these paths are mutually exclusive.</span>
        <span class="n">drop_fi</span> <span class="o">=</span> <span class="kc">False</span> 
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;comp_params must be an instance of NNCompParams or LinCompParams&quot;</span><span class="p">)</span>

    <span class="c1"># TempParams unpack</span>
    <span class="n">sigma_curriculum</span> <span class="o">=</span> <span class="n">temp_params</span><span class="o">.</span><span class="n">σ_curriculum</span>
    <span class="n">l_window</span> <span class="o">=</span> <span class="n">temp_params</span><span class="o">.</span><span class="n">l_window</span>
    <span class="n">window_type_temporal</span> <span class="o">=</span> <span class="n">temp_params</span><span class="o">.</span><span class="n">window_type</span> <span class="c1"># Renamed to avoid clash</span>
    <span class="n">tf_layer_type</span> <span class="o">=</span> <span class="n">temp_params</span><span class="o">.</span><span class="n">tf_layer_type</span>
    <span class="n">tf_norm_type</span> <span class="o">=</span> <span class="n">temp_params</span><span class="o">.</span><span class="n">tf_norm_type</span>
    <span class="n">dropout_prob</span> <span class="o">=</span> <span class="n">temp_params</span><span class="o">.</span><span class="n">dropout_prob</span>
    <span class="n">N_tf_head</span> <span class="o">=</span> <span class="n">temp_params</span><span class="o">.</span><span class="n">N_tf_head</span>
    <span class="n">tf_gain</span> <span class="o">=</span> <span class="n">temp_params</span><span class="o">.</span><span class="n">tf_gain</span>
    
    <span class="c1"># Adjust y_type based on model_type (mirroring Julia logic)</span>
    <span class="n">original_y_type</span> <span class="o">=</span> <span class="n">y_type</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">y_type</span> <span class="o">!=</span> <span class="s2">&quot;e&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Forcing y_type </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2"> -&gt; &#39;e&#39; (BPF&#39;d total field) for model_type </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">y_type</span> <span class="o">=</span> <span class="s2">&quot;e&quot;</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;map_TL&quot;</span> <span class="ow">and</span> <span class="n">y_type</span> <span class="o">!=</span> <span class="s2">&quot;c&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Forcing y_type </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2"> -&gt; &#39;c&#39; (aircraft field #1, using map) for model_type </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">y_type</span> <span class="o">=</span> <span class="s2">&quot;c&quot;</span>
    
    <span class="c1"># Adjust norm_types for certain linear models</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;elasticnet&quot;</span><span class="p">,</span> <span class="s2">&quot;plsr&quot;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">norm_type_x</span> <span class="o">!=</span> <span class="s2">&quot;standardize&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Forcing norm_type_x </span><span class="si">{</span><span class="n">norm_type_x</span><span class="si">}</span><span class="s2"> -&gt; &#39;standardize&#39; for </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">norm_type_x</span> <span class="o">=</span> <span class="s2">&quot;standardize&quot;</span>
        <span class="k">if</span> <span class="n">norm_type_y</span> <span class="o">!=</span> <span class="s2">&quot;standardize&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Forcing norm_type_y </span><span class="si">{</span><span class="n">norm_type_y</span><span class="si">}</span><span class="s2"> -&gt; &#39;standardize&#39; for </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">norm_type_y</span> <span class="o">=</span> <span class="s2">&quot;standardize&quot;</span>

    <span class="c1"># Adjust terms_A for M3 models</span>
    <span class="k">if</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
        <span class="n">original_terms_A_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">terms_A</span><span class="p">)</span>
        <span class="n">original_TL_coef_len</span> <span class="o">=</span> <span class="n">TL_coef_nn</span><span class="o">.</span><span class="n">size</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">)</span> <span class="ow">and</span> <span class="n">TL_coef_nn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        
        <span class="n">terms_A_updated</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">TL_coef_indices_to_keep</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">current_coeff_idx</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="c1"># Simulate create_TL_A term parsing to correctly adjust TL_coef_nn if terms are removed</span>
        <span class="c1"># This is a simplified version. A robust solution would need the exact column counts from create_TL_A.</span>
        <span class="c1"># For now, assume standard term sizes if present.</span>
        <span class="n">term_sizes</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;permanent&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;p&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;permanent3&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;p3&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span>
                      <span class="s2">&quot;induced&quot;</span><span class="p">:</span><span class="mi">6</span><span class="p">,</span> <span class="s2">&quot;i&quot;</span><span class="p">:</span><span class="mi">6</span><span class="p">,</span> <span class="s2">&quot;induced6&quot;</span><span class="p">:</span><span class="mi">6</span><span class="p">,</span> <span class="s2">&quot;i6&quot;</span><span class="p">:</span><span class="mi">6</span><span class="p">,</span> <span class="s2">&quot;induced5&quot;</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;i5&quot;</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;induced3&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;i3&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span>
                      <span class="s2">&quot;eddy&quot;</span><span class="p">:</span><span class="mi">9</span><span class="p">,</span> <span class="s2">&quot;e&quot;</span><span class="p">:</span><span class="mi">9</span><span class="p">,</span> <span class="s2">&quot;eddy9&quot;</span><span class="p">:</span><span class="mi">9</span><span class="p">,</span> <span class="s2">&quot;e9&quot;</span><span class="p">:</span><span class="mi">9</span><span class="p">,</span> <span class="s2">&quot;eddy8&quot;</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="s2">&quot;e8&quot;</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="s2">&quot;eddy3&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;e3&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">}</span>
        
        <span class="n">temp_terms_A_parsing</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># To track parsed terms and their original indices in TL_coef_nn</span>
        
        <span class="c1"># This parsing needs to be in the order create_TL_A would assemble them.</span>
        <span class="c1"># Assuming: permanent, then induced, then eddy, then others.</span>
        <span class="c1"># This is a simplification. The actual create_TL_A logic is complex.</span>
        
        <span class="n">parsed_coeffs_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># Simplified parsing logic - this needs to be robust based on create_TL_A</span>
        <span class="c1"># For now, we&#39;ll just filter terms_A and assume TL_coef_nn is handled correctly by nn_comp_3_train</span>
        <span class="c1"># if it receives a shorter terms_A list and a TL_coef that might be too long (it should use TL_vec_split).</span>
        
        <span class="n">terms_A_to_remove</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fdm&quot;</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">,</span> <span class="s2">&quot;fdm3&quot;</span><span class="p">,</span> <span class="s2">&quot;f3&quot;</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">]</span>
        <span class="n">terms_A_final</span> <span class="o">=</span> <span class="p">[</span><span class="n">term</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">terms_A</span> <span class="k">if</span> <span class="n">term</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">terms_A_to_remove</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">terms_A_final</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">terms_A</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Removing derivative/bias terms from terms_A for M3 model. Original: </span><span class="si">{</span><span class="n">terms_A</span><span class="si">}</span><span class="s2">, New: </span><span class="si">{</span><span class="n">terms_A_final</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">terms_A</span> <span class="o">=</span> <span class="n">terms_A_final</span>
            <span class="c1"># Note: TL_coef_nn might need adjustment here if its length was based on the original terms_A.</span>
            <span class="c1"># nn_comp_3_train&#39;s internal TL_vec_split should handle a potentially longer TL_coef_nn</span>
            <span class="c1"># if terms_A is shorter, by only using the relevant parts of TL_coef_nn.</span>

    <span class="c1"># Get map values if needed</span>
    <span class="n">map_val_data</span> <span class="o">=</span> <span class="n">get_map_val</span><span class="p">(</span><span class="n">mapS</span><span class="p">,</span> <span class="n">xyz</span><span class="o">.</span><span class="n">traj</span><span class="p">,</span> <span class="n">ind</span><span class="p">)</span> <span class="k">if</span> <span class="n">y_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>

    <span class="c1"># Create Tolles-Lawson A matrix and other B components</span>
    <span class="c1"># `create_TL_A` needs to be fully implemented from `tolles_lawson.py`</span>
    <span class="c1"># For now, using the placeholder which might not be fully accurate.</span>
    <span class="c1"># The `terms` argument for create_TL_A in Julia is `terms_A` from comp_params.</span>
    
    <span class="c1"># Call the version of create_TL_A from tolles_lawson.py if available, else placeholder</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.tolles_lawson</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_TL_A</span> <span class="k">as</span> <span class="n">create_TL_A_actual</span>
        <span class="c1"># Check if it&#39;s different from the placeholder, to avoid recursion if it&#39;s the same file</span>
        <span class="k">if</span> <span class="s1">&#39;compensation&#39;</span> <span class="ow">in</span> <span class="n">create_TL_A_actual</span><span class="o">.</span><span class="vm">__module__</span> <span class="p">:</span> <span class="c1"># if it&#39;s the placeholder in this file</span>
            <span class="n">create_TL_A_fn</span> <span class="o">=</span> <span class="n">create_TL_A</span> <span class="c1"># use placeholder</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">create_TL_A_fn</span> <span class="o">=</span> <span class="n">create_TL_A_actual</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">create_TL_A_fn</span> <span class="o">=</span> <span class="n">create_TL_A</span> <span class="c1"># Use placeholder if import fails</span>

    <span class="n">A_matrix_np</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">Bt_np</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">B_dot_np</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">:</span>
        <span class="n">A_matrix_np</span> <span class="o">=</span> <span class="n">create_TL_A_fn</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_vec</span><span class="p">),</span> <span class="n">ind</span><span class="p">,</span> <span class="n">terms</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">Bt</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_mag</span><span class="p">)[</span><span class="n">ind</span><span class="p">])</span>
    <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;map_TL&quot;</span><span class="p">:</span>
        <span class="n">A_matrix_np</span> <span class="o">=</span> <span class="n">create_TL_A_fn</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_vec</span><span class="p">),</span> <span class="n">ind</span><span class="p">,</span> <span class="n">terms</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">Bt</span><span class="o">=</span><span class="n">map_val_data</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># Includes M1, M2, M3, TL, elasticnet, plsr</span>
        <span class="c1"># For M3, create_TL_A returns A, Bt, B_dot</span>
        <span class="c1"># For others, it might just return A. The placeholder needs to handle this.</span>
        <span class="c1"># The fully implemented create_TL_A from tolles_lawson.py should handle return_B=True.</span>
        <span class="n">A_out</span> <span class="o">=</span> <span class="n">create_TL_A_fn</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_vec</span><span class="p">),</span> <span class="n">ind</span><span class="p">,</span> <span class="n">terms</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">return_B</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">Bt_in</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span><span class="n">use_mag</span><span class="p">)[</span><span class="n">ind</span><span class="p">]</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span><span class="n">use_mag</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">A_out</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">A_out</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">Bt_np</span><span class="p">,</span> <span class="n">B_dot_np</span> <span class="o">=</span> <span class="n">A_out</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Assuming it returned only A</span>
            <span class="n">A_matrix_np</span> <span class="o">=</span> <span class="n">A_out</span>
            <span class="c1"># For models other than M3 that might still need Bt, B_dot, they&#39;d need to be derived</span>
            <span class="c1"># or get_Axy should provide them. For now, assume create_TL_A gives what&#39;s needed.</span>
            <span class="c1"># If M1/M2 need Bt/B_dot, this needs to be addressed.</span>
            <span class="c1"># The placeholder create_TL_A returns dummy Bt, B_dot if return_B=True.</span>

    <span class="n">fs</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">xyz</span><span class="o">.</span><span class="n">dt</span> <span class="k">if</span> <span class="n">xyz</span><span class="o">.</span><span class="n">dt</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">10.0</span> <span class="c1"># Default fs if dt is zero</span>
    
    <span class="n">A_no_bpf_np</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">]:</span> <span class="c1"># Store A before BPF for these models</span>
        <span class="n">A_no_bpf_np</span> <span class="o">=</span> <span class="n">A_matrix_np</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;e&quot;</span><span class="p">:</span> <span class="c1"># Bandpass filter A if y_type is &#39;e&#39; (BPF&#39;d total field)</span>
        <span class="c1"># `bpf_data` needs to be fully implemented. Placeholder does no-op.</span>
        <span class="c1"># `get_bpf` also needs to be implemented.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">.analysis_util</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_bpf</span> <span class="k">as</span> <span class="n">get_bpf_actual</span><span class="p">,</span> <span class="n">bpf_data</span> <span class="k">as</span> <span class="n">bpf_data_actual</span>
            <span class="k">if</span> <span class="s1">&#39;compensation&#39;</span> <span class="ow">in</span> <span class="n">get_bpf_actual</span><span class="o">.</span><span class="vm">__module__</span><span class="p">:</span> <span class="c1"># placeholder</span>
                 <span class="n">bpf_coeffs</span> <span class="o">=</span> <span class="n">get_bpf</span><span class="p">(</span><span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
                 <span class="n">A_matrix_np</span> <span class="o">=</span> <span class="n">bpf_data</span><span class="p">(</span><span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">bpf</span><span class="o">=</span><span class="n">bpf_coeffs</span><span class="p">)</span> <span class="k">if</span> <span class="n">bpf_coeffs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">A_matrix_np</span>
            <span class="k">else</span><span class="p">:</span>
                 <span class="n">bpf_coeffs</span> <span class="o">=</span> <span class="n">get_bpf_actual</span><span class="p">(</span><span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span> <span class="c1"># pass1, pass2 defaults</span>
                 <span class="n">A_matrix_np</span> <span class="o">=</span> <span class="n">bpf_data_actual</span><span class="p">(</span><span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">bpf</span><span class="o">=</span><span class="n">bpf_coeffs</span><span class="p">)</span> <span class="k">if</span> <span class="n">bpf_coeffs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">A_matrix_np</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="n">bpf_coeffs</span> <span class="o">=</span> <span class="n">get_bpf</span><span class="p">(</span><span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
            <span class="n">A_matrix_np</span> <span class="o">=</span> <span class="n">bpf_data</span><span class="p">(</span><span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">bpf</span><span class="o">=</span><span class="n">bpf_coeffs</span><span class="p">)</span> <span class="k">if</span> <span class="n">b_coeffs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">A_matrix_np</span>


    <span class="c1"># Load features (x) and target (y)</span>
    <span class="c1"># `get_x` and `get_y` need to be fully implemented.</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.analysis_util</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_x</span> <span class="k">as</span> <span class="n">get_x_actual</span><span class="p">,</span> <span class="n">get_y</span> <span class="k">as</span> <span class="n">get_y_actual</span>
        <span class="n">get_x_fn</span> <span class="o">=</span> <span class="n">get_x_actual</span> <span class="k">if</span> <span class="s1">&#39;compensation&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">get_x_actual</span><span class="o">.</span><span class="vm">__module__</span> <span class="k">else</span> <span class="n">get_x</span>
        <span class="n">get_y_fn</span> <span class="o">=</span> <span class="n">get_y_actual</span> <span class="k">if</span> <span class="s1">&#39;compensation&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">get_y_actual</span><span class="o">.</span><span class="vm">__module__</span> <span class="k">else</span> <span class="n">get_y</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">get_x_fn</span> <span class="o">=</span> <span class="n">get_x</span>
        <span class="n">get_y_fn</span> <span class="o">=</span> <span class="n">get_y</span>

    <span class="n">x_np</span><span class="p">,</span> <span class="n">no_norm_out</span><span class="p">,</span> <span class="n">features_out</span><span class="p">,</span> <span class="n">l_segs_out</span> <span class="o">=</span> <span class="n">get_x_fn</span><span class="p">(</span>
        <span class="n">xyz</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">features_setup</span><span class="p">,</span>
        <span class="n">features_no_norm</span><span class="o">=</span><span class="n">features_no_norm</span><span class="p">,</span> <span class="n">terms</span><span class="o">=</span><span class="n">terms</span><span class="p">,</span> <span class="c1"># `terms` here refers to comp_params.terms (e.g. for specific feature construction)</span>
        <span class="n">sub_diurnal</span><span class="o">=</span><span class="n">sub_diurnal</span><span class="p">,</span> <span class="n">sub_igrf</span><span class="o">=</span><span class="n">sub_igrf</span><span class="p">,</span> <span class="n">bpf_mag</span><span class="o">=</span><span class="n">bpf_mag</span>
    <span class="p">)</span>

    <span class="n">y_np</span> <span class="o">=</span> <span class="n">get_y_fn</span><span class="p">(</span>
        <span class="n">xyz</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">map_val_data</span><span class="p">,</span>
        <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span> <span class="n">use_mag</span><span class="o">=</span><span class="n">use_mag</span><span class="p">,</span>
        <span class="n">sub_diurnal</span><span class="o">=</span><span class="n">sub_diurnal</span><span class="p">,</span> <span class="n">sub_igrf</span><span class="o">=</span><span class="n">sub_igrf</span><span class="p">,</span> <span class="n">bpf_mag</span><span class="o">=</span><span class="n">bpf_mag</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">fs</span> <span class="c1"># Pass fs for potential BPF in get_y</span>
    <span class="p">)</span>
    
    <span class="n">y_no_bpf_np</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">]:</span> <span class="c1"># Get non-BPF&#39;d y for these models for final error calc</span>
        <span class="n">y_no_bpf_np</span> <span class="o">=</span> <span class="n">get_y_fn</span><span class="p">(</span>
            <span class="n">xyz</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">map_val_data</span><span class="p">,</span>
            <span class="n">y_type</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">use_mag</span><span class="o">=</span><span class="n">use_mag</span><span class="p">,</span> <span class="c1"># Typically &#39;d&#39; (delta_mag) for non-BPF comparison</span>
            <span class="n">sub_diurnal</span><span class="o">=</span><span class="n">sub_diurnal</span><span class="p">,</span> <span class="n">sub_igrf</span><span class="o">=</span><span class="n">sub_igrf</span> 
            <span class="c1"># bpf_mag should be False here or handled by y_type=&#39;d&#39;</span>
        <span class="p">)</span>

    <span class="c1"># Prepare test data if ind_test is provided</span>
    <span class="n">A_test_np</span><span class="p">,</span> <span class="n">Bt_test_np</span><span class="p">,</span> <span class="n">B_dot_test_np</span><span class="p">,</span> <span class="n">x_test_np</span><span class="p">,</span> <span class="n">y_test_np</span><span class="p">,</span> <span class="n">l_segs_test_out</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span> <span class="o">*</span> <span class="mi">6</span>
    <span class="k">if</span> <span class="n">ind_test</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ind_test</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">xyz_test_eff</span> <span class="o">=</span> <span class="n">xyz_test</span> <span class="k">if</span> <span class="n">xyz_test</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">xyz</span> <span class="c1"># Default to training xyz if not provided</span>

        <span class="n">map_val_test</span> <span class="o">=</span> <span class="n">get_map_val</span><span class="p">(</span><span class="n">mapS</span><span class="p">,</span> <span class="n">xyz_test_eff</span><span class="o">.</span><span class="n">traj</span><span class="p">,</span> <span class="n">ind_test</span><span class="p">)</span> <span class="k">if</span> <span class="n">y_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
        
        <span class="n">A_test_out</span> <span class="o">=</span> <span class="n">create_TL_A_fn</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz_test_eff</span><span class="p">,</span> <span class="n">use_vec</span><span class="p">),</span> <span class="n">ind_test</span><span class="p">,</span> <span class="n">terms</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">return_B</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">Bt_in</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz_test_eff</span><span class="p">,</span><span class="n">use_mag</span><span class="p">)[</span><span class="n">ind_test</span><span class="p">]</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">xyz_test_eff</span><span class="p">,</span><span class="n">use_mag</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">A_test_out</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">A_test_out</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">A_test_np</span><span class="p">,</span> <span class="n">Bt_test_np</span><span class="p">,</span> <span class="n">B_dot_test_np</span> <span class="o">=</span> <span class="n">A_test_out</span>
        <span class="k">else</span><span class="p">:</span> <span class="n">A_test_np</span> <span class="o">=</span> <span class="n">A_test_out</span>

        <span class="n">x_test_np</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">l_segs_test_out</span> <span class="o">=</span> <span class="n">get_x_fn</span><span class="p">(</span>
            <span class="n">xyz_test_eff</span><span class="p">,</span> <span class="n">ind_test</span><span class="p">,</span> <span class="n">features_setup</span><span class="p">,</span>
            <span class="n">features_no_norm</span><span class="o">=</span><span class="n">features_no_norm</span><span class="p">,</span> <span class="n">terms</span><span class="o">=</span><span class="n">terms</span><span class="p">,</span>
            <span class="n">sub_diurnal</span><span class="o">=</span><span class="n">sub_diurnal</span><span class="p">,</span> <span class="n">sub_igrf</span><span class="o">=</span><span class="n">sub_igrf</span><span class="p">,</span> <span class="n">bpf_mag</span><span class="o">=</span><span class="n">bpf_mag</span>
        <span class="p">)</span>
        <span class="n">y_test_np</span> <span class="o">=</span> <span class="n">get_y_fn</span><span class="p">(</span>
            <span class="n">xyz_test_eff</span><span class="p">,</span> <span class="n">ind_test</span><span class="p">,</span> <span class="n">map_val_test</span><span class="p">,</span>
            <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span> <span class="n">use_mag</span><span class="o">=</span><span class="n">use_mag</span><span class="p">,</span>
            <span class="n">sub_diurnal</span><span class="o">=</span><span class="n">sub_diurnal</span><span class="p">,</span> <span class="n">sub_igrf</span><span class="o">=</span><span class="n">sub_igrf</span><span class="p">,</span> <span class="n">bpf_mag</span><span class="o">=</span><span class="n">bpf_mag</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">fs</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># Ensure empty arrays if no test data</span>
        <span class="n">A_test_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">A_matrix_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">A_matrix_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">A_matrix_np</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">A_matrix_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">Bt_test_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">Bt_np</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">Bt_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">B_dot_test_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">B_dot_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">B_dot_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">B_dot_np</span><span class="o">.</span><span class="n">ndim</span><span class="o">==</span><span class="mi">2</span> <span class="k">else</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">B_dot_np</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">B_dot_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">x_test_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">x_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">x_np</span><span class="o">.</span><span class="n">ndim</span><span class="o">==</span><span class="mi">2</span> <span class="k">else</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x_np</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">y_test_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">y_np</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">l_segs_test_out</span> <span class="o">=</span> <span class="p">[]</span>


    <span class="n">y_hat_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_np</span><span class="p">)</span>
    <span class="n">err_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span> <span class="c1"># Initialize with NaN or large value</span>

    <span class="c1"># Drop Feature Importance (FI) logic</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">)</span> <span class="ow">and</span> <span class="n">drop_fi</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INFO: Starting Drop Feature Importance training...&quot;</span><span class="p">)</span>
        <span class="c1"># This loop retrains the model for each feature dropped.</span>
        <span class="c1"># The best model (or params from it) based on error is not explicitly stored back to comp_params in Julia loop.</span>
        <span class="c1"># It seems to save each dropped-feature model. The final returned comp_params is from the last iteration.</span>
        <span class="c1"># This might need clarification if the goal is to return the *best* overall model.</span>
        <span class="c1"># For now, will replicate the behavior of returning the params from the last FI iteration.</span>
        
        <span class="c1"># Ensure drop_fi_bson and drop_fi_csv are set if drop_fi is True</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi_bson</span><span class="p">:</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi_bson</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;comp_params_</span><span class="si">{</span><span class="n">comp_params</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2">_dropfi.bson&quot;</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: drop_fi_bson not set, defaulting to </span><span class="si">{</span><span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi_bson</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi_csv</span><span class="p">:</span> <span class="c1"># Not used in this Python version directly for saving errors</span>
            <span class="k">pass</span>

        <span class="n">best_err_std_fi</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i_fi</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span> <span class="c1"># Iterate through features to drop</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Training with feature </span><span class="si">{</span><span class="n">features_out</span><span class="p">[</span><span class="n">i_fi</span><span class="p">]</span><span class="si">}</span><span class="s2"> dropped.&quot;</span><span class="p">)</span>
            
            <span class="n">x_fi_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">x_np</span><span class="p">,</span> <span class="n">i_fi</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">no_norm_fi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">no_norm_out</span><span class="p">,</span> <span class="n">i_fi</span><span class="p">)</span> <span class="k">if</span> <span class="n">no_norm_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
            
            <span class="n">x_fi_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">x_test_np</span><span class="p">,</span> <span class="n">i_fi</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">x_test_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x_test_np</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">x_test_np</span>

            <span class="c1"># Temporary comp_params for this FI iteration to hold intermediate model/data_norms</span>
            <span class="n">temp_comp_params_fi</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">comp_params</span><span class="p">)</span>
            <span class="n">temp_comp_params_fi</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># Reset data_norms for retraining</span>
            <span class="n">temp_comp_params_fi</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>      <span class="c1"># Reset model for retraining</span>

            <span class="n">y_hat_fi_iter</span><span class="p">,</span> <span class="n">err_fi_iter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span> <span class="c1"># Init</span>

            <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;m1&quot;</span><span class="p">:</span>
                <span class="n">model_fi</span><span class="p">,</span> <span class="n">data_norms_fi</span><span class="p">,</span> <span class="n">y_hat_fi_iter</span><span class="p">,</span> <span class="n">err_fi_iter</span> <span class="o">=</span> <span class="n">nn_comp_1_train</span><span class="p">(</span>
                    <span class="n">x_fi_train</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm_fi</span><span class="p">,</span> <span class="n">norm_type_x</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="p">,</span> <span class="n">eta_adam</span><span class="p">,</span> <span class="n">epoch_adam</span><span class="p">,</span> <span class="n">epoch_lbfgs</span><span class="p">,</span>
                    <span class="n">hidden</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">,</span> <span class="n">frac_train</span><span class="p">,</span> <span class="n">alpha_sgl</span><span class="p">,</span> <span class="n">lambda_sgl</span><span class="p">,</span> <span class="n">k_pca</span><span class="p">,</span>
                    <span class="n">data_norms_in</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_in</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># Retrain from scratch</span>
                    <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">x_test_in</span><span class="o">=</span><span class="n">x_fi_test</span><span class="p">,</span> <span class="n">y_test_in</span><span class="o">=</span><span class="n">y_test_np</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="o">=</span><span class="n">l_segs_test_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
                <span class="p">)</span>
                <span class="n">temp_comp_params_fi</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_fi</span>
                <span class="n">temp_comp_params_fi</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">data_norms_fi</span>
            <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m2&quot;</span><span class="p">):</span>
                <span class="n">model_fi</span><span class="p">,</span> <span class="n">TL_coef_fi</span><span class="p">,</span> <span class="n">data_norms_fi</span><span class="p">,</span> <span class="n">y_hat_fi_iter</span><span class="p">,</span> <span class="n">err_fi_iter</span> <span class="o">=</span> <span class="n">nn_comp_2_train</span><span class="p">(</span>
                    <span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">x_fi_train</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm_fi</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">norm_type_A</span><span class="p">,</span> <span class="n">norm_type_x</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="p">,</span>
                    <span class="n">TL_coef_nn</span><span class="p">,</span> <span class="n">eta_adam</span><span class="p">,</span> <span class="n">epoch_adam</span><span class="p">,</span> <span class="n">epoch_lbfgs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">,</span>
                    <span class="n">frac_train</span><span class="p">,</span> <span class="n">alpha_sgl</span><span class="p">,</span> <span class="n">lambda_sgl</span><span class="p">,</span> <span class="n">k_pca</span><span class="p">,</span>
                    <span class="n">data_norms_in</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_in</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span>
                    <span class="n">A_test_raw</span><span class="o">=</span><span class="n">A_test_np</span><span class="p">,</span> <span class="n">x_test_raw</span><span class="o">=</span><span class="n">x_fi_test</span><span class="p">,</span> <span class="n">y_test_raw</span><span class="o">=</span><span class="n">y_test_np</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="o">=</span><span class="n">l_segs_test_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
                <span class="p">)</span>
                <span class="n">temp_comp_params_fi</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_fi</span>
                <span class="n">temp_comp_params_fi</span><span class="o">.</span><span class="n">TL_coef</span> <span class="o">=</span> <span class="n">TL_coef_fi</span>
                <span class="n">temp_comp_params_fi</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">data_norms_fi</span>
            <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
                <span class="n">model_fi</span><span class="p">,</span> <span class="n">TL_coef_fi</span><span class="p">,</span> <span class="n">data_norms_fi</span><span class="p">,</span> <span class="n">y_hat_fi_iter</span><span class="p">,</span> <span class="n">err_fi_iter</span> <span class="o">=</span> <span class="n">nn_comp_3_train</span><span class="p">(</span>
                    <span class="n">A_raw</span><span class="o">=</span><span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">Bt_raw</span><span class="o">=</span><span class="n">Bt_np</span><span class="p">,</span> <span class="n">B_dot_raw</span><span class="o">=</span><span class="n">B_dot_np</span><span class="p">,</span> <span class="c1"># These are from training data</span>
                    <span class="n">x_raw</span><span class="o">=</span><span class="n">x_fi_train</span><span class="p">,</span> <span class="n">y_raw</span><span class="o">=</span><span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm_fi</span><span class="p">,</span> <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span>
                    <span class="n">norm_type_x</span><span class="o">=</span><span class="n">norm_type_x</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="o">=</span><span class="n">norm_type_y</span><span class="p">,</span> <span class="n">TL_coef_in</span><span class="o">=</span><span class="n">TL_coef_nn</span><span class="p">,</span> <span class="n">terms_A</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span>
                    <span class="n">eta_adam</span><span class="o">=</span><span class="n">eta_adam</span><span class="p">,</span> <span class="n">epoch_adam</span><span class="o">=</span><span class="n">epoch_adam</span><span class="p">,</span> <span class="n">epoch_lbfgs</span><span class="o">=</span><span class="n">epoch_lbfgs</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="n">hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
                    <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">batchsize</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">frac_train</span><span class="o">=</span><span class="n">frac_train</span><span class="p">,</span> <span class="n">alpha_sgl</span><span class="o">=</span><span class="n">alpha_sgl</span><span class="p">,</span> <span class="n">lambda_sgl</span><span class="o">=</span><span class="n">lambda_sgl</span><span class="p">,</span>
                    <span class="n">k_pca</span><span class="o">=</span><span class="n">k_pca</span><span class="p">,</span> <span class="n">sigma_curriculum</span><span class="o">=</span><span class="n">sigma_curriculum</span><span class="p">,</span> <span class="n">l_window</span><span class="o">=</span><span class="n">l_window</span><span class="p">,</span> <span class="n">window_type_temporal</span><span class="o">=</span><span class="n">window_type_temporal</span><span class="p">,</span>
                    <span class="n">tf_layer_type</span><span class="o">=</span><span class="n">tf_layer_type</span><span class="p">,</span> <span class="n">tf_norm_type</span><span class="o">=</span><span class="n">tf_norm_type</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="o">=</span><span class="n">dropout_prob</span><span class="p">,</span> <span class="n">N_tf_head</span><span class="o">=</span><span class="n">N_tf_head</span><span class="p">,</span> <span class="n">tf_gain</span><span class="o">=</span><span class="n">tf_gain</span><span class="p">,</span>
                    <span class="n">data_norms_in</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_in</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span>
                    <span class="n">A_test_raw_in</span><span class="o">=</span><span class="n">A_test_np</span><span class="p">,</span> <span class="n">Bt_test_raw_in</span><span class="o">=</span><span class="n">Bt_test_np</span><span class="p">,</span> <span class="n">B_dot_test_raw_in</span><span class="o">=</span><span class="n">B_dot_test_np</span><span class="p">,</span>
                    <span class="n">x_test_raw_in</span><span class="o">=</span><span class="n">x_fi_test</span><span class="p">,</span> <span class="n">y_test_raw_in</span><span class="o">=</span><span class="n">y_test_np</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="o">=</span><span class="n">l_segs_test_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
                <span class="p">)</span>
                <span class="n">temp_comp_params_fi</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_fi</span>
                <span class="n">temp_comp_params_fi</span><span class="o">.</span><span class="n">TL_coef</span> <span class="o">=</span> <span class="n">TL_coef_fi</span>
                <span class="n">temp_comp_params_fi</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">data_norms_fi</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WARN: Drop FI not implemented for model_type </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">. Skipping FI for this feature.&quot;</span><span class="p">)</span>
                <span class="k">continue</span>
            
            <span class="n">current_err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_fi_iter</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_fi_iter</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Dropped &#39;</span><span class="si">{</span><span class="n">features_out</span><span class="p">[</span><span class="n">i_fi</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;, train error std: </span><span class="si">{</span><span class="n">current_err_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT&quot;</span><span class="p">)</span>

            <span class="c1"># Save this FI model&#39;s params</span>
            <span class="k">if</span> <span class="n">drop_fi_bson</span><span class="p">:</span>
                <span class="n">save_comp_params</span><span class="p">(</span><span class="n">temp_comp_params_fi</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">remove_extension</span><span class="p">(</span><span class="n">drop_fi_bson</span><span class="p">)</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">i_fi</span><span class="si">}</span><span class="s2">.bson&quot;</span><span class="p">)</span>
            
            <span class="c1"># Update overall best error and potentially the main comp_params if this is better</span>
            <span class="c1"># The Julia code seems to just save each and the last one&#39;s results are implicitly returned.</span>
            <span class="c1"># To match, we update comp_params with the last iteration&#39;s results.</span>
            <span class="k">if</span> <span class="n">i_fi</span> <span class="o">==</span> <span class="n">x_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span> <span class="c1"># Last iteration</span>
                <span class="n">comp_params</span> <span class="o">=</span> <span class="n">temp_comp_params_fi</span>
                <span class="n">y_hat_np</span> <span class="o">=</span> <span class="n">y_hat_fi_iter</span>
                <span class="n">err_np</span> <span class="o">=</span> <span class="n">err_fi_iter</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INFO: Drop Feature Importance training finished.&quot;</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span> <span class="c1"># Standard training (no drop_fi)</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;m1&quot;</span><span class="p">:</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_1_train</span><span class="p">(</span>
                <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm_out</span><span class="p">,</span> <span class="n">norm_type_x</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="p">,</span> <span class="n">eta_adam</span><span class="p">,</span> <span class="n">epoch_adam</span><span class="p">,</span> <span class="n">epoch_lbfgs</span><span class="p">,</span>
                <span class="n">hidden</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">,</span> <span class="n">frac_train</span><span class="p">,</span> <span class="n">alpha_sgl</span><span class="p">,</span> <span class="n">lambda_sgl</span><span class="p">,</span> <span class="n">k_pca</span><span class="p">,</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">model_in</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span>
                <span class="n">x_test_in</span><span class="o">=</span><span class="n">x_test_np</span><span class="p">,</span> <span class="n">y_test_in</span><span class="o">=</span><span class="n">y_test_np</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="o">=</span><span class="n">l_segs_test_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">data_norms</span>
        <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m2&quot;</span><span class="p">):</span> <span class="c1"># m2a, m2b, m2c, m2d</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">TL_coef_out</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_2_train</span><span class="p">(</span>
                <span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm_out</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">norm_type_A</span><span class="p">,</span> <span class="n">norm_type_x</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="p">,</span>
                <span class="n">TL_coef_nn</span><span class="p">,</span> <span class="n">eta_adam</span><span class="p">,</span> <span class="n">epoch_adam</span><span class="p">,</span> <span class="n">epoch_lbfgs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">,</span>
                <span class="n">frac_train</span><span class="p">,</span> <span class="n">alpha_sgl</span><span class="p">,</span> <span class="n">lambda_sgl</span><span class="p">,</span> <span class="n">k_pca</span><span class="p">,</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">model_in</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span>
                <span class="n">A_test_raw</span><span class="o">=</span><span class="n">A_test_np</span><span class="p">,</span> <span class="n">x_test_raw</span><span class="o">=</span><span class="n">x_test_np</span><span class="p">,</span> <span class="n">y_test_raw</span><span class="o">=</span><span class="n">y_test_np</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="o">=</span><span class="n">l_segs_test_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">):</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span> <span class="o">=</span> <span class="n">TL_coef_out</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">data_norms</span>
        <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
             <span class="n">model</span><span class="p">,</span> <span class="n">TL_coef_out</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_3_train</span><span class="p">(</span>
                <span class="n">A_raw</span><span class="o">=</span><span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">Bt_raw</span><span class="o">=</span><span class="n">Bt_np</span><span class="p">,</span> <span class="n">B_dot_raw</span><span class="o">=</span><span class="n">B_dot_np</span><span class="p">,</span> <span class="c1"># Pass the versions derived from training xyz</span>
                <span class="n">x_raw</span><span class="o">=</span><span class="n">x_np</span><span class="p">,</span> <span class="n">y_raw</span><span class="o">=</span><span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm_out</span><span class="p">,</span> <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span>
                <span class="n">norm_type_x</span><span class="o">=</span><span class="n">norm_type_x</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="o">=</span><span class="n">norm_type_y</span><span class="p">,</span> <span class="n">TL_coef_in</span><span class="o">=</span><span class="n">TL_coef_nn</span><span class="p">,</span> <span class="n">terms_A</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span>
                <span class="n">eta_adam</span><span class="o">=</span><span class="n">eta_adam</span><span class="p">,</span> <span class="n">epoch_adam</span><span class="o">=</span><span class="n">epoch_adam</span><span class="p">,</span> <span class="n">epoch_lbfgs</span><span class="o">=</span><span class="n">epoch_lbfgs</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="n">hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
                <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">batchsize</span><span class="o">=</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">frac_train</span><span class="o">=</span><span class="n">frac_train</span><span class="p">,</span> <span class="n">alpha_sgl</span><span class="o">=</span><span class="n">alpha_sgl</span><span class="p">,</span> <span class="n">lambda_sgl</span><span class="o">=</span><span class="n">lambda_sgl</span><span class="p">,</span>
                <span class="n">k_pca</span><span class="o">=</span><span class="n">k_pca</span><span class="p">,</span> <span class="n">sigma_curriculum</span><span class="o">=</span><span class="n">sigma_curriculum</span><span class="p">,</span> <span class="n">l_window</span><span class="o">=</span><span class="n">l_window</span><span class="p">,</span> <span class="n">window_type_temporal</span><span class="o">=</span><span class="n">window_type_temporal</span><span class="p">,</span>
                <span class="n">tf_layer_type</span><span class="o">=</span><span class="n">tf_layer_type</span><span class="p">,</span> <span class="n">tf_norm_type</span><span class="o">=</span><span class="n">tf_norm_type</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="o">=</span><span class="n">dropout_prob</span><span class="p">,</span> <span class="n">N_tf_head</span><span class="o">=</span><span class="n">N_tf_head</span><span class="p">,</span> <span class="n">tf_gain</span><span class="o">=</span><span class="n">tf_gain</span><span class="p">,</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">model_in</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span>
                <span class="n">A_test_raw_in</span><span class="o">=</span><span class="n">A_test_np</span><span class="p">,</span> <span class="n">Bt_test_raw_in</span><span class="o">=</span><span class="n">Bt_test_np</span><span class="p">,</span> <span class="n">B_dot_test_raw_in</span><span class="o">=</span><span class="n">B_dot_test_np</span><span class="p">,</span>
                <span class="n">x_test_raw_in</span><span class="o">=</span><span class="n">x_test_np</span><span class="p">,</span> <span class="n">y_test_raw_in</span><span class="o">=</span><span class="n">y_test_np</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="o">=</span><span class="n">l_segs_test_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
             <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
             <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">):</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span> <span class="o">=</span> <span class="n">TL_coef_out</span>
             <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">data_norms</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">,</span> <span class="s2">&quot;map_TL&quot;</span><span class="p">]:</span>
            <span class="n">trim_val</span> <span class="o">=</span> <span class="mi">20</span> <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="n">model_tuple</span><span class="p">,</span> <span class="n">data_norms_out_lin</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">linear_fit</span><span class="p">(</span>
                <span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">trim</span><span class="o">=</span><span class="n">trim_val</span><span class="p">,</span> <span class="n">lambda_ridge</span><span class="o">=</span><span class="n">lambda_TL</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">LinCompParams</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">,</span>
                <span class="n">norm_type_x</span><span class="o">=</span><span class="n">norm_type_A</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="o">=</span><span class="n">norm_type_y</span><span class="p">,</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">A_no_bpf_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_no_bpf_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Recalculate error on non-BPF&#39;d data for these specific models</span>
                <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">linear_test</span><span class="p">(</span><span class="n">A_no_bpf_np</span><span class="p">,</span> <span class="n">y_no_bpf_np</span><span class="p">,</span> <span class="n">data_norms_out_lin</span><span class="p">,</span> <span class="n">model_tuple</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span>

            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_tuple</span> <span class="c1"># Store (coeffs, bias)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">data_norms_out_lin</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;elasticnet&quot;</span><span class="p">:</span>
            <span class="n">model_tuple</span><span class="p">,</span> <span class="n">data_norms_out_lin</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">elasticnet_fit</span><span class="p">(</span>
                <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm_out</span><span class="p">,</span> <span class="c1"># Default alpha from Julia</span>
                <span class="n">lambda_val</span><span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="c1"># Default to CV</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_tuple</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">data_norms_out_lin</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;plsr&quot;</span><span class="p">:</span>
            <span class="n">model_tuple</span><span class="p">,</span> <span class="n">data_norms_out_lin</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">plsr_fit</span><span class="p">(</span>
                <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k_plsr</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">LinCompParams</span><span class="p">)</span> <span class="k">else</span> <span class="n">x_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
                <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm_out</span><span class="p">,</span> <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_tuple</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">data_norms_out_lin</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown model_type: </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2"> in comp_train&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
        <span class="n">time_unit</span> <span class="o">=</span> <span class="s2">&quot;sec&quot;</span>
        <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">60</span><span class="p">:</span>
            <span class="n">elapsed_time</span> <span class="o">/=</span> <span class="mi">60</span>
            <span class="n">time_unit</span> <span class="o">=</span> <span class="s2">&quot;min&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: comp_train completed in </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">time_unit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">comp_params</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span><span class="p">,</span> <span class="n">features_out</span>
<div class="viewcode-block" id="comp_train">
<a class="viewcode-back" href="../../comp.html#magnavpy.compensation.comp_train">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">comp_train</span><span class="p">(</span> <span class="c1"># Overload for DataFrames</span>
    <span class="n">comp_params</span><span class="p">:</span> <span class="n">CompParams</span><span class="p">,</span>
    <span class="n">lines</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="c1"># Can be single line or list/array of lines</span>
    <span class="n">df_line</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="c1"># pandas.DataFrame</span>
    <span class="n">df_flight</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="c1"># pandas.DataFrame</span>
    <span class="n">df_map</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="c1"># pandas.DataFrame</span>
    <span class="n">temp_params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TempParams</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">CompParams</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train an aeromagnetic compensation model using DataFrame inputs.</span>
<span class="sd">    This version loads XYZ data based on lines and DataFrames.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">t0_df</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">temp_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">temp_params</span> <span class="o">=</span> <span class="n">TempParams</span><span class="p">()</span>

    <span class="c1"># The core logic of this overload in Julia is to:</span>
    <span class="c1"># 1. Determine if `lines` refers to training lines or test lines based on `comp_params.frac_train`.</span>
    <span class="c1">#    (This seems to be for a specific workflow where `lines` could be all available lines,</span>
    <span class="c1">#     and `frac_train` dictates splitting them into actual train/test sets for this call).</span>
    <span class="c1">#    However, the Python `nn_comp_X_train` functions already handle frac_train internally.</span>
    <span class="c1">#    The `comp_train(XYZ, ind)` version also takes explicit `xyz_test, ind_test`.</span>
    <span class="c1">#    For simplicity and consistency, this Python wrapper will assume `lines` are for training,</span>
    <span class="c1">#    and if a test set is desired from the same `lines` based on `frac_train`,</span>
    <span class="c1">#    that splitting logic should be handled before calling this, or by passing</span>
    <span class="c1">#    explicit `xyz_test, ind_test` to the primary `comp_train`.</span>
    <span class="c1">#    Alternatively, we can implement a split here if that&#39;s the intended behavior.</span>
    <span class="c1">#</span>
    <span class="c1">#    Looking at the Julia `comp_train` (df version), it does:</span>
    <span class="c1">#    - `get_Axy` which itself calls `get_XYZ` and `get_ind` for the provided `lines`.</span>
    <span class="c1">#    - It does *not* seem to split `lines` into train/test at this top `comp_train` (df) level.</span>
    <span class="c1">#    - The `frac_train` is passed down to `nn_comp_X_train` which does the split on the data `x,y`.</span>
    <span class="c1">#    - The `drop_fi` logic inside the primary `comp_train(XYZ, ind)` *does* use `xyz_test, ind_test`</span>
    <span class="c1">#      which are passed as optional arguments. If they are not provided, they default to empty.</span>
    <span class="c1">#</span>
    <span class="c1">#    Therefore, this wrapper will focus on loading the primary XYZ data for `lines`.</span>
    <span class="c1">#    If a separate test set from different lines is needed, the `comp_train_test` function</span>
    <span class="c1">#    or manual preparation of `xyz_test, ind_test` for the primary `comp_train` is more appropriate.</span>

    <span class="c1"># For now, assume `lines` are all for training, and `frac_train` within `comp_params`</span>
    <span class="c1"># will be used by the `nn_comp_X_train` functions to split the *data* (not the lines themselves here).</span>

    <span class="c1"># `get_Axy` is a complex function that loads data. We need its Python equivalent.</span>
    <span class="c1"># For now, we&#39;ll assume `get_Axy` is available from `analysis_util.py`</span>
    <span class="c1"># and it correctly processes DataFrames to produce A, x, y, etc.</span>
    <span class="c1"># The call signature in Julia is:</span>
    <span class="c1"># get_Axy(lines, df_line, df_flight, df_map, features_setup; kwargs...)</span>
    
    <span class="c1"># Unpack relevant comp_params for get_Axy and subsequent calls</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">model_type</span>
    <span class="n">y_type</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">y_type</span>
    <span class="n">use_mag</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">use_mag</span>
    <span class="n">use_vec</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">use_vec</span>
    <span class="n">terms</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">terms</span>
    <span class="n">terms_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">terms_A</span><span class="p">)</span> <span class="c1"># mutable copy</span>
    <span class="n">sub_diurnal</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">sub_diurnal</span>
    <span class="n">sub_igrf</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">sub_igrf</span>
    <span class="n">bpf_mag</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">bpf_mag</span>
    <span class="n">reorient_vec</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">reorient_vec</span>
    <span class="n">features_setup</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">features_setup</span><span class="p">)</span>
    <span class="n">features_no_norm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">features_no_norm</span><span class="p">)</span>
    
    <span class="c1"># Adjust y_type and terms_A based on model_type, similar to the other comp_train</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">y_type</span> <span class="o">!=</span> <span class="s2">&quot;e&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Forcing y_type </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2"> -&gt; &#39;e&#39; for model_type </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">y_type</span> <span class="o">=</span> <span class="s2">&quot;e&quot;</span> <span class="c1"># Update local y_type for get_Axy</span>
        <span class="n">comp_params</span><span class="o">.</span><span class="n">y_type</span> <span class="o">=</span> <span class="s2">&quot;e&quot;</span> <span class="c1"># Also update in comp_params if it&#39;s to be persisted</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;map_TL&quot;</span> <span class="ow">and</span> <span class="n">y_type</span> <span class="o">!=</span> <span class="s2">&quot;c&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Forcing y_type </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2"> -&gt; &#39;c&#39; for model_type </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">y_type</span> <span class="o">=</span> <span class="s2">&quot;c&quot;</span>
        <span class="n">comp_params</span><span class="o">.</span><span class="n">y_type</span> <span class="o">=</span> <span class="s2">&quot;c&quot;</span>
    <span class="k">if</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
        <span class="n">terms_A_original</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">terms_A</span><span class="p">)</span>
        <span class="n">terms_A</span> <span class="o">=</span> <span class="p">[</span><span class="n">term</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">terms_A</span> <span class="k">if</span> <span class="n">term</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;fdm&quot;</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">,</span> <span class="s2">&quot;fdm3&quot;</span><span class="p">,</span> <span class="s2">&quot;f3&quot;</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">]]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">terms_A</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">terms_A_original</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Removing derivative/bias terms from terms_A for M3 model. Original: </span><span class="si">{</span><span class="n">terms_A_original</span><span class="si">}</span><span class="s2">, New: </span><span class="si">{</span><span class="n">terms_A</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">comp_params</span><span class="o">.</span><span class="n">terms_A</span> <span class="o">=</span> <span class="n">terms_A</span> <span class="c1"># Persist change</span>

    <span class="c1"># Call get_Axy (assuming it&#39;s imported or defined)</span>
    <span class="c1"># This function needs to be robustly implemented from analysis_util.py</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.analysis_util</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_Axy</span> <span class="k">as</span> <span class="n">get_Axy_actual</span>
        <span class="k">if</span> <span class="s1">&#39;compensation&#39;</span> <span class="ow">in</span> <span class="n">get_Axy_actual</span><span class="o">.</span><span class="vm">__module__</span><span class="p">:</span> <span class="n">get_Axy_fn</span> <span class="o">=</span> <span class="n">get_Axy</span> <span class="c1"># placeholder</span>
        <span class="k">else</span><span class="p">:</span> <span class="n">get_Axy_fn</span> <span class="o">=</span> <span class="n">get_Axy_actual</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">get_Axy_fn</span> <span class="o">=</span> <span class="n">get_Axy</span> <span class="c1"># Use placeholder</span>

    <span class="n">Axy_outputs</span> <span class="o">=</span> <span class="n">get_Axy_fn</span><span class="p">(</span>
        <span class="n">lines</span><span class="p">,</span> <span class="n">df_line</span><span class="p">,</span> <span class="n">df_flight</span><span class="p">,</span> <span class="n">df_map</span><span class="p">,</span>
        <span class="n">features_setup</span><span class="p">,</span>
        <span class="n">features_no_norm</span><span class="o">=</span><span class="n">features_no_norm</span><span class="p">,</span>
        <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span>
        <span class="n">use_mag</span><span class="o">=</span><span class="n">use_mag</span><span class="p">,</span>
        <span class="n">use_vec</span><span class="o">=</span><span class="n">use_vec</span><span class="p">,</span>
        <span class="n">terms</span><span class="o">=</span><span class="n">terms</span><span class="p">,</span> <span class="c1"># comp_params.terms</span>
        <span class="n">terms_A</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="c1"># comp_params.terms_A (potentially modified for M3)</span>
        <span class="n">sub_diurnal</span><span class="o">=</span><span class="n">sub_diurnal</span><span class="p">,</span>
        <span class="n">sub_igrf</span><span class="o">=</span><span class="n">sub_igrf</span><span class="p">,</span>
        <span class="n">bpf_mag</span><span class="o">=</span><span class="n">bpf_mag</span><span class="p">,</span>
        <span class="n">reorient_vec</span><span class="o">=</span><span class="n">reorient_vec</span><span class="p">,</span>
        <span class="n">mod_TL</span><span class="o">=</span><span class="p">(</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">),</span>
        <span class="n">map_TL</span><span class="o">=</span><span class="p">(</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;map_TL&quot;</span><span class="p">),</span>
        <span class="n">return_B</span><span class="o">=</span><span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">),</span> <span class="c1"># Only M3 explicitly needs Bt, B_dot from get_Axy</span>
        <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span> <span class="c1"># Use global for internal prints of get_Axy</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
        <span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">Bt_np</span><span class="p">,</span> <span class="n">B_dot_np</span><span class="p">,</span> <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm_out</span><span class="p">,</span> <span class="n">features_out</span><span class="p">,</span> <span class="n">l_segs_out</span> <span class="o">=</span> <span class="n">Axy_outputs</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm_out</span><span class="p">,</span> <span class="n">features_out</span><span class="p">,</span> <span class="n">l_segs_out</span> <span class="o">=</span> <span class="n">Axy_outputs</span>
        <span class="n">Bt_np</span><span class="p">,</span> <span class="n">B_dot_np</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span> <span class="c1"># Not returned by get_Axy for non-M3, or not used directly by train functions</span>

    <span class="c1"># --- The rest of the logic mirrors the primary comp_train after data loading ---</span>
    <span class="c1"># This includes handling drop_fi and calling the specific nn_comp_X_train or linear_fit.</span>
    <span class="c1"># For brevity and to avoid large duplication, we can call the primary comp_train here,</span>
    <span class="c1"># but that would require constructing an XYZ object first.</span>
    <span class="c1"># The Julia version directly passes A, x, y to nn_comp_X_train.</span>
    <span class="c1"># Let&#39;s follow that pattern.</span>

    <span class="n">y_hat_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_np</span><span class="p">)</span>
    <span class="n">err_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
    
    <span class="c1"># We need to pass all relevant comp_params attributes to the training functions.</span>
    <span class="c1"># Re-fetch them from comp_params as they might have been updated (e.g. y_type, terms_A)</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">model_type</span> <span class="c1"># Use potentially updated one</span>
    <span class="n">y_type</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">y_type</span>         <span class="c1"># Use potentially updated one</span>
    <span class="n">terms_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">terms_A</span><span class="p">)</span> <span class="c1"># Use potentially updated one</span>
    <span class="n">norm_type_A</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">norm_type_A</span>
    <span class="n">norm_type_x</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">norm_type_x</span>
    <span class="n">norm_type_y</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">norm_type_y</span>
    <span class="n">data_norms</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="c1"># Pass current, will be updated by train functions</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span>           <span class="c1"># Pass current, will be updated</span>

    <span class="c1"># Test data handling: get_Axy for DataFrames doesn&#39;t explicitly return a test set.</span>
    <span class="c1"># The nn_comp_X_train functions expect raw test data if provided.</span>
    <span class="c1"># For this wrapper, we&#39;ll assume no separate test set is loaded by get_Axy(df) itself.</span>
    <span class="c1"># If testing is needed, it should be done via comp_test or comp_train_test.</span>
    <span class="c1"># So, pass empty/None for test data to nn_comp_X_train.</span>
    <span class="n">A_test_for_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">A_matrix_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">A_matrix_np</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="k">if</span> <span class="n">A_matrix_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">A_matrix_np</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span><span class="mi">2</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">Bt_test_for_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">Bt_np</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">Bt_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">B_dot_test_for_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">B_dot_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">B_dot_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">B_dot_np</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span><span class="mi">2</span> <span class="k">else</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">B_dot_np</span><span class="o">.</span><span class="n">dtype</span> <span class="k">if</span> <span class="n">B_dot_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">x_test_for_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">x_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">x_np</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="k">else</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x_np</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">y_test_for_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">y_np</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">l_segs_test_for_train</span> <span class="o">=</span> <span class="p">[]</span>


    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">)</span> <span class="ow">and</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INFO: df_comp_train Drop Feature Importance starting...&quot;</span><span class="p">)</span>
        <span class="c1"># Simplified: We&#39;ll just run the main training once without FI for this wrapper.</span>
        <span class="c1"># Full FI loop here would be very extensive. The primary comp_train(XYZ) handles FI.</span>
        <span class="c1"># To enable FI here, one would need to reconstruct the FI loop from the other comp_train.</span>
        <span class="c1"># For now, set drop_fi to False for this specific call path.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARN: Drop FI with DataFrame input is simplified in this version. Training full model.&quot;</span><span class="p">)</span>
        <span class="n">drop_fi_original_setting</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi</span>
        <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># Temporarily disable for this path</span>
        
        <span class="c1"># Call the main training logic (copied/adapted from the other comp_train)</span>
        <span class="c1"># This section will be very similar to the `else` block of the FI logic in the primary comp_train</span>
        <span class="c1"># (Code for standard training path)</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;m1&quot;</span><span class="p">:</span>
            <span class="n">model_res</span><span class="p">,</span> <span class="n">dn_res</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_1_train</span><span class="p">(</span>
                <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm_out</span><span class="p">,</span> <span class="n">norm_type_x</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">η_adam</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_adam</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_lbfgs</span><span class="p">,</span>
                <span class="n">comp_params</span><span class="o">.</span><span class="n">hidden</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">frac_train</span><span class="p">,</span> 
                <span class="n">comp_params</span><span class="o">.</span><span class="n">α_sgl</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">λ_sgl</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">k_pca</span><span class="p">,</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">model_in</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span>
                <span class="n">x_test_in</span><span class="o">=</span><span class="n">x_test_for_train</span><span class="p">,</span> <span class="n">y_test_in</span><span class="o">=</span><span class="n">y_test_for_train</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="o">=</span><span class="n">l_segs_test_for_train</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_res</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">dn_res</span>
        <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m2&quot;</span><span class="p">):</span>
            <span class="n">model_res</span><span class="p">,</span> <span class="n">tl_coef_res</span><span class="p">,</span> <span class="n">dn_res</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_2_train</span><span class="p">(</span>
                <span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm_out</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">norm_type_A</span><span class="p">,</span> <span class="n">norm_type_x</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="p">,</span>
                <span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">η_adam</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_adam</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_lbfgs</span><span class="p">,</span> 
                <span class="n">comp_params</span><span class="o">.</span><span class="n">hidden</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">batchsize</span><span class="p">,</span>
                <span class="n">comp_params</span><span class="o">.</span><span class="n">frac_train</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">α_sgl</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">λ_sgl</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">k_pca</span><span class="p">,</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">model_in</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span>
                <span class="n">A_test_raw</span><span class="o">=</span><span class="n">A_test_for_train</span><span class="p">,</span> <span class="n">x_test_raw</span><span class="o">=</span><span class="n">x_test_for_train</span><span class="p">,</span> <span class="n">y_test_raw</span><span class="o">=</span><span class="n">y_test_for_train</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="o">=</span><span class="n">l_segs_test_for_train</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_res</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span> <span class="o">=</span> <span class="n">tl_coef_res</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">dn_res</span>
        <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
            <span class="n">model_res</span><span class="p">,</span> <span class="n">tl_coef_res</span><span class="p">,</span> <span class="n">dn_res</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_3_train</span><span class="p">(</span>
                <span class="n">A_raw</span><span class="o">=</span><span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">Bt_raw</span><span class="o">=</span><span class="n">Bt_np</span><span class="p">,</span> <span class="n">B_dot_raw</span><span class="o">=</span><span class="n">B_dot_np</span><span class="p">,</span> 
                <span class="n">x_raw</span><span class="o">=</span><span class="n">x_np</span><span class="p">,</span> <span class="n">y_raw</span><span class="o">=</span><span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm_out</span><span class="p">,</span> <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span>
                <span class="n">norm_type_x</span><span class="o">=</span><span class="n">norm_type_x</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="o">=</span><span class="n">norm_type_y</span><span class="p">,</span> <span class="n">TL_coef_in</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span><span class="p">,</span> <span class="n">terms_A</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span>
                <span class="n">eta_adam</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">η_adam</span><span class="p">,</span> <span class="n">epoch_adam</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_adam</span><span class="p">,</span> <span class="n">epoch_lbfgs</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_lbfgs</span><span class="p">,</span> 
                <span class="n">hidden</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> 
                <span class="n">batchsize</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">frac_train</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">frac_train</span><span class="p">,</span> 
                <span class="n">alpha_sgl</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">α_sgl</span><span class="p">,</span> <span class="n">lambda_sgl</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">λ_sgl</span><span class="p">,</span> <span class="n">k_pca</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">k_pca</span><span class="p">,</span> 
                <span class="n">sigma_curriculum</span><span class="o">=</span><span class="n">sigma_curriculum</span><span class="p">,</span> <span class="n">l_window</span><span class="o">=</span><span class="n">l_window</span><span class="p">,</span> <span class="n">window_type_temporal</span><span class="o">=</span><span class="n">window_type_temporal</span><span class="p">,</span>
                <span class="n">tf_layer_type</span><span class="o">=</span><span class="n">tf_layer_type</span><span class="p">,</span> <span class="n">tf_norm_type</span><span class="o">=</span><span class="n">tf_norm_type</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="o">=</span><span class="n">dropout_prob</span><span class="p">,</span> <span class="n">N_tf_head</span><span class="o">=</span><span class="n">N_tf_head</span><span class="p">,</span> <span class="n">tf_gain</span><span class="o">=</span><span class="n">tf_gain</span><span class="p">,</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">model_in</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span>
                <span class="n">A_test_raw_in</span><span class="o">=</span><span class="n">A_test_for_train</span><span class="p">,</span> <span class="n">Bt_test_raw_in</span><span class="o">=</span><span class="n">Bt_test_for_train</span><span class="p">,</span> <span class="n">B_dot_test_raw_in</span><span class="o">=</span><span class="n">B_dot_test_for_train</span><span class="p">,</span>
                <span class="n">x_test_raw_in</span><span class="o">=</span><span class="n">x_test_for_train</span><span class="p">,</span> <span class="n">y_test_raw_in</span><span class="o">=</span><span class="n">y_test_for_train</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="o">=</span><span class="n">l_segs_test_for_train</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_res</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span> <span class="o">=</span> <span class="n">tl_coef_res</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">dn_res</span>
        <span class="c1"># ... (add LinCompParams models if drop_fi was intended for them too)</span>
        <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi</span> <span class="o">=</span> <span class="n">drop_fi_original_setting</span> <span class="c1"># Restore original setting</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># Standard training path (no drop_fi, or drop_fi handled by primary comp_train)</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;m1&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">):</span>
            <span class="n">model_res</span><span class="p">,</span> <span class="n">dn_res</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_1_train</span><span class="p">(</span>
                <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm_out</span><span class="p">,</span> <span class="n">norm_type_x</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">η_adam</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_adam</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_lbfgs</span><span class="p">,</span>
                <span class="n">comp_params</span><span class="o">.</span><span class="n">hidden</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">frac_train</span><span class="p">,</span> 
                <span class="n">comp_params</span><span class="o">.</span><span class="n">α_sgl</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">λ_sgl</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">k_pca</span><span class="p">,</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">model_in</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span>
                <span class="n">x_test_in</span><span class="o">=</span><span class="n">x_test_for_train</span><span class="p">,</span> <span class="n">y_test_in</span><span class="o">=</span><span class="n">y_test_for_train</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="o">=</span><span class="n">l_segs_test_for_train</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_res</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">dn_res</span>
        <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m2&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">):</span>
            <span class="n">model_res</span><span class="p">,</span> <span class="n">tl_coef_res</span><span class="p">,</span> <span class="n">dn_res</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_2_train</span><span class="p">(</span>
                <span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm_out</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">norm_type_A</span><span class="p">,</span> <span class="n">norm_type_x</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="p">,</span>
                <span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">η_adam</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_adam</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_lbfgs</span><span class="p">,</span> 
                <span class="n">comp_params</span><span class="o">.</span><span class="n">hidden</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">batchsize</span><span class="p">,</span>
                <span class="n">comp_params</span><span class="o">.</span><span class="n">frac_train</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">α_sgl</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">λ_sgl</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">k_pca</span><span class="p">,</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">model_in</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span>
                <span class="n">A_test_raw</span><span class="o">=</span><span class="n">A_test_for_train</span><span class="p">,</span> <span class="n">x_test_raw</span><span class="o">=</span><span class="n">x_test_for_train</span><span class="p">,</span> <span class="n">y_test_raw</span><span class="o">=</span><span class="n">y_test_for_train</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="o">=</span><span class="n">l_segs_test_for_train</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_res</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span> <span class="o">=</span> <span class="n">tl_coef_res</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">dn_res</span>
        <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">):</span>
            <span class="n">model_res</span><span class="p">,</span> <span class="n">tl_coef_res</span><span class="p">,</span> <span class="n">dn_res</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_3_train</span><span class="p">(</span>
                <span class="n">A_raw</span><span class="o">=</span><span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">Bt_raw</span><span class="o">=</span><span class="n">Bt_np</span><span class="p">,</span> <span class="n">B_dot_raw</span><span class="o">=</span><span class="n">B_dot_np</span><span class="p">,</span> 
                <span class="n">x_raw</span><span class="o">=</span><span class="n">x_np</span><span class="p">,</span> <span class="n">y_raw</span><span class="o">=</span><span class="n">y_np</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm_out</span><span class="p">,</span> <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span>
                <span class="n">norm_type_x</span><span class="o">=</span><span class="n">norm_type_x</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="o">=</span><span class="n">norm_type_y</span><span class="p">,</span> <span class="n">TL_coef_in</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span><span class="p">,</span> <span class="n">terms_A</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">y_type</span><span class="o">=</span><span class="n">y_type</span><span class="p">,</span>
                <span class="n">eta_adam</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">η_adam</span><span class="p">,</span> <span class="n">epoch_adam</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_adam</span><span class="p">,</span> <span class="n">epoch_lbfgs</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">epoch_lbfgs</span><span class="p">,</span> 
                <span class="n">hidden</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> 
                <span class="n">batchsize</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">frac_train</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">frac_train</span><span class="p">,</span> 
                <span class="n">alpha_sgl</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">α_sgl</span><span class="p">,</span> <span class="n">lambda_sgl</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">λ_sgl</span><span class="p">,</span> <span class="n">k_pca</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">k_pca</span><span class="p">,</span> 
                <span class="n">sigma_curriculum</span><span class="o">=</span><span class="n">sigma_curriculum</span><span class="p">,</span> <span class="n">l_window</span><span class="o">=</span><span class="n">l_window</span><span class="p">,</span> <span class="n">window_type_temporal</span><span class="o">=</span><span class="n">window_type_temporal</span><span class="p">,</span>
                <span class="n">tf_layer_type</span><span class="o">=</span><span class="n">tf_layer_type</span><span class="p">,</span> <span class="n">tf_norm_type</span><span class="o">=</span><span class="n">tf_norm_type</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="o">=</span><span class="n">dropout_prob</span><span class="p">,</span> <span class="n">N_tf_head</span><span class="o">=</span><span class="n">N_tf_head</span><span class="p">,</span> <span class="n">tf_gain</span><span class="o">=</span><span class="n">tf_gain</span><span class="p">,</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">model_in</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span>
                <span class="n">A_test_raw_in</span><span class="o">=</span><span class="n">A_test_for_train</span><span class="p">,</span> <span class="n">Bt_test_raw_in</span><span class="o">=</span><span class="n">Bt_test_for_train</span><span class="p">,</span> <span class="n">B_dot_test_raw_in</span><span class="o">=</span><span class="n">B_dot_test_for_train</span><span class="p">,</span>
                <span class="n">x_test_raw_in</span><span class="o">=</span><span class="n">x_test_for_train</span><span class="p">,</span> <span class="n">y_test_raw_in</span><span class="o">=</span><span class="n">y_test_for_train</span><span class="p">,</span> <span class="n">l_segs_test</span><span class="o">=</span><span class="n">l_segs_test_for_train</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_res</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span> <span class="o">=</span> <span class="n">tl_coef_res</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">dn_res</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">,</span> <span class="s2">&quot;map_TL&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">LinCompParams</span><span class="p">):</span>
            <span class="n">trim_val</span> <span class="o">=</span> <span class="mi">20</span> <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="n">model_tuple</span><span class="p">,</span> <span class="n">dn_res</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">linear_fit</span><span class="p">(</span>
                <span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">trim</span><span class="o">=</span><span class="n">trim_val</span><span class="p">,</span> <span class="n">lambda_ridge</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">λ_TL</span><span class="p">,</span>
                <span class="n">norm_type_x</span><span class="o">=</span><span class="n">norm_type_A</span><span class="p">,</span> <span class="n">norm_type_y</span><span class="o">=</span><span class="n">norm_type_y</span><span class="p">,</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">A_no_bpf_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_no_bpf_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                 <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">linear_test</span><span class="p">(</span><span class="n">A_no_bpf_np</span><span class="p">,</span> <span class="n">y_no_bpf_np</span><span class="p">,</span> <span class="n">dn_res</span><span class="p">,</span> <span class="n">model_tuple</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_tuple</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">dn_res</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;elasticnet&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">LinCompParams</span><span class="p">):</span>
            <span class="n">model_tuple</span><span class="p">,</span> <span class="n">dn_res</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">elasticnet_fit</span><span class="p">(</span>
                <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm_out</span><span class="p">,</span> <span class="c1"># Default alpha from Julia</span>
                <span class="n">lambda_val</span><span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="c1"># Default to CV, or use a param from LinCompParams if defined</span>
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_tuple</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">dn_res</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;plsr&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">LinCompParams</span><span class="p">):</span>
            <span class="n">model_tuple</span><span class="p">,</span> <span class="n">dn_res</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">plsr_fit</span><span class="p">(</span>
                <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">comp_params</span><span class="o">.</span><span class="n">k_plsr</span><span class="p">,</span> <span class="n">no_norm</span><span class="o">=</span><span class="n">no_norm_out</span><span class="p">,</span> 
                <span class="n">data_norms_in</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model_tuple</span>
            <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span> <span class="o">=</span> <span class="n">dn_res</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported model_type &#39;</span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&#39; or mismatched CompParams type for comp_train(df).&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0_df</span>
        <span class="n">time_unit</span> <span class="o">=</span> <span class="s2">&quot;sec&quot;</span>
        <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">60</span><span class="p">:</span>
            <span class="n">elapsed_time</span> <span class="o">/=</span> <span class="mi">60</span>
            <span class="n">time_unit</span> <span class="o">=</span> <span class="s2">&quot;min&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: comp_train (DataFrame version) completed in </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">time_unit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">comp_params</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span><span class="p">,</span> <span class="n">features_out</span></div>

<span class="k">def</span><span class="w"> </span><span class="nf">comp_test</span><span class="p">(</span>
    <span class="n">comp_params</span><span class="p">:</span> <span class="n">CompParams</span><span class="p">,</span> 
    <span class="n">xyz</span><span class="p">:</span> <span class="n">XYZ</span><span class="p">,</span> 
    <span class="n">ind</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">mapS</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">mapS_null</span><span class="p">,</span> <span class="c1"># Union[MapS, MapSd, MapS3D]</span>
    <span class="n">temp_params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TempParams</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate performance of an aeromagnetic compensation model.</span>
<span class="sd">    Base version taking XYZ and ind.</span>

<span class="sd">    Args:</span>
<span class="sd">        comp_params: CompParams object (NNCompParams or LinCompParams).</span>
<span class="sd">        xyz: XYZ flight data struct.</span>
<span class="sd">        ind: Selected data indices for testing.</span>
<span class="sd">        mapS: (optional) MapS struct, only used for y_type = &#39;b&#39;, &#39;c&#39;.</span>
<span class="sd">        temp_params: (optional) TempParams struct.</span>
<span class="sd">        silent: (optional) If true, no print outs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        y: Target vector.</span>
<span class="sd">        y_hat: Prediction vector.</span>
<span class="sd">        err: Compensation error.</span>
<span class="sd">        features: List of feature names used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># for reproducibility</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">temp_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">temp_params</span> <span class="o">=</span> <span class="n">TempParams</span><span class="p">()</span>

    <span class="c1"># Unpack parameters</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">model_type</span>
    <span class="n">y_type</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">y_type</span>
    <span class="n">use_mag</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">use_mag</span>
    <span class="n">use_vec</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">use_vec</span>
    <span class="n">data_norms</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">data_norms</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">model</span> <span class="c1"># This is the trained model</span>
    <span class="n">terms</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">terms</span>
    <span class="n">terms_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">terms_A</span><span class="p">)</span>
    <span class="n">sub_diurnal</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">sub_diurnal</span>
    <span class="n">sub_igrf</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">sub_igrf</span>
    <span class="n">bpf_mag</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">bpf_mag</span>
    <span class="c1"># reorient_vec = comp_params.reorient_vec # Not directly used in test dispatch</span>
    <span class="n">features_setup</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">features_setup</span><span class="p">)</span>
    <span class="n">features_no_norm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">features_no_norm</span><span class="p">)</span>

    <span class="n">TL_coef_val</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">):</span>
        <span class="n">TL_coef_val</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span>
        <span class="c1"># drop_fi / perm_fi logic is specific to comp_test in Julia, handle below</span>
        <span class="n">drop_fi</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi</span>
        <span class="n">perm_fi</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">perm_fi</span>
        <span class="n">drop_fi_bson_base</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi_bson</span>
        <span class="n">drop_fi_csv_path</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">drop_fi_csv</span>
        <span class="n">perm_fi_csv_path</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">perm_fi_csv</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">LinCompParams</span><span class="p">):</span>
        <span class="n">drop_fi</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># Not applicable to LinCompParams in the same way</span>
        <span class="n">perm_fi</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;comp_params must be an instance of NNCompParams or LinCompParams&quot;</span><span class="p">)</span>

    <span class="c1"># TempParams unpack (only l_window needed for _from_raw calls if temporal)</span>
    <span class="n">l_window</span> <span class="o">=</span> <span class="n">temp_params</span><span class="o">.</span><span class="n">l_window</span>


    <span class="c1"># Adjust y_type based on model_type for testing (mirroring Julia&#39;s comp_test)</span>
    <span class="c1"># In Julia&#39;s comp_test, for TL, mod_TL, it forces y_type to &#39;d&#39; if it was &#39;e&#39; during training.</span>
    <span class="c1"># This is because the error is typically evaluated on the un-filtered delta mag.</span>
    <span class="n">original_y_type_for_get_y</span> <span class="o">=</span> <span class="n">y_type</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;e&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Forcing y_type </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2"> -&gt; &#39;d&#39; (Δmag) for error calculation in model_type </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">original_y_type_for_get_y</span> <span class="o">=</span> <span class="s2">&quot;d&quot;</span> <span class="c1"># Use &#39;d&#39; to get the target for error calculation</span>
    <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;map_TL&quot;</span> <span class="ow">and</span> <span class="n">y_type</span> <span class="o">!=</span> <span class="s2">&quot;c&quot;</span><span class="p">:</span> <span class="c1"># map_TL was trained on &#39;c&#39;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Forcing y_type </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2"> -&gt; &#39;c&#39; for error calculation in model_type </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">original_y_type_for_get_y</span> <span class="o">=</span> <span class="s2">&quot;c&quot;</span>
    
    <span class="c1"># For M3 models, terms_A might need adjustment if derivative/bias terms were removed during training</span>
    <span class="k">if</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
        <span class="n">terms_A</span> <span class="o">=</span> <span class="p">[</span><span class="n">term</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">terms_A</span> <span class="k">if</span> <span class="n">term</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;fdm&quot;</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">,</span> <span class="s2">&quot;fdm3&quot;</span><span class="p">,</span> <span class="s2">&quot;f3&quot;</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">]]</span>


    <span class="c1"># Get map values if needed for the target y</span>
    <span class="n">map_val_data</span> <span class="o">=</span> <span class="n">get_map_val</span><span class="p">(</span><span class="n">mapS</span><span class="p">,</span> <span class="n">xyz</span><span class="o">.</span><span class="n">traj</span><span class="p">,</span> <span class="n">ind</span><span class="p">)</span> <span class="k">if</span> <span class="n">original_y_type_for_get_y</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
    
    <span class="c1"># Prepare A, Bt, B_dot, x, y for the test data</span>
    <span class="c1"># `create_TL_A` and `get_x`/`get_y` need to be robust.</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.analysis_util</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_x</span> <span class="k">as</span> <span class="n">get_x_actual</span><span class="p">,</span> <span class="n">get_y</span> <span class="k">as</span> <span class="n">get_y_actual</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.tolles_lawson</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_TL_A</span> <span class="k">as</span> <span class="n">create_TL_A_actual</span>

        <span class="n">get_x_fn</span> <span class="o">=</span> <span class="n">get_x_actual</span> <span class="k">if</span> <span class="s1">&#39;compensation&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">get_x_actual</span><span class="o">.</span><span class="vm">__module__</span> <span class="k">else</span> <span class="n">get_x</span>
        <span class="n">get_y_fn</span> <span class="o">=</span> <span class="n">get_y_actual</span> <span class="k">if</span> <span class="s1">&#39;compensation&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">get_y_actual</span><span class="o">.</span><span class="vm">__module__</span> <span class="k">else</span> <span class="n">get_y</span>
        <span class="n">create_TL_A_fn</span> <span class="o">=</span> <span class="n">create_TL_A_actual</span> <span class="k">if</span> <span class="s1">&#39;compensation&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">create_TL_A_actual</span><span class="o">.</span><span class="vm">__module__</span> <span class="k">else</span> <span class="n">create_TL_A</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">get_x_fn</span><span class="p">,</span> <span class="n">get_y_fn</span><span class="p">,</span> <span class="n">create_TL_A_fn</span> <span class="o">=</span> <span class="n">get_x</span><span class="p">,</span> <span class="n">get_y</span><span class="p">,</span> <span class="n">create_TL_A</span>


    <span class="n">A_matrix_np</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">Bt_np</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">B_dot_np</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># A_matrix_np for linear models (TL, mod_TL, map_TL)</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">,</span> <span class="s2">&quot;map_TL&quot;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">:</span>
            <span class="n">A_matrix_np</span> <span class="o">=</span> <span class="n">create_TL_A_fn</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_vec</span><span class="p">),</span> <span class="n">ind</span><span class="p">,</span> <span class="n">terms</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">Bt</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_mag</span><span class="p">)[</span><span class="n">ind</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;map_TL&quot;</span><span class="p">:</span>
            <span class="n">A_matrix_np</span> <span class="o">=</span> <span class="n">create_TL_A_fn</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_vec</span><span class="p">),</span> <span class="n">ind</span><span class="p">,</span> <span class="n">terms</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">Bt</span><span class="o">=</span><span class="n">map_val_data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># TL</span>
            <span class="n">A_matrix_np</span> <span class="o">=</span> <span class="n">create_TL_A_fn</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_vec</span><span class="p">),</span> <span class="n">ind</span><span class="p">,</span> <span class="n">terms</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">return_B</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">Bt_in</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span><span class="n">use_mag</span><span class="p">)[</span><span class="n">ind</span><span class="p">]</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span><span class="n">use_mag</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="c1"># If y_type was &#39;e&#39; during training, A was BPF&#39;d. For testing against &#39;d&#39;, use non-BPF&#39;d A.</span>
        <span class="c1"># This is implicitly handled if create_TL_A is called fresh.</span>
        <span class="c1"># If comp_params stored a BPF&#39;d A, that&#39;s an issue. Assume create_TL_A here gives the correct A for testing.</span>
    <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m2&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
        <span class="c1"># These models need A, Bt, B_dot for their _from_raw forward pass</span>
        <span class="n">A_out_test</span> <span class="o">=</span> <span class="n">create_TL_A_fn</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_vec</span><span class="p">),</span> <span class="n">ind</span><span class="p">,</span> <span class="n">terms</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">return_B</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">Bt_in</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span><span class="n">use_mag</span><span class="p">)[</span><span class="n">ind</span><span class="p">]</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span><span class="n">use_mag</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">A_out_test</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">A_out_test</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">Bt_np</span><span class="p">,</span> <span class="n">B_dot_np</span> <span class="o">=</span> <span class="n">A_out_test</span> <span class="c1"># A_matrix_np here is the raw flux components for M3, or full TL for M2</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Should not happen if return_B=True</span>
            <span class="n">A_matrix_np</span> <span class="o">=</span> <span class="n">A_out_test</span> 


    <span class="n">x_np</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">features_out</span><span class="p">,</span> <span class="n">l_segs_out</span> <span class="o">=</span> <span class="n">get_x_fn</span><span class="p">(</span>
        <span class="n">xyz</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">features_setup</span><span class="p">,</span>
        <span class="n">features_no_norm</span><span class="o">=</span><span class="n">features_no_norm</span><span class="p">,</span> <span class="n">terms</span><span class="o">=</span><span class="n">terms</span><span class="p">,</span>
        <span class="n">sub_diurnal</span><span class="o">=</span><span class="n">sub_diurnal</span><span class="p">,</span> <span class="n">sub_igrf</span><span class="o">=</span><span class="n">sub_igrf</span><span class="p">,</span> <span class="n">bpf_mag</span><span class="o">=</span><span class="n">bpf_mag</span>
    <span class="p">)</span>

    <span class="n">y_np</span> <span class="o">=</span> <span class="n">get_y_fn</span><span class="p">(</span>
        <span class="n">xyz</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">map_val_data</span><span class="p">,</span>
        <span class="n">y_type</span><span class="o">=</span><span class="n">original_y_type_for_get_y</span><span class="p">,</span> <span class="c1"># Use the potentially adjusted y_type for target</span>
        <span class="n">use_mag</span><span class="o">=</span><span class="n">use_mag</span><span class="p">,</span>
        <span class="n">sub_diurnal</span><span class="o">=</span><span class="n">sub_diurnal</span><span class="p">,</span> <span class="n">sub_igrf</span><span class="o">=</span><span class="n">sub_igrf</span><span class="p">,</span> <span class="n">bpf_mag</span><span class="o">=</span><span class="n">bpf_mag</span><span class="p">,</span> <span class="c1"># bpf_mag for get_y if y_type=&#39;e&#39;</span>
        <span class="n">fs</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">xyz</span><span class="o">.</span><span class="n">dt</span> <span class="k">if</span> <span class="n">xyz</span><span class="o">.</span><span class="n">dt</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">10.0</span><span class="p">)</span>
    <span class="p">)</span>
    
    <span class="n">y_hat_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_np</span><span class="p">)</span>
    <span class="n">err_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">y_np</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

    <span class="c1"># Feature Importance (FI) logic for testing</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">drop_fi</span> <span class="ow">or</span> <span class="n">perm_fi</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: comp_test running Feature Importance (perm_fi=</span><span class="si">{</span><span class="n">perm_fi</span><span class="si">}</span><span class="s2">, drop_fi=</span><span class="si">{</span><span class="n">drop_fi</span><span class="si">}</span><span class="s2">)...&quot;</span><span class="p">)</span>
        
        <span class="n">fi_csv_output_path</span> <span class="o">=</span> <span class="n">perm_fi_csv_path</span> <span class="k">if</span> <span class="n">perm_fi</span> <span class="k">else</span> <span class="n">drop_fi_csv_path</span>
        <span class="k">if</span> <span class="n">fi_csv_output_path</span><span class="p">:</span>
             <span class="c1"># Clear or header for FI CSV</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fi_csv_output_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;feature_idx,error_std</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">best_err_std_fi</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
        <span class="c1"># y_hat_np and err_np will be from the iteration that produced the best_err_std_fi</span>

        <span class="k">for</span> <span class="n">i_fi</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span> <span class="c1"># Iterate through features</span>
            <span class="n">x_fi_test</span> <span class="o">=</span> <span class="n">x_np</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">current_comp_params</span> <span class="o">=</span> <span class="n">comp_params</span> <span class="c1"># Use the main trained comp_params</span>

            <span class="k">if</span> <span class="n">perm_fi</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Permuting feature </span><span class="si">{</span><span class="n">features_out</span><span class="p">[</span><span class="n">i_fi</span><span class="p">]</span><span class="si">}</span><span class="s2"> for FI test.&quot;</span><span class="p">)</span>
                <span class="n">x_fi_test</span><span class="p">[:,</span> <span class="n">i_fi</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">x_fi_test</span><span class="p">[:,</span> <span class="n">i_fi</span><span class="p">])</span>
            <span class="k">elif</span> <span class="n">drop_fi</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Testing with model trained without feature </span><span class="si">{</span><span class="n">features_out</span><span class="p">[</span><span class="n">i_fi</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="c1"># Load the specific model trained without this feature</span>
                <span class="n">bson_path_fi</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">remove_extension</span><span class="p">(</span><span class="n">drop_fi_bson_base</span><span class="p">)</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">i_fi</span><span class="si">}</span><span class="s2">.bson&quot;</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">current_comp_params</span> <span class="o">=</span> <span class="n">get_comp_params</span><span class="p">(</span><span class="n">bson_path_fi</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded FI model from </span><span class="si">{</span><span class="n">bson_path_fi</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WARN: FI model </span><span class="si">{</span><span class="n">bson_path_fi</span><span class="si">}</span><span class="s2"> not found. Skipping this feature for drop_fi.&quot;</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="c1"># x_fi_test will be x_np with the i_fi column conceptually dropped,</span>
                <span class="c1"># because the loaded model was trained on data without it.</span>
                <span class="c1"># The _from_raw functions need to handle x that matches the model&#39;s training.</span>
                <span class="c1"># This means nn_comp_X_test_from_raw needs x_raw that&#39;s already subsetted.</span>
                <span class="c1"># This is complex. The Julia version passes x_fi (subsetted x) to nn_comp_X_test.</span>
                <span class="c1"># For drop_fi, the loaded `current_comp_params.model` was trained on x_fi.</span>
                <span class="c1"># So, `data_norms` in `current_comp_params` are also for x_fi.</span>
                <span class="c1"># We need to pass x_fi_test (which is x_np with col i_fi removed) to _from_raw.</span>
                <span class="n">x_fi_test_for_drop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">x_np</span><span class="p">,</span> <span class="n">i_fi</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


            <span class="c1"># Select the correct test function based on model_type</span>
            <span class="n">y_hat_iter</span><span class="p">,</span> <span class="n">err_iter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
            
            <span class="c1"># Use _from_raw versions for testing with loaded comp_params</span>
            <span class="k">if</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;m1&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">drop_fi</span><span class="p">:</span>
                    <span class="n">y_hat_iter</span><span class="p">,</span> <span class="n">err_iter</span> <span class="o">=</span> <span class="n">nn_comp_1_test_from_raw</span><span class="p">(</span><span class="n">x_fi_test_for_drop</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span> <span class="c1"># perm_fi</span>
                    <span class="n">y_hat_iter</span><span class="p">,</span> <span class="n">err_iter</span> <span class="o">=</span> <span class="n">nn_comp_1_test_from_raw</span><span class="p">(</span><span class="n">x_fi_test</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="p">)</span>
            
            <span class="k">elif</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m2&quot;</span><span class="p">):</span>
                <span class="c1"># A_matrix_np, Bt_np, B_dot_np are from the full test data (xyz, ind)</span>
                <span class="c1"># x_fi_test or x_fi_test_for_drop is used</span>
                <span class="c1"># TL_coef is from current_comp_params</span>
                <span class="k">if</span> <span class="n">drop_fi</span><span class="p">:</span>
                    <span class="n">y_hat_iter</span><span class="p">,</span> <span class="n">err_iter</span> <span class="o">=</span> <span class="n">nn_comp_2_test_from_raw</span><span class="p">(</span><span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">x_fi_test_for_drop</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model_type</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">TL_coef</span><span class="p">,</span> <span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span> <span class="c1"># perm_fi</span>
                     <span class="n">y_hat_iter</span><span class="p">,</span> <span class="n">err_iter</span> <span class="o">=</span> <span class="n">nn_comp_2_test_from_raw</span><span class="p">(</span><span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">x_fi_test</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model_type</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">TL_coef</span><span class="p">,</span> <span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="p">)</span>
            
            <span class="k">elif</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">drop_fi</span><span class="p">:</span>
                    <span class="n">y_hat_iter</span><span class="p">,</span> <span class="n">err_iter</span> <span class="o">=</span> <span class="n">nn_comp_3_test_from_raw</span><span class="p">(</span>
                        <span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">Bt_np</span><span class="p">,</span> <span class="n">B_dot_np</span><span class="p">,</span> <span class="n">x_fi_test_for_drop</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                        <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model_type</span><span class="p">,</span> <span class="n">original_y_type_for_get_y</span><span class="p">,</span> <span class="c1"># Use original y_type for consistency with how model was trained/tested</span>
                        <span class="n">current_comp_params</span><span class="o">.</span><span class="n">TL_coef</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">l_window</span><span class="o">=</span><span class="n">l_window</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span> <span class="c1"># perm_fi</span>
                     <span class="n">y_hat_iter</span><span class="p">,</span> <span class="n">err_iter</span> <span class="o">=</span> <span class="n">nn_comp_3_test_from_raw</span><span class="p">(</span>
                        <span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">Bt_np</span><span class="p">,</span> <span class="n">B_dot_np</span><span class="p">,</span> <span class="n">x_fi_test</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                        <span class="n">current_comp_params</span><span class="o">.</span><span class="n">model_type</span><span class="p">,</span> <span class="n">original_y_type_for_get_y</span><span class="p">,</span>
                        <span class="n">current_comp_params</span><span class="o">.</span><span class="n">TL_coef</span><span class="p">,</span> <span class="n">current_comp_params</span><span class="o">.</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">l_window</span><span class="o">=</span><span class="n">l_window</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WARN: FI testing not implemented for model_type </span><span class="si">{</span><span class="n">current_comp_params</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="n">current_err_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">err_iter</span><span class="p">)</span> <span class="k">if</span> <span class="n">err_iter</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">fi_csv_output_path</span><span class="p">:</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fi_csv_output_path</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i_fi</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">current_err_std</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># Save 0-indexed feature index</span>

            <span class="k">if</span> <span class="n">current_err_std</span> <span class="o">&lt;</span> <span class="n">best_err_std_fi</span> <span class="p">:</span> <span class="c1"># Julia uses &gt; for perm_fi, &lt; for drop_fi. Let&#39;s use &lt; for both (lower error is better)</span>
                <span class="n">best_err_std_fi</span> <span class="o">=</span> <span class="n">current_err_std</span>
                <span class="n">y_hat_np</span> <span class="o">=</span> <span class="n">y_hat_iter</span> <span class="c1"># Store the y_hat from the best FI iteration</span>
                <span class="n">err_np</span> <span class="o">=</span> <span class="n">err_iter</span>     <span class="c1"># Store the error from the best FI iteration</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Feature Importance testing finished. Best error std: </span><span class="si">{</span><span class="n">best_err_std_fi</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> nT (results in y_hat, err are from this best FI iteration).&quot;</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span> <span class="c1"># Standard test (no FI loop)</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;m1&quot;</span><span class="p">:</span>
            <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_1_test_from_raw</span><span class="p">(</span><span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m2&quot;</span><span class="p">):</span>
            <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_2_test_from_raw</span><span class="p">(</span><span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">TL_coef_val</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
            <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_3_test_from_raw</span><span class="p">(</span>
                <span class="n">A_raw</span><span class="o">=</span><span class="n">A_matrix_np</span><span class="p">,</span> <span class="n">Bt_raw</span><span class="o">=</span><span class="n">Bt_np</span><span class="p">,</span> <span class="n">B_dot_raw</span><span class="o">=</span><span class="n">B_dot_np</span><span class="p">,</span> <span class="c1"># A_matrix_np is flux for M3</span>
                <span class="n">x_raw</span><span class="o">=</span><span class="n">x_np</span><span class="p">,</span> <span class="n">y_raw</span><span class="o">=</span><span class="n">y_np</span><span class="p">,</span> <span class="n">data_norms</span><span class="o">=</span><span class="n">data_norms</span><span class="p">,</span> <span class="n">model_nn</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span> <span class="n">y_type</span><span class="o">=</span><span class="n">original_y_type_for_get_y</span><span class="p">,</span> <span class="n">TL_coef_raw</span><span class="o">=</span><span class="n">TL_coef_val</span><span class="p">,</span> <span class="n">terms_A</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span>
                <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">l_window</span><span class="o">=</span><span class="n">l_window</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">,</span> <span class="s2">&quot;map_TL&quot;</span><span class="p">]:</span>
            <span class="c1"># linear_test expects normalized x (A_matrix_np here) and raw y (y_np)</span>
            <span class="c1"># It also needs y_bias and y_scale from data_norms.</span>
            <span class="c1"># The model is (coeffs, bias_val)</span>
            <span class="k">if</span> <span class="n">data_norms</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_norms</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">:</span> <span class="c1"># Should have been set during training</span>
                 <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;data_norms missing or incomplete for linear model testing&quot;</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">y_bias_lin</span><span class="p">,</span> <span class="n">y_scale_lin</span> <span class="o">=</span> <span class="n">unpack_data_norms</span><span class="p">(</span><span class="n">data_norms</span><span class="p">)</span> <span class="c1"># type: ignore</span>
            
            <span class="c1"># A_matrix_np should be the one used for training (potentially BPF&#39;d if y_type was &#39;e&#39;)</span>
            <span class="c1"># However, for error calculation, if original y_type was &#39;e&#39;, we test against &#39;d&#39; with non-BPF&#39;d A.</span>
            <span class="n">A_test_final</span> <span class="o">=</span> <span class="n">A_matrix_np</span>
            <span class="n">y_test_final</span> <span class="o">=</span> <span class="n">y_np</span>
            <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;e&quot;</span><span class="p">:</span> <span class="c1"># If trained on &#39;e&#39;</span>
                <span class="k">if</span> <span class="n">A_no_bpf_np</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># Should have been stored during comp_train if y_type was &#39;e&#39;</span>
                     <span class="c1"># Recreate non-BPF A if not available (less ideal)</span>
                     <span class="n">A_no_bpf_np</span> <span class="o">=</span> <span class="n">create_TL_A_fn</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">use_vec</span><span class="p">),</span> <span class="n">ind</span><span class="p">,</span> <span class="n">terms</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="n">return_B</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">Bt_in</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span><span class="n">use_mag</span><span class="p">)[</span><span class="n">ind</span><span class="p">]</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span><span class="n">use_mag</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
                <span class="n">A_test_final</span> <span class="o">=</span> <span class="n">A_no_bpf_np</span>
                <span class="k">if</span> <span class="n">y_no_bpf_np</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                     <span class="n">y_no_bpf_np</span> <span class="o">=</span> <span class="n">get_y_fn</span><span class="p">(</span><span class="n">xyz</span><span class="p">,</span> <span class="n">ind</span><span class="p">,</span> <span class="n">map_val_data</span><span class="p">,</span> <span class="n">y_type</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">use_mag</span><span class="o">=</span><span class="n">use_mag</span><span class="p">,</span> <span class="n">sub_diurnal</span><span class="o">=</span><span class="n">sub_diurnal</span><span class="p">,</span> <span class="n">sub_igrf</span><span class="o">=</span><span class="n">sub_igrf</span><span class="p">)</span>
                <span class="n">y_test_final</span> <span class="o">=</span> <span class="n">y_no_bpf_np</span>

            <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">linear_test</span><span class="p">(</span><span class="n">A_test_final</span><span class="p">,</span> <span class="n">y_test_final</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;elasticnet&quot;</span> <span class="ow">or</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;plsr&quot;</span><span class="p">:</span>
            <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">linear_test</span><span class="p">(</span><span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown model_type: </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2"> in comp_test&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
        <span class="n">time_unit</span> <span class="o">=</span> <span class="s2">&quot;sec&quot;</span>
        <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">60</span><span class="p">:</span>
            <span class="n">elapsed_time</span> <span class="o">/=</span> <span class="mi">60</span>
            <span class="n">time_unit</span> <span class="o">=</span> <span class="s2">&quot;min&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: comp_test completed in </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">time_unit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span><span class="p">,</span> <span class="n">features_out</span>
<div class="viewcode-block" id="comp_test">
<a class="viewcode-back" href="../../comp.html#magnavpy.compensation.comp_test">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">comp_test</span><span class="p">(</span> <span class="c1"># Overload for DataFrames</span>
    <span class="n">comp_params</span><span class="p">:</span> <span class="n">CompParams</span><span class="p">,</span>
    <span class="n">lines</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">df_line</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="c1"># pandas.DataFrame</span>
    <span class="n">df_flight</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="c1"># pandas.DataFrame</span>
    <span class="n">df_map</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="c1"># pandas.DataFrame</span>
    <span class="n">temp_params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TempParams</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate performance of an aeromagnetic compensation model using DataFrame inputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">t0_df</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">temp_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">temp_params</span> <span class="o">=</span> <span class="n">TempParams</span><span class="p">()</span>

    <span class="c1"># Unpack parameters</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">model_type</span>
    <span class="n">y_type</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">y_type</span> <span class="c1"># This is the y_type the model was trained on</span>
    <span class="n">use_mag</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">use_mag</span>
    <span class="n">use_vec</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">use_vec</span>
    <span class="c1"># data_norms = comp_params.data_norms # Loaded by comp_test(XYZ,...)</span>
    <span class="c1"># model = comp_params.model           # Loaded by comp_test(XYZ,...)</span>
    <span class="n">terms</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">terms</span>
    <span class="n">terms_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">terms_A</span><span class="p">)</span>
    <span class="n">sub_diurnal</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">sub_diurnal</span>
    <span class="n">sub_igrf</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">sub_igrf</span>
    <span class="n">bpf_mag</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">bpf_mag</span>
    <span class="n">reorient_vec</span> <span class="o">=</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">reorient_vec</span>
    <span class="n">features_setup</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">features_setup</span><span class="p">)</span>
    <span class="n">features_no_norm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">comp_params</span><span class="o">.</span><span class="n">features_no_norm</span><span class="p">)</span>
    
    <span class="c1"># Adjust y_type for testing if necessary (e.g. evaluate TL model trained on &#39;e&#39; against &#39;d&#39;)</span>
    <span class="n">y_type_for_eval</span> <span class="o">=</span> <span class="n">y_type</span>
    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;e&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Forcing y_type </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2"> -&gt; &#39;d&#39; (Δmag) for error calculation in model_type </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">y_type_for_eval</span> <span class="o">=</span> <span class="s2">&quot;d&quot;</span>
    <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;map_TL&quot;</span> <span class="ow">and</span> <span class="n">y_type</span> <span class="o">!=</span> <span class="s2">&quot;c&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Forcing y_type </span><span class="si">{</span><span class="n">y_type</span><span class="si">}</span><span class="s2"> -&gt; &#39;c&#39; for error calculation in model_type </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">y_type_for_eval</span> <span class="o">=</span> <span class="s2">&quot;c&quot;</span>
    
    <span class="k">if</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
        <span class="n">terms_A_original</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">terms_A</span><span class="p">)</span>
        <span class="n">terms_A</span> <span class="o">=</span> <span class="p">[</span><span class="n">term</span> <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">terms_A</span> <span class="k">if</span> <span class="n">term</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;fdm&quot;</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">,</span> <span class="s2">&quot;fdm3&quot;</span><span class="p">,</span> <span class="s2">&quot;f3&quot;</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">]]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">terms_A</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">terms_A_original</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
             <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: Removing derivative/bias terms from terms_A for M3 model test. Original: </span><span class="si">{</span><span class="n">terms_A_original</span><span class="si">}</span><span class="s2">, New: </span><span class="si">{</span><span class="n">terms_A</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>

<span class="k">def</span><span class="w"> </span><span class="nf">comp_train_test</span><span class="p">(</span>
    <span class="n">comp_params</span><span class="p">:</span> <span class="n">CompParams</span><span class="p">,</span>
    <span class="n">xyz_train</span><span class="p">:</span> <span class="n">XYZ</span><span class="p">,</span>
    <span class="n">xyz_test</span><span class="p">:</span> <span class="n">XYZ</span><span class="p">,</span>
    <span class="n">ind_train</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">ind_test</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">mapS_train</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">mapS_null</span><span class="p">,</span> <span class="c1"># Union[MapS, MapSd, MapS3D]</span>
    <span class="n">mapS_test</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">mapS_null</span><span class="p">,</span>  <span class="c1"># Union[MapS, MapSd, MapS3D]</span>
    <span class="n">temp_params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TempParams</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">CompParams</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train &amp; evaluate performance of an aeromagnetic compensation model.</span>

<span class="sd">    Args:</span>
<span class="sd">        comp_params: CompParams object.</span>
<span class="sd">        xyz_train: XYZ flight data struct for training.</span>
<span class="sd">        xyz_test: XYZ flight data struct for testing.</span>
<span class="sd">        ind_train: Selected data indices for training.</span>
<span class="sd">        ind_test: Selected data indices for testing.</span>
<span class="sd">        mapS_train: (optional) MapS struct for training.</span>
<span class="sd">        mapS_test: (optional) MapS struct for testing.</span>
<span class="sd">        temp_params: (optional) TempParams struct.</span>
<span class="sd">        silent: (optional) If true, no print outs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        comp_params: Updated CompParams object.</span>
<span class="sd">        y_train: Training target vector.</span>
<span class="sd">        y_train_hat: Training prediction vector.</span>
<span class="sd">        err_train: Training compensation error.</span>
<span class="sd">        y_test: Testing target vector.</span>
<span class="sd">        y_test_hat: Testing prediction vector.</span>
<span class="sd">        err_test: Testing compensation error.</span>
<span class="sd">        features: List of feature names used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">xyz_train</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">type</span><span class="p">(</span><span class="n">xyz_test</span><span class="p">):</span> <span class="c1"># Basic type check</span>
        <span class="c1"># In Julia, this might check for specific XYZ subtypes.</span>
        <span class="c1"># For Python, a simple type check or isinstance checks might be used.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARN: xyz_train and xyz_test are of different types. This might be unintended.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">temp_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">temp_params</span> <span class="o">=</span> <span class="n">TempParams</span><span class="p">()</span>

    <span class="c1"># Train the model</span>
    <span class="c1"># The comp_train(XYZ, ind, ...) version can take xyz_test and ind_test for internal validation/best model selection</span>
    <span class="c1"># during its own training epochs. Here, we are doing a separate test *after* training is complete.</span>
    <span class="c1"># So, we pass None for xyz_test, ind_test to the comp_train call.</span>
    <span class="n">comp_params_trained</span><span class="p">,</span> <span class="n">y_train_np</span><span class="p">,</span> <span class="n">y_train_hat_np</span><span class="p">,</span> <span class="n">err_train_np</span><span class="p">,</span> <span class="n">features_out</span> <span class="o">=</span> <span class="n">comp_train</span><span class="p">(</span>
        <span class="n">comp_params</span><span class="p">,</span> <span class="n">xyz_train</span><span class="p">,</span> <span class="n">ind_train</span><span class="p">,</span> <span class="n">mapS_train</span><span class="p">,</span>
        <span class="n">temp_params</span><span class="o">=</span><span class="n">temp_params</span><span class="p">,</span>
        <span class="n">xyz_test</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># Do not use xyz_test for internal validation loop of comp_train here</span>
        <span class="n">ind_test</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># As this is a separate test step after full training</span>
        <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
    <span class="p">)</span>

    <span class="c1"># Test the trained model</span>
    <span class="n">y_test_np</span><span class="p">,</span> <span class="n">y_test_hat_np</span><span class="p">,</span> <span class="n">err_test_np</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">comp_test</span><span class="p">(</span>
        <span class="n">comp_params_trained</span><span class="p">,</span> <span class="n">xyz_test</span><span class="p">,</span> <span class="n">ind_test</span><span class="p">,</span> <span class="n">mapS_test</span><span class="p">,</span>
        <span class="n">temp_params</span><span class="o">=</span><span class="n">temp_params</span><span class="p">,</span>
        <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">comp_params_trained</span><span class="p">,</span>
        <span class="n">y_train_np</span><span class="p">,</span> <span class="n">y_train_hat_np</span><span class="p">,</span> <span class="n">err_train_np</span><span class="p">,</span>
        <span class="n">y_test_np</span><span class="p">,</span> <span class="n">y_test_hat_np</span><span class="p">,</span> <span class="n">err_test_np</span><span class="p">,</span>
        <span class="n">features_out</span>
    <span class="p">)</span>
        <span class="c1"># comp_params.terms_A is not modified here as it&#39;s a test function</span>

    <span class="c1"># Load data using get_Axy</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">.analysis_util</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_Axy</span> <span class="k">as</span> <span class="n">get_Axy_actual</span><span class="p">,</span> <span class="n">get_XYZ</span> <span class="k">as</span> <span class="n">get_XYZ_actual</span><span class="p">,</span> <span class="n">get_ind</span> <span class="c1"># Assuming get_ind is also there</span>
        <span class="k">if</span> <span class="s1">&#39;compensation&#39;</span> <span class="ow">in</span> <span class="n">get_Axy_actual</span><span class="o">.</span><span class="vm">__module__</span><span class="p">:</span> <span class="n">get_Axy_fn</span> <span class="o">=</span> <span class="n">get_Axy</span> <span class="c1"># placeholder</span>
        <span class="k">else</span><span class="p">:</span> <span class="n">get_Axy_fn</span> <span class="o">=</span> <span class="n">get_Axy_actual</span>
        <span class="k">if</span> <span class="s1">&#39;compensation&#39;</span> <span class="ow">in</span> <span class="n">get_XYZ_actual</span><span class="o">.</span><span class="vm">__module__</span><span class="p">:</span> <span class="n">get_XYZ_fn</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># placeholder used by get_Axy</span>
        <span class="k">else</span><span class="p">:</span> <span class="n">get_XYZ_fn</span> <span class="o">=</span> <span class="n">get_XYZ_actual</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">get_Axy_fn</span> <span class="o">=</span> <span class="n">get_Axy</span> 
        <span class="n">get_XYZ_fn</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># Cannot get XYZ directly</span>

    <span class="c1"># The comp_test(XYZ, ind, ...) needs an XYZ object.</span>
    <span class="c1"># We need to construct it from the DataFrames for the given `lines`.</span>
    <span class="c1"># This part is simplified; a full get_XYZ from DataFrames would be complex.</span>
    <span class="c1"># Assuming `get_Axy` can internally call or we can call `get_XYZ` and `get_ind`.</span>
    
    <span class="c1"># For now, let&#39;s assume we can get a single XYZ object for all lines for testing.</span>
    <span class="c1"># This might need refinement if lines span multiple flights that can&#39;t be concatenated.</span>
    <span class="c1"># The Julia `get_Axy` handles iterating through lines and concatenating.</span>
    <span class="c1"># We will rely on the primary `comp_test(XYZ, ...)` to use the data from `get_Axy`</span>
    <span class="c1"># rather than re-calling `get_XYZ` itself.</span>
    
    <span class="c1"># The `comp_test(XYZ, ind, ...)` function will internally call get_Axy components.</span>
    <span class="c1"># It&#39;s better to call the primary `comp_test` by first creating the `xyz` and `ind` objects.</span>
    
    <span class="c1"># Simplified approach: Create one XYZ for all lines.</span>
    <span class="c1"># This assumes all lines are from compatible flights/setups if multiple.</span>
    <span class="c1"># A more robust `get_XYZ_from_df_lines` would be needed for general cases.</span>
    
    <span class="n">xyz_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ind_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">current_total_samples</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">_lines</span> <span class="o">=</span> <span class="n">lines</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
        <span class="n">_lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">lines</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">line_num_val</span> <span class="ow">in</span> <span class="n">_lines</span><span class="p">:</span>
        <span class="n">line_info</span> <span class="o">=</span> <span class="n">df_line</span><span class="p">[</span><span class="n">df_line</span><span class="p">[</span><span class="s2">&quot;line&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">line_num_val</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">line_info</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WARN: Line </span><span class="si">{</span><span class="n">line_num_val</span><span class="si">}</span><span class="s2"> not found in df_line. Skipping.&quot;</span><span class="p">)</span>
            <span class="k">continue</span>
        <span class="n">line_info</span> <span class="o">=</span> <span class="n">line_info</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># Take the first match</span>

        <span class="n">flight_name</span> <span class="o">=</span> <span class="n">line_info</span><span class="p">[</span><span class="s2">&quot;flight&quot;</span><span class="p">]</span>
        <span class="n">flight_info</span> <span class="o">=</span> <span class="n">df_flight</span><span class="p">[</span><span class="n">df_flight</span><span class="p">[</span><span class="s2">&quot;flight&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">flight_name</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">flight_info</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WARN: Flight </span><span class="si">{</span><span class="n">flight_name</span><span class="si">}</span><span class="s2"> for line </span><span class="si">{</span><span class="n">line_num_val</span><span class="si">}</span><span class="s2"> not found in df_flight. Skipping line.&quot;</span><span class="p">)</span>
            <span class="k">continue</span>
        <span class="n">flight_info</span> <span class="o">=</span> <span class="n">flight_info</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">xyz_file_path</span> <span class="o">=</span> <span class="n">flight_info</span><span class="p">[</span><span class="s2">&quot;xyz_file&quot;</span><span class="p">]</span>
        <span class="c1"># Assuming get_XYZ can load this (needs to be fully implemented)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># This is a placeholder for actual XYZ loading logic from file + df_line info</span>
            <span class="c1"># xyz_single_line = get_XYZ(xyz_file_path, flight_info[&quot;xyz_type&quot;]) </span>
            <span class="c1"># For now, we&#39;ll pass all data to the main comp_test via get_Axy logic below</span>
            <span class="c1"># This means we don&#39;t construct XYZ here but let comp_test(params, lines, dfs...) do it.</span>
            <span class="k">pass</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading XYZ for line </span><span class="si">{</span><span class="n">line_num_val</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Skipping.&quot;</span><span class="p">)</span>
            <span class="k">continue</span>
    
    <span class="c1"># Since comp_test(XYZ, ind, ...) is the primary one that handles model logic,</span>
    <span class="c1"># this DataFrame version should ideally prepare XYZ and ind and call that.</span>
    <span class="c1"># However, the Julia version&#39;s comp_test(df) also calls get_Axy directly.</span>
    <span class="c1"># Let&#39;s stick to that pattern for now.</span>

    <span class="n">Axy_outputs_test</span> <span class="o">=</span> <span class="n">get_Axy_fn</span><span class="p">(</span>
        <span class="n">lines</span><span class="p">,</span> <span class="n">df_line</span><span class="p">,</span> <span class="n">df_flight</span><span class="p">,</span> <span class="n">df_map</span><span class="p">,</span>
        <span class="n">features_setup</span><span class="p">,</span>
        <span class="n">features_no_norm</span><span class="o">=</span><span class="n">features_no_norm</span><span class="p">,</span>
        <span class="n">y_type</span><span class="o">=</span><span class="n">y_type_for_eval</span><span class="p">,</span> <span class="c1"># Use the potentially adjusted y_type</span>
        <span class="n">use_mag</span><span class="o">=</span><span class="n">use_mag</span><span class="p">,</span>
        <span class="n">use_vec</span><span class="o">=</span><span class="n">use_vec</span><span class="p">,</span>
        <span class="n">terms</span><span class="o">=</span><span class="n">terms</span><span class="p">,</span>
        <span class="n">terms_A</span><span class="o">=</span><span class="n">terms_A</span><span class="p">,</span> <span class="c1"># Use potentially adjusted terms_A</span>
        <span class="n">sub_diurnal</span><span class="o">=</span><span class="n">sub_diurnal</span><span class="p">,</span>
        <span class="n">sub_igrf</span><span class="o">=</span><span class="n">sub_igrf</span><span class="p">,</span>
        <span class="n">bpf_mag</span><span class="o">=</span><span class="n">bpf_mag</span><span class="p">,</span> <span class="c1"># This should align with y_type_for_eval</span>
        <span class="n">reorient_vec</span><span class="o">=</span><span class="n">reorient_vec</span><span class="p">,</span>
        <span class="n">mod_TL</span><span class="o">=</span><span class="p">(</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">),</span>
        <span class="n">map_TL</span><span class="o">=</span><span class="p">(</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;map_TL&quot;</span><span class="p">),</span>
        <span class="n">return_B</span><span class="o">=</span><span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">),</span>
        <span class="n">silent</span><span class="o">=</span><span class="n">SILENT_DEBUG</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
        <span class="n">A_test_np</span><span class="p">,</span> <span class="n">Bt_test_np</span><span class="p">,</span> <span class="n">B_dot_test_np</span><span class="p">,</span> <span class="n">x_test_np</span><span class="p">,</span> <span class="n">y_test_np</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">features_out</span><span class="p">,</span> <span class="n">l_segs_out</span> <span class="o">=</span> <span class="n">Axy_outputs_test</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">A_test_np</span><span class="p">,</span> <span class="n">x_test_np</span><span class="p">,</span> <span class="n">y_test_np</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">features_out</span><span class="p">,</span> <span class="n">l_segs_out</span> <span class="o">=</span> <span class="n">Axy_outputs_test</span>
        <span class="n">Bt_test_np</span><span class="p">,</span> <span class="n">B_dot_test_np</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span> 
        <span class="c1"># Ensure these are correctly sized if None, for functions expecting them</span>
        <span class="k">if</span> <span class="n">A_test_np</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_samples_test</span> <span class="o">=</span> <span class="n">A_test_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">Bt_test_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">num_samples_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">Bt_test_np</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">Bt_test_np</span>
            <span class="n">B_dot_test_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">num_samples_test</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">if</span> <span class="n">B_dot_test_np</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">B_dot_test_np</span>


    <span class="c1"># Now call the appropriate _from_raw test function</span>
    <span class="n">y_hat_np</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">err_np</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>

    <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">data_norms</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model or data_norms not found in comp_params for comp_test.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;m1&quot;</span><span class="p">:</span>
        <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_1_test_from_raw</span><span class="p">(</span><span class="n">x_test_np</span><span class="p">,</span> <span class="n">y_test_np</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m2&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;NNCompParams expected for M2 models&quot;</span><span class="p">)</span>
        <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_2_test_from_raw</span><span class="p">(</span><span class="n">A_test_np</span><span class="p">,</span> <span class="n">x_test_np</span><span class="p">,</span> <span class="n">y_test_np</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">model_type</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;m3&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">comp_params</span><span class="p">,</span> <span class="n">NNCompParams</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;NNCompParams expected for M3 models&quot;</span><span class="p">)</span>
        <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">nn_comp_3_test_from_raw</span><span class="p">(</span>
            <span class="n">A_test_np</span><span class="p">,</span> <span class="n">Bt_test_np</span><span class="p">,</span> <span class="n">B_dot_test_np</span><span class="p">,</span> <span class="n">x_test_np</span><span class="p">,</span> <span class="n">y_test_np</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span>
            <span class="n">model_type</span><span class="p">,</span> <span class="n">y_type_for_eval</span><span class="p">,</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">TL_coef</span><span class="p">,</span> <span class="n">terms_A</span><span class="p">,</span> <span class="c1"># Use original terms_A from comp_params for TL_coef interpretation</span>
            <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">l_window</span><span class="o">=</span><span class="n">l_window</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">,</span> <span class="s2">&quot;map_TL&quot;</span><span class="p">]:</span>
         <span class="c1"># linear_test expects normalized A_test_np, raw y_test_np, y_bias, y_scale, and model tuple</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">y_bias_lin</span><span class="p">,</span> <span class="n">y_scale_lin</span> <span class="o">=</span> <span class="n">unpack_data_norms</span><span class="p">(</span><span class="n">data_norms</span><span class="p">)</span> <span class="c1"># type: ignore</span>
        
        <span class="n">A_eval_final</span> <span class="o">=</span> <span class="n">A_test_np</span>
        <span class="n">y_eval_final</span> <span class="o">=</span> <span class="n">y_test_np</span>

        <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;TL&quot;</span><span class="p">,</span> <span class="s2">&quot;mod_TL&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">comp_params</span><span class="o">.</span><span class="n">y_type</span> <span class="o">==</span> <span class="s2">&quot;e&quot;</span><span class="p">:</span> <span class="c1"># If model was trained on &#39;e&#39;</span>
            <span class="c1"># Need to re-fetch non-BPF&#39;d A and y for evaluation against &#39;d&#39;</span>
            <span class="c1"># This is complex as get_Axy was called with y_type_for_eval=&#39;d&#39;</span>
            <span class="c1"># If comp_params.y_type was &#39;e&#39;, the stored model was for BPF&#39;d A.</span>
            <span class="c1"># We need non-BPF A for testing against non-BPF y.</span>
            <span class="c1"># This implies the data_norms might also be for BPF&#39;d A.</span>
            <span class="c1"># This path needs careful review of how data was normed and model trained.</span>
            <span class="c1"># For now, assume A_test_np and y_test_np from get_Axy(y_type_for_eval=&#39;d&#39;) are correct.</span>
            <span class="c1"># The model (coefficients) in comp_params, however, was trained on potentially BPF&#39;d A.</span>
            <span class="c1"># This is a mismatch if not handled carefully.</span>
            <span class="c1"># The Julia version&#39;s linear_test for TL/mod_TL uses A_no_bpf and y_no_bpf if original y was &#39;e&#39;.</span>
            <span class="c1"># This means we should try to get the non-BPF versions of A and y.</span>
            <span class="c1"># The current get_Axy call uses y_type_for_eval. If that was &#39;d&#39;, A_test_np is not BPF&#39;d.</span>
            <span class="k">pass</span> <span class="c1"># Assuming A_test_np and y_test_np are correctly non-BPF&#39;d if y_type_for_eval is &#39;d&#39;</span>

        <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">linear_test</span><span class="p">(</span><span class="n">A_eval_final</span><span class="p">,</span> <span class="n">y_eval_final</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;elasticnet&quot;</span><span class="p">,</span> <span class="s2">&quot;plsr&quot;</span><span class="p">]:</span>
        <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span> <span class="o">=</span> <span class="n">linear_test</span><span class="p">(</span><span class="n">x_test_np</span><span class="p">,</span> <span class="n">y_test_np</span><span class="p">,</span> <span class="n">data_norms</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">l_segs</span><span class="o">=</span><span class="n">l_segs_out</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="n">silent</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown model_type: </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2"> in comp_test (DataFrame version)&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0_df</span>
        <span class="n">time_unit</span> <span class="o">=</span> <span class="s2">&quot;sec&quot;</span>
        <span class="k">if</span> <span class="n">elapsed_time</span> <span class="o">&gt;</span> <span class="mi">60</span><span class="p">:</span>
            <span class="n">elapsed_time</span> <span class="o">/=</span> <span class="mi">60</span>
            <span class="n">time_unit</span> <span class="o">=</span> <span class="s2">&quot;min&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: comp_test (DataFrame version) completed in </span><span class="si">{</span><span class="n">elapsed_time</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">time_unit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">y_test_np</span><span class="p">,</span> <span class="n">y_hat_np</span><span class="p">,</span> <span class="n">err_np</span><span class="p">,</span> <span class="n">features_out</span>
<div class="viewcode-block" id="comp_train_test">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.comp_train_test">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">comp_train_test</span><span class="p">(</span> <span class="c1"># Overload for DataFrames</span>
    <span class="n">comp_params</span><span class="p">:</span> <span class="n">CompParams</span><span class="p">,</span>
    <span class="n">lines_train</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">lines_test</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">df_line</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="c1"># pandas.DataFrame</span>
    <span class="n">df_flight</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="c1"># pandas.DataFrame</span>
    <span class="n">df_map</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="c1"># pandas.DataFrame</span>
    <span class="n">temp_params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TempParams</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">silent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">CompParams</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train &amp; evaluate performance of an aeromagnetic compensation model using DataFrame inputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">temp_params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">temp_params</span> <span class="o">=</span> <span class="n">TempParams</span><span class="p">()</span>

    <span class="c1"># This function needs to load XYZ data for train and test sets.</span>
    <span class="c1"># The Julia version calls get_XYZ and get_ind for lines_train and lines_test separately.</span>
    <span class="c1"># We need a robust way to do this. For now, assuming a helper or direct logic.</span>

    <span class="c1"># Simplified XYZ and ind loading for train and test based on DataFrames</span>
    <span class="c1"># This is a placeholder for a more robust get_XYZ_and_ind_from_dfs function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_xyz_and_ind_for_lines</span><span class="p">(</span>
        <span class="n">lines_set</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">df_line_local</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="c1"># pd.DataFrame,</span>
        <span class="n">df_flight_local</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="c1"># pd.DataFrame,</span>
        <span class="n">df_map_local</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="c1"># pd.DataFrame,</span>
        <span class="c1"># mapS_cache: Dict[str, Any], # To cache loaded maps</span>
        <span class="c1"># xyz_cache: Dict[str, XYZ] # To cache loaded XYZ data by flight</span>
        <span class="n">comp_params_local</span><span class="p">:</span> <span class="n">CompParams</span> <span class="c1"># To access use_mag, use_vec etc. for field_check</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">XYZ</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]]:</span> <span class="c1"># Returns XYZ, ind, mapS_obj</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">df_line_local</span><span class="p">,</span> <span class="s2">&quot;empty&quot;</span><span class="p">):</span> <span class="c1"># Check if it&#39;s a DataFrame</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;df_line must be a pandas DataFrame&quot;</span><span class="p">)</span>

        <span class="n">_lines_set</span> <span class="o">=</span> <span class="n">lines_set</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lines_set</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="n">_lines_set</span> <span class="o">=</span> <span class="p">[</span><span class="n">lines_set</span><span class="p">]</span>
        
        <span class="n">all_xyz_data_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_indices_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">map_name_train</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">map_obj_train</span> <span class="o">=</span> <span class="n">mapS_null</span>

        <span class="c1"># This is highly simplified. A proper implementation would:</span>
        <span class="c1"># - Iterate through unique flights in _lines_set.</span>
        <span class="c1"># - Load each flight&#39;s XYZ data once (use a cache).</span>
        <span class="c1"># - For each line in _lines_set for that flight:</span>
        <span class="c1">#   - Get the time indices (t_start, t_end).</span>
        <span class="c1">#   - Convert time indices to sample indices based on xyz.dt.</span>
        <span class="c1">#   - Append the XYZ object and the sample indices for that line.</span>
        <span class="c1"># - Concatenate all XYZ data if possible (if from same flight or compatible)</span>
        <span class="c1">#   or handle as a list of (XYZ, ind) pairs.</span>
        <span class="c1"># - Load the relevant mapS object.</span>
        
        <span class="c1"># For now, let&#39;s assume get_Axy can handle a list of lines and DataFrames</span>
        <span class="c1"># and internally does the XYZ loading and indexing.</span>
        <span class="c1"># The primary comp_train(XYZ, ind) expects a single XYZ and corresponding ind.</span>
        <span class="c1"># So, this wrapper needs to produce that.</span>
        
        <span class="c1"># Let&#39;s assume a simplified scenario: all lines are from the *first* flight encountered.</span>
        <span class="c1"># This is a major simplification and likely not robust for general use.</span>
        
        <span class="n">first_line_num</span> <span class="o">=</span> <span class="n">_lines_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">first_line_info</span> <span class="o">=</span> <span class="n">df_line_local</span><span class="p">[</span><span class="n">df_line_local</span><span class="p">[</span><span class="s2">&quot;line&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">first_line_num</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">first_line_info</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WARN: First line </span><span class="si">{</span><span class="n">first_line_num</span><span class="si">}</span><span class="s2"> not found. Cannot load data.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        
        <span class="n">first_flight_name</span> <span class="o">=</span> <span class="n">first_line_info</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;flight&quot;</span><span class="p">]</span>
        <span class="n">first_flight_info</span> <span class="o">=</span> <span class="n">df_flight_local</span><span class="p">[</span><span class="n">df_flight_local</span><span class="p">[</span><span class="s2">&quot;flight&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">first_flight_name</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">first_flight_info</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WARN: Flight </span><span class="si">{</span><span class="n">first_flight_name</span><span class="si">}</span><span class="s2"> not found. Cannot load data.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
            
        <span class="n">xyz_file</span> <span class="o">=</span> <span class="n">first_flight_info</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;xyz_file&quot;</span><span class="p">]</span>
        <span class="n">xyz_type_sym</span> <span class="o">=</span> <span class="n">first_flight_info</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;xyz_type&quot;</span><span class="p">]</span> <span class="c1"># Symbol in Julia, string in Python</span>
        
        <span class="c1"># Placeholder for get_XYZ and get_ind</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">.create_xyz</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_XYZ</span> <span class="c1"># Assuming it&#39;s in create_xyz.py</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">.analysis_util</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_ind</span> <span class="c1"># Assuming it&#39;s in analysis_util.py</span>
            
            <span class="c1"># Load the base XYZ for the flight</span>
            <span class="c1"># This is a placeholder call, actual get_XYZ needs full implementation</span>
            <span class="n">xyz_loaded</span> <span class="o">=</span> <span class="n">get_XYZ</span><span class="p">(</span><span class="n">xyz_file</span><span class="p">,</span> <span class="n">xyz_type_sym</span><span class="p">)</span> 
            
            <span class="c1"># Get all indices for the specified lines within this XYZ</span>
            <span class="c1"># This also needs full implementation based on t_start, t_end from df_line</span>
            <span class="c1"># For simplicity, assume get_ind can take multiple lines for the *same* xyz_loaded</span>
            <span class="n">indices_for_set</span> <span class="o">=</span> <span class="n">get_ind</span><span class="p">(</span><span class="n">xyz_loaded</span><span class="p">,</span> <span class="n">_lines_set</span><span class="p">,</span> <span class="n">df_line_local</span><span class="p">)</span>

            <span class="c1"># Map loading (simplified)</span>
            <span class="n">map_obj_loaded</span> <span class="o">=</span> <span class="n">mapS_null</span>
            <span class="k">if</span> <span class="s2">&quot;map_name&quot;</span> <span class="ow">in</span> <span class="n">first_line_info</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">first_line_info</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;map_name&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">map_name_val</span> <span class="o">=</span> <span class="n">first_line_info</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;map_name&quot;</span><span class="p">]</span>
                <span class="n">map_info</span> <span class="o">=</span> <span class="n">df_map_local</span><span class="p">[</span><span class="n">df_map_local</span><span class="p">[</span><span class="s2">&quot;map_name&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">map_name_val</span><span class="p">]</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">map_info</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
                    <span class="c1"># map_file_path = map_info.iloc[0][&quot;map_file&quot;]</span>
                    <span class="c1"># map_obj_loaded = get_map(map_file_path) # Placeholder for map loading</span>
                    <span class="k">pass</span> <span class="c1"># Actual map loading needed here</span>

            <span class="k">return</span> <span class="n">xyz_loaded</span><span class="p">,</span> <span class="n">indices_for_set</span><span class="p">,</span> <span class="n">map_obj_loaded</span>

        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;WARN: Could not import get_XYZ or get_ind: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Returning None for XYZ/ind.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ERROR loading XYZ/ind for lines </span><span class="si">{</span><span class="n">lines_set</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

    <span class="n">xyz_train_loaded</span><span class="p">,</span> <span class="n">ind_train_loaded</span><span class="p">,</span> <span class="n">mapS_train_loaded</span> <span class="o">=</span> <span class="n">load_xyz_and_ind_for_lines</span><span class="p">(</span>
        <span class="n">lines_train</span><span class="p">,</span> <span class="n">df_line</span><span class="p">,</span> <span class="n">df_flight</span><span class="p">,</span> <span class="n">df_map</span><span class="p">,</span> <span class="n">comp_params</span>
    <span class="p">)</span>
    <span class="n">xyz_test_loaded</span><span class="p">,</span> <span class="n">ind_test_loaded</span><span class="p">,</span> <span class="n">mapS_test_loaded</span> <span class="o">=</span> <span class="n">load_xyz_and_ind_for_lines</span><span class="p">(</span>
        <span class="n">lines_test</span><span class="p">,</span> <span class="n">df_line</span><span class="p">,</span> <span class="n">df_flight</span><span class="p">,</span> <span class="n">df_map</span><span class="p">,</span> <span class="n">comp_params</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">xyz_train_loaded</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">ind_train_loaded</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> \
       <span class="n">xyz_test_loaded</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">ind_test_loaded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Failed to load training or testing data from DataFrames.&quot;</span><span class="p">)</span>

    <span class="c1"># Call the primary comp_train_test function</span>
    <span class="k">return</span> <span class="n">comp_train_test</span><span class="p">(</span>
        <span class="n">comp_params</span><span class="p">,</span>
        <span class="n">xyz_train_loaded</span><span class="p">,</span> <span class="n">xyz_test_loaded</span><span class="p">,</span>
        <span class="n">ind_train_loaded</span><span class="p">,</span> <span class="n">ind_test_loaded</span><span class="p">,</span>
        <span class="n">mapS_train</span><span class="o">=</span><span class="n">mapS_train_loaded</span> <span class="k">if</span> <span class="n">mapS_train_loaded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">mapS_null</span><span class="p">,</span>
        <span class="n">mapS_test</span><span class="o">=</span><span class="n">mapS_test_loaded</span> <span class="k">if</span> <span class="n">mapS_test_loaded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">mapS_null</span><span class="p">,</span>
        <span class="n">temp_params</span><span class="o">=</span><span class="n">temp_params</span><span class="p">,</span>
        <span class="n">silent</span><span class="o">=</span><span class="n">silent</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="remove_extension">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.remove_extension">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">remove_extension</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">ext</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;.bson&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Removes the extension from a filename if it exists.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">filename</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="n">ext</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">filename</span><span class="p">[:</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">ext</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">filename</span></div>


<div class="viewcode-block" id="add_extension">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.add_extension">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">add_extension</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">ext</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;.csv&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Adds the extension to a filename if it doesn&#39;t exist.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">filename</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="n">ext</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">filename</span> <span class="o">+</span> <span class="n">ext</span>
    <span class="k">return</span> <span class="n">filename</span></div>


<span class="c1"># Helper for LBFGS in PyTorch (simplified, actual implementation might need more from Optim.jl)</span>
<span class="c1"># The lbfgs_setup from Julia is quite specific to Optim.jl&#39;s interface.</span>
<span class="c1"># PyTorch&#39;s LBFGS optimizer has a different API (optimizer.step(closure)).</span>
<span class="c1"># The closure function is defined within each nn_comp_X_train function.</span>
<span class="c1"># So, a direct translation of lbfgs_setup might not be needed if using PyTorch&#39;s LBFGS correctly.</span>

<div class="viewcode-block" id="print_time">
<a class="viewcode-back" href="../../api_reference.html#magnavpy.compensation.print_time">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">print_time</span><span class="p">(</span><span class="n">t</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">digits</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Prints time in sec if &lt;1 min, otherwise min.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="mi">60</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: time: </span><span class="si">{</span><span class="n">t</span><span class="si">:</span><span class="s2">.</span><span class="si">{</span><span class="n">digits</span><span class="si">}</span><span class="s2">f</span><span class="si">}</span><span class="s2"> sec&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INFO: time: </span><span class="si">{</span><span class="n">t</span><span class="o">/</span><span class="mi">60</span><span class="si">:</span><span class="s2">.</span><span class="si">{</span><span class="n">digits</span><span class="si">}</span><span class="s2">f</span><span class="si">}</span><span class="s2"> min&quot;</span><span class="p">)</span></div>


<span class="c1"># Removed duplicate __main__ block and extensive summary comments.</span>
<span class="c1"># The final __main__ block is kept for potential example usage.</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="c1"># Example usage or tests could go here</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MagNavPy compensation module cleaned.&quot;</span><span class="p">)</span>

    <span class="c1"># Example: Test m1_struct and a dummy model</span>
    <span class="c1"># model_example = nn.Sequential(nn.Linear(10, 8), nn.SiLU(), nn.Linear(8, 1))</span>
    <span class="c1"># m1_instance = M1Struct(model_example)</span>
    <span class="c1"># dummy_input = torch.randn(5, 10) # batch_size=5, features=10</span>
    <span class="c1"># output = m1_instance.m(dummy_input)</span>
    <span class="c1"># print(f&quot;M1Struct dummy output shape: {output.shape}&quot;)</span>
    <span class="k">pass</span>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">MagNavPy</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">Flight Path &amp; INS Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../maps.html">Magnetic Anomaly Maps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../comp.html">Aeromagnetic Compensation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nncomp.html">Neural Network-Based Model Diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nav.html">Navigation Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_functions.html">API: Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_structs.html">API: Structs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference.html">API Reference</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, MagNav.jl Authors & AI Porting Team.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
    </div>

    

    
  </body>
</html>